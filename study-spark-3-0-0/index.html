<!doctype html>
<html lang="jp">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name="hugo-theme" content="Axiom 0.7.0">



  <link rel="icon" type="image/png" sizes="32x32" href="/image/brand/favicon.png">
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/">
  <link rel="canonical" href="https://soonraah.github.io/study-spark-3-0-0/">
<link rel="preload" as="style" href="/bundle.css?v=1595258565" media="all">
<link rel="stylesheet" href="/bundle.css?v=1595258565" media="all">
<style>.cdata pre{color:#edf2f7;background-color:#2d3748}.cdata :not(pre)>code{color:#805ad5;background-color:#f7fafc}.chroma .err{color:#fed7d7;background-color:#9b2c2c}.chroma .hl{background-color:#4a5568}.chroma .ln{color:#a0aec0}.chroma .k,.chroma .kc,.chroma .kd,.chroma .kn,.chroma .kp,.chroma .kr{color:#63b3ed}.chroma .kt{color:#b794f4}.chroma .na{color:#f6e05e}.chroma .nb{color:#f6ad55}.chroma .nc{color:#fc8181}.chroma .no{color:#68d391}.chroma .nd{color:#fc8181}.chroma .ne{color:#fc8181}.chroma .nf{color:#f6ad55}.chroma .nt{color:#fc8181}.chroma .l{color:#b794f4}.chroma .dl,.chroma .ld,.chroma .s,.chroma .s2,.chroma .sa,.chroma .sb,.chroma .sc,.chroma .sd{color:#68d391}.chroma .se{color:#a0aec0}.chroma .s1,.chroma .sh,.chroma .si,.chroma .sr,.chroma .ss,.chroma .sx{color:#68d391}.chroma .il,.chroma .m,.chroma .mb,.chroma .mf,.chroma .mh,.chroma .mi,.chroma .mo{color:#b794f4}.chroma .o,.chroma .ow{color:#90cdf4}.chroma .p{color:#cbd5e0}.chroma .c,.chroma .c1,.chroma .ch,.chroma .cm,.chroma .cp,.chroma .cpf,.chroma .cs{color:#a0aec0}.chroma .ge{font-style:italic}.chroma .gs{font-weight:700}</style>



<title>Apache Spark 3.0.0 について調べた : Froglog</title>

<meta property="og:title" content="Apache Spark 3.0.0 について調べた">
<meta property="og:site_name" content="Froglog">
<meta property="og:url" content="https://soonraah.github.io/study-spark-3-0-0/">
<link rel="image_src" href="https://soonraah.github.io/">
<meta property="og:image" content="https://soonraah.github.io/">
<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">
<meta property="og:type" content="article">
<meta property="og:locale" content="jp">
<meta property="og:description" content="はじめに Apache Spark 3.0.0 がリリースされました。  Spark Release 3.0.0  release note を見て個人的に気になったところなど簡単に調べました。 書いてみると Databricks の記事へのリンクばっかになってしまった… 全体感 こちらの記事を読めば全体感は OK.  Introducing Apache Spark 3.0  公式の release note には  Python is now the most widely used language on Spark.">
<meta name="description" content="はじめに Apache Spark 3.0.0 がリリースされました。  Spark Release 3.0.0  release note を見て個人的に気になったところなど簡単に調べました。 書いてみると Databricks の記事へのリンクばっかになってしまった… 全体感 こちらの記事を読めば全体感は OK.  Introducing Apache Spark 3.0  公式の release note には  Python is now the most widely used language on Spark.">
<meta property="og:updated_time" content="2020-07-12T00:00:00Z">
<meta property="fb:app_id" content="">
<meta name="author" content="soonraah">
<meta property="article:author" content="https://soonraah.github.io/">
<meta property="article:published_time" content="2020-07-12T00:00:00Z">
<meta property="article:modified_time" content="2020-07-12T00:00:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "Apache Spark 3.0.0 について調べた",
  "alternativeHeadline": "はじめに Apache Spark 3.0.0 がリリースされました。  Spark Release 3.0.0  release note を見て個人的に気になったところなど簡単に調べました。 書いてみると Databricks の記事へのリンクばっかになってしまった… 全体感 こちらの記事を読めば全体感は OK.  Introducing Apache Spark 3.0  公式の release note には  Python is now the most widely used language on Spark.",
  "url": "https://soonraah.github.io/study-spark-3-0-0/",
  "image": "https://soonraah.github.io/",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://soonraah.github.io/study-spark-3-0-0/"
  },
  "description": "はじめに Apache Spark 3.0.0 がリリースされました。  Spark Release 3.0.0  release note を見て個人的に気になったところなど簡単に調べました。 書いてみると Databricks の記事へのリンクばっかになってしまった… 全体感 こちらの記事を読めば全体感は OK.  Introducing Apache Spark 3.0  公式の release note には  Python is now the most widely used language on Spark.",
  "author": {
    "@type": "Person",
    "name": "soonraah"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Froglog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://soonraah.github.io/"
    }
  },
  "datePublished": "2020-07-12T00:00:00Z",
  "dateModified": "2020-07-12T00:00:00Z",
  "articleBody": "\u003ch2 id=\"はじめに\"\u003eはじめに\u003c/h2\u003e\n\u003cp\u003eApache Spark 3.0.0 がリリースされました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://spark.apache.org/releases/spark-release-3-0-0.html\"\u003eSpark Release 3.0.0\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003erelease note を見て個人的に気になったところなど簡単に調べました。\n書いてみると Databricks の記事へのリンクばっかになってしまった…\u003c/p\u003e\n\u003ch2 id=\"全体感\"\u003e全体感\u003c/h2\u003e\n\u003cp\u003eこちらの記事を読めば全体感は OK.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://databricks.com/jp/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html\"\u003eIntroducing Apache Spark 3.0\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e公式の release note には\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003ePython is now the most widely used language on Spark.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eとあってそうなん？ってなったけど、こちらの記事だと\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003ePython is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eと書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。\nプロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。\u003c/p\u003e\n\u003ch2 id=\"project-hydrogen-accelerator-aware-scheduler\"\u003e[Project Hydrogen] Accelerator-aware Scheduler\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://issues.apache.org/jira/browse/SPARK-24615\"\u003eSPARK-24615\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSpark 上で deep learning できるようにすることを目指す Project Hydrogen、その3つの大きな目標のうちの一つ。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.slideshare.net/MatthewStubbs6/big-data-ldn-2018-project-hydrogen-unifying-ai-with-apache-spark/26\"\u003eBig Data LDN 2018: PROJECT HYDROGEN: UNIFYING AI WITH APACHE SPARK\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eYARN や Kubernetes では GPU や FPGA を扱えるようになっているので Spark でも扱えるようにしたいというモチベーション。\n\u003ca href=\"https://spark.apache.org/docs/3.0.0/running-on-yarn.html#resource-allocation-and-configuration-overview\"\u003eSpark のドキュメント\u003c/a\u003e によると\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFor example, the user wants to request 2 GPUs for each executor. The user can just specify \u003ccode\u003espark.executor.resource.gpu.amount=2\u003c/code\u003e and Spark will handle requesting \u003ccode\u003eyarn.io/gpu\u003c/code\u003e resource type from YARN.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eのようにして executor に GPU リソースを要求できるみたいです。\u003c/p\u003e\n\u003ch2 id=\"adaptive-query-execution\"\u003eAdaptive Query Execution\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://issues.apache.org/jira/browse/SPARK-31412\"\u003eSPARK-31412\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e平たく言うと実行時に得られる統計情報を使って plan を最適化すると、静的に生成された plan より効率化できるよねという話。\n\u003ccode\u003espark.sql.adaptive.enabled=true\u003c/code\u003e にすることで有効になります。\u003c/p\u003e\n\u003cp\u003e処理の途中で中間生成物が materialize されるタイミングで、その時点の統計情報を使って残りの処理を最適化する、というのを繰り返します。\u003c/p\u003e\n\u003cp\u003eSpark 3.0.0 では以下3つの AQE が実装されました。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eCoalescing Post Shuffle Partitions\u003c/li\u003e\n\u003cli\u003eConverting sort-merge join to broadcast join\u003c/li\u003e\n\u003cli\u003eOptimizing Skew Join\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eSpark 2 以前だとこのあたりは実行しつつチューニングするような運用になりがちでした。\n特に skew の解消は salt を追加したりなど面倒だったりします。\nこれらが自動で最適化されるというのは運用上うれしいところ。\n急なデータ傾向の変化に対しても自動で最適化して対応できるという面があります。\u003c/p\u003e\n\u003cp\u003eAQE に関してもやはり Databricks の解説記事がわかりやすいです。\n図もいい感じ。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html\"\u003eAdaptive Query Execution: Speeding Up Spark SQL at Runtime\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dynamic-partition-pruning\"\u003eDynamic Partition Pruning\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://issues.apache.org/jira/browse/SPARK-11150\"\u003eSPARK-11150\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこちらも AQE 同様にクエリのパフォーマンスを改善する目的で導入されたもの。\n改善幅は AQE より大きいようです。\nやはり実行時の情報を使って partition pruning を行い、不要な partition の参照を減らすという方法。\u003c/p\u003e\n\u003cp\u003e主に \u003ca href=\"https://ja.wikipedia.org/wiki/%E3%82%B9%E3%82%BF%E3%83%BC%E3%82%B9%E3%82%AD%E3%83%BC%E3%83%9E\"\u003estar schema\u003c/a\u003e における join 時のように、静的には partition pruning が行えない場合を想定しています。\n比較的小さいことが多いと思われる dimension table 側を broadcast する broadcast join において、broadcast された情報を fact table の partition pruning に利用するというやり口。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.slideshare.net/databricks/dynamic-partition-pruning-in-apache-spark\"\u003eDynamic Partition Pruning in Apache Spark\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"structured-streaming-ui\"\u003eStructured Streaming UI\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://issues.apache.org/jira/browse/SPARK-29543\"\u003eSPARK-29543\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u0026quot;Structured Streaming\u0026quot; というタブが UI に追加された件。\nSpark のドキュメントに例があります。\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cimg src=\"https://spark.apache.org/docs/3.0.0/img/webui-structured-streaming-detail.png\" alt=\"Structured Streaming Query Statistics\"\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003e \u003c/p\u003e\n  \u003cfooter\u003e\u0026#8212; Apache Spark \u003ccite title=\"Structured Streaming Tab\"\u003e\u003ca rel=\"noopener nofollow\" href=\"https://spark.apache.org/docs/3.0.0/web-ui.html#structured-streaming-tab\"\u003eStructured Streaming Tab\u003c/a\u003e\u003c/cite\u003e\u003c/footer\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eSpark 2.4 系では Structured Streaming を動かしていてもせいぜい job や stage が増えていくという味気ないものしか見えませんでした。\nSpark 3.0.0 で実際に動かしてみたけど欲しかったやつ！という感じ。\nストリーム処理では入力データ量の変化の可視化がマストだと思ってます。\u003c/p\u003e\n\u003ch2 id=\"catalog-plugin-api\"\u003eCatalog plugin API\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://issues.apache.org/jira/browse/SPARK-31121\"\u003eSPARK-31121\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://docs.google.com/document/d/1zLFiA1VuaWeVxeTDXNg8bL6GP3BVoOZBkewFtEnjEoo/edit\"\u003eSPIP: Spark API for Table Metadata\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこれまでは CTAS (Create Table As Select) の操作はあったが、外部のデータソースに対して DDL 的な操作をする API が足りていませんでした。\nCTAS も挙動に実装依存の曖昧さがありました。\nそこで \u003ccode\u003ecreate\u003c/code\u003e, \u003ccode\u003ealter\u003c/code\u003e, \u003ccode\u003eload\u003c/code\u003e, \u003ccode\u003edrop\u003c/code\u003e 等のテーブル操作をできるようにしたという話。\u003c/p\u003e\n\u003cp\u003eドキュメントの \u003ca href=\"https://spark.apache.org/docs/3.0.0/sql-ref-syntax.html#ddl-statements\"\u003eDDL Statements\u003c/a\u003e のあたりを読め何ができるかわかります。\n以前のバージョンでも一部のデータソースについてはできた模様 (ex. \u003ca href=\"https://spark.apache.org/docs/2.4.6/sql-migration-guide-hive-compatibility.html#supported-hive-features\"\u003eHive\u003c/a\u003e)。\u003c/p\u003e\n\u003cp\u003e今の自分の業務では Spark から DDL を扱うようなことはしないのでそれほど恩恵は感じられません。\nnotebook からアドホックな Spark のバッチを動かすというような使い方をしていればうれしいかもしれません。\u003c/p\u003e\n\u003ch2 id=\"add-an-api-that-allows-a-user-to-define-and-observe-arbitrary-metrics-on-batch-and-streaming-queries\"\u003eAdd an API that allows a user to define and observe arbitrary metrics on batch and streaming queries\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://issues.apache.org/jira/browse/SPARK-29345\"\u003eSPARK-29345\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eクエリの途中の段階で何らかの metrics を仕込んでおいて callback 的にその metrics にアクセスできる仕組み。\n\u003ca href=\"https://spark.apache.org/docs/3.0.0/api/scala/org/apache/spark/sql/Dataset.html#observe(name:String,expr:org.apache.spark.sql.Column,exprs:org.apache.spark.sql.Column*):org.apache.spark.sql.Dataset%5BT%5D\"\u003eDataset#observe() の API ドキュメント\u003c/a\u003e を読むのが一番早いです。\nこの例ではストリーム処理を扱っているが、バッチ処理の例を自分で書いて試してみました。\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre class=\"chroma\"\u003e\u003ccode class=\"language-scala\" data-lang=\"scala\"\u003e\u003cspan class=\"c1\"\u003e// Register listener\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003espark\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003elistenerManager\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eregister\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003enew\u003c/span\u003e \u003cspan class=\"nc\"\u003eQueryExecutionListener\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n    \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003eonSuccess\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efuncName\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eString\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eqe\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eQueryExecution\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003edurationNs\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eLong\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eUnit\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e{\u003c/span\u003e\n      \u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003enum\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003eqe\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eobservedMetrics\u003c/span\u003e\n        \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eget\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;my_metrics\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n        \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emap\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"k\"\u003e_\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetAs\u003c/span\u003e\u003cspan class=\"o\"\u003e[\u003c/span\u003e\u003cspan class=\"kt\"\u003eLong\u003c/span\u003e\u003cspan class=\"o\"\u003e](\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;num\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e))\u003c/span\u003e\n        \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egetOrElse\u003c/span\u003e\u003cspan class=\"o\"\u003e(-\u003c/span\u003e\u003cspan class=\"mf\"\u003e100.0\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\n      \u003cspan class=\"n\"\u003eprintln\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003es\u0026#34;num of data: \u003c/span\u003e\u003cspan class=\"si\"\u003e$num\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n    \u003cspan class=\"o\"\u003e}\u003c/span\u003e\n\n    \u003cspan class=\"k\"\u003eoverride\u003c/span\u003e \u003cspan class=\"k\"\u003edef\u003c/span\u003e \u003cspan class=\"n\"\u003eonFailure\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003efuncName\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eString\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eqe\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eQueryExecution\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003eexception\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eException\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\u003cspan class=\"k\"\u003e:\u003c/span\u003e \u003cspan class=\"kt\"\u003eUnit\u003c/span\u003e \u003cspan class=\"o\"\u003e=\u003c/span\u003e \u003cspan class=\"o\"\u003e{}\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e})\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e// Make DataFrame\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"nc\"\u003eSeq\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erange\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e0\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"mi\"\u003e1000\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003emap\u003c/span\u003e\u003cspan class=\"o\"\u003e((\u003c/span\u003e\u003cspan class=\"k\"\u003e_\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"nc\"\u003eSeq\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;a\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;b\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;c\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)(\u003c/span\u003e\u003cspan class=\"nc\"\u003eRandom\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003enextInt\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"mi\"\u003e3\u003c/span\u003e\u003cspan class=\"o\"\u003e)),\u003c/span\u003e \u003cspan class=\"n\"\u003emath\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003erandom\u003c/span\u003e\u003cspan class=\"o\"\u003e()))\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003etoDF\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;id\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;type\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"s\"\u003e\u0026#34;value\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e// Observe and process\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"k\"\u003eval\u003c/span\u003e \u003cspan class=\"n\"\u003edfResult\u003c/span\u003e \u003cspan class=\"k\"\u003e=\u003c/span\u003e \u003cspan class=\"n\"\u003edf\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eobserve\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;my_metrics\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e,\u003c/span\u003e \u003cspan class=\"n\"\u003ecount\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e$\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;*\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eas\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;num\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e))\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003egroupBy\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e$\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;type\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e)\u003c/span\u003e\n  \u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eagg\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003eavg\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"n\"\u003e$\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;value\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e).\u003c/span\u003e\u003cspan class=\"n\"\u003eas\u003c/span\u003e\u003cspan class=\"o\"\u003e(\u003c/span\u003e\u003cspan class=\"s\"\u003e\u0026#34;avg_value\u0026#34;\u003c/span\u003e\u003cspan class=\"o\"\u003e))\u003c/span\u003e\n\n\u003cspan class=\"c1\"\u003e// Run\n\u003c/span\u003e\u003cspan class=\"c1\"\u003e\u003c/span\u003e\u003cspan class=\"n\"\u003edfResult\u003c/span\u003e\u003cspan class=\"o\"\u003e.\u003c/span\u003e\u003cspan class=\"n\"\u003eshow\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eこれを動かしたときの出力は次のようになりました。\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e+----+------------------+\n|type|         avg_value|\n+----+------------------+\n|   c|0.5129435063033314|\n|   b|0.4693004460694317|\n|   a|0.4912087482418599|\n+----+------------------+\n\nnum of data: 1000\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003eobserve()\u003c/code\u003e はその出力の DataFrame に対して schema やデータの中身を変更することはありません。\nmetrics を仕込むのみ。\nlogical plan を出力してみると \u003ccode\u003eobserve()\u003c/code\u003e を入れることにより途中に \u003ccode\u003eCollectMetrics\u003c/code\u003e という plan が挿入されていました。\nソースを見ると accumulator を使っている模様。\nなので \u003ccode\u003eobserve()\u003c/code\u003e の集計のみで一度 job が動くわけではなく、クエリが2回走るという感じではありません。\n全体の処理の中でひっそりと accumulator で脇で集計しておくといった趣でしょうか。\u003c/p\u003e\n\u003cp\u003eこれは結構有用だと思います。\n例えば何らかの集計をやるにしてもその最初や途中で、例えば入力データは何件あったか？みたいなことをログに出しておきたいことがあります。\nというか accumulator で頑張ってそういうものを作ったことがある…\nこれがフレームワーク側でサポートされるのはうれしいです。\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e2つのダイナミックな最適化に期待大。\n気が向いたら追加でまた調べるかもしれません。\u003c/p\u003e"
}
</script>

<link rel="preload" as="script" href="/bundle.js?v=1595258565">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://stats.g.doubleclick.net">
<link rel="preconnect" href="https://www.googleadservices.com">
<link rel="preload" as="script" href="https://www.googletagmanager.com/gtag/js?id=UA-73329599-2">
<script src="https://www.googletagmanager.com/gtag/js?id=UA-73329599-2"></script>
<script>
  window.dataLayer=window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js',new Date());
  gtag('config','UA-73329599-2');
</script>

</head>
<body>

  <header id="nav" class="header">
  <div class="ax-l-i max-w-6xl">
    <div class="ax-logo">
      <a class="block" href="/" title="Froglog"><span class="font-semibold text-raven-900">Froglog</span></a>
    </div>
    <div class="ax-user">
      <a class="p-2 w-8 h-8 block text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" target="_blank" rel="noopener nofollow" href="https://www.google.com/search?q=site:soonraah.github.io" title="Search">
        <svg class="fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M2.67 12.804c0-5.6 4.544-10.134 10.133-10.134s10.134 4.544 10.134 10.134-4.544 10.133-10.134 10.133S2.67 18.393 2.67 12.804zm28.943 16.923l-8.868-8.868c4.287-5.3 3.68-13.012-1.378-17.57S8.564-1.066 3.75 3.75s-5.017 12.558-.46 17.618 12.28 5.665 17.57 1.378l8.868 8.868a1.33 1.33 0 0 0 2.231-.597c.123-.46-.008-.952-.345-1.29h0z"/></svg>

      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/posts/">
        Posts
      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/tags/">
        Tags
      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/about/">
        About
      </a>
    </div>
  </div>

  
</header>

  <main>
<div class="default-single">
  <div class="ax-title ax-l-o">
    <div class="ax-l-i max-w-680">
      <h1 class="post-title font-content-title font-normal leading-tight tracking-default text-40">Apache Spark 3.0.0 について調べた</h1>

      <div class="ax-meta flex items-center mt-5">
        <div class="flex-grow min-w-0">
          <div class="flex items-center">
  <div class="flex-shrink-0">
    <img
    class="w-12 h-12 sm:w-14 sm:h-14 object-cover p-3px rounded-full border border-blue-300"
    src="/image/author/soonraah.png"
    alt="soonraah">
  </div>
  <div class="flex-shrink-0 ml-2 leading-tight font-content-sans">
    <a class="block text-sm text-raven-800 hover:text-raven-900 hover:underline focus:underline" target="_blank" rel="noopener nofollow" title="soonraah" href="https://soonraah.github.io/">soonraah</a>
    <time class="text-sm text-raven-500" datetime="2020-07-12T00:00:00Z">2020-07-12 09:00</time>
  </div>
</div>

        </div>
        <div>
          <div class="flex items-center">
  <a class="flex-shrink-0 block text-raven-800 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="Share on Twitter" href="https://twitter.com/intent/tweet?text=Apache%20Spark%203.0.0%20%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%20by%20%40soonraah%20https%3a%2f%2fsoonraah.github.io%2fstudy-spark-3-0-0%2f"><svg class="w-6 h-6 fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M32 6.078c-1.2.522-2.458.868-3.78 1.036 1.36-.812 2.398-2.088 2.886-3.626a13.11 13.11 0 0 1-4.16 1.588C25.742 3.794 24.026 3 22.154 3a6.56 6.56 0 0 0-6.556 6.562c0 .52.044 1.02.152 1.496-5.454-.266-10.28-2.88-13.522-6.862-.566.982-.898 2.106-.898 3.316a6.57 6.57 0 0 0 2.914 5.452 6.48 6.48 0 0 1-2.964-.808v.072c0 3.188 2.274 5.836 5.256 6.446-.534.146-1.116.216-1.72.216-.42 0-.844-.024-1.242-.112.85 2.598 3.262 4.508 6.13 4.57a13.18 13.18 0 0 1-8.134 2.798c-.538 0-1.054-.024-1.57-.1C2.906 27.93 6.35 29 10.064 29c12.072 0 18.672-10 18.672-18.668 0-.3-.01-.57-.024-.848C30.014 8.56 31.108 7.406 32 6.078z"/></svg>
</a>
  <a class="ml-3 flex-shrink-0 block text-raven-800 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="Share on Facebook" href="https://www.facebook.com/dialog/share?app_id=&display=page&href=https%3a%2f%2fsoonraah.github.io%2fstudy-spark-3-0-0%2f"><svg class="w-6 h-6 fill-current" viewBox="-7 -3.5 39 39" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M30.234 0H1.765C.8.001 0 .79 0 1.766v28.47C.001 31.2.79 32 1.766 32h15.328V19.625h-4.156V14.78h4.156v-3.564c0-4.134 2.523-6.384 6.21-6.384 1.766 0 3.284.13 3.726.2v4.32h-2.543c-2.006 0-2.394.953-2.394 2.352v3.085h4.797l-.625 4.844h-4.172V32h8.14C31.21 32 32 31.2 32 30.234V1.765C32 .8 31.21 0 30.234 0z"/></svg>
</a>
</div>

        </div>
      </div>
    </div>
  </div><div class="ax-content ax-l-o">
    <div class="ax-l-i max-w-680">
      <article class="cdata">
<h2 id="はじめに">はじめに</h2>
<p>Apache Spark 3.0.0 がリリースされました。</p>
<ul>
<li><a href="https://spark.apache.org/releases/spark-release-3-0-0.html">Spark Release 3.0.0</a></li>
</ul>
<p>release note を見て個人的に気になったところなど簡単に調べました。
書いてみると Databricks の記事へのリンクばっかになってしまった…</p>
<h2 id="全体感">全体感</h2>
<p>こちらの記事を読めば全体感は OK.</p>
<ul>
<li><a href="https://databricks.com/jp/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html">Introducing Apache Spark 3.0</a></li>
</ul>
<p>公式の release note には</p>
<blockquote>
<p>Python is now the most widely used language on Spark.</p>
</blockquote>
<p>とあってそうなん？ってなったけど、こちらの記事だと</p>
<blockquote>
<p>Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.</p>
</blockquote>
<p>と書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。
プロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。</p>
<h2 id="project-hydrogen-accelerator-aware-scheduler">[Project Hydrogen] Accelerator-aware Scheduler</h2>
<ul>
<li><a href="https://issues.apache.org/jira/browse/SPARK-24615">SPARK-24615</a></li>
</ul>
<p>Spark 上で deep learning できるようにすることを目指す Project Hydrogen、その3つの大きな目標のうちの一つ。</p>
<ul>
<li><a href="https://www.slideshare.net/MatthewStubbs6/big-data-ldn-2018-project-hydrogen-unifying-ai-with-apache-spark/26">Big Data LDN 2018: PROJECT HYDROGEN: UNIFYING AI WITH APACHE SPARK</a></li>
</ul>
<p>YARN や Kubernetes では GPU や FPGA を扱えるようになっているので Spark でも扱えるようにしたいというモチベーション。
<a href="https://spark.apache.org/docs/3.0.0/running-on-yarn.html#resource-allocation-and-configuration-overview">Spark のドキュメント</a> によると</p>
<blockquote>
<p>For example, the user wants to request 2 GPUs for each executor. The user can just specify <code>spark.executor.resource.gpu.amount=2</code> and Spark will handle requesting <code>yarn.io/gpu</code> resource type from YARN.</p>
</blockquote>
<p>のようにして executor に GPU リソースを要求できるみたいです。</p>
<h2 id="adaptive-query-execution">Adaptive Query Execution</h2>
<ul>
<li><a href="https://issues.apache.org/jira/browse/SPARK-31412">SPARK-31412</a></li>
</ul>
<p>平たく言うと実行時に得られる統計情報を使って plan を最適化すると、静的に生成された plan より効率化できるよねという話。
<code>spark.sql.adaptive.enabled=true</code> にすることで有効になります。</p>
<p>処理の途中で中間生成物が materialize されるタイミングで、その時点の統計情報を使って残りの処理を最適化する、というのを繰り返します。</p>
<p>Spark 3.0.0 では以下3つの AQE が実装されました。</p>
<ul>
<li>Coalescing Post Shuffle Partitions</li>
<li>Converting sort-merge join to broadcast join</li>
<li>Optimizing Skew Join</li>
</ul>
<p>Spark 2 以前だとこのあたりは実行しつつチューニングするような運用になりがちでした。
特に skew の解消は salt を追加したりなど面倒だったりします。
これらが自動で最適化されるというのは運用上うれしいところ。
急なデータ傾向の変化に対しても自動で最適化して対応できるという面があります。</p>
<p>AQE に関してもやはり Databricks の解説記事がわかりやすいです。
図もいい感じ。</p>
<ul>
<li><a href="https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html">Adaptive Query Execution: Speeding Up Spark SQL at Runtime</a></li>
</ul>
<h2 id="dynamic-partition-pruning">Dynamic Partition Pruning</h2>
<ul>
<li><a href="https://issues.apache.org/jira/browse/SPARK-11150">SPARK-11150</a></li>
</ul>
<p>こちらも AQE 同様にクエリのパフォーマンスを改善する目的で導入されたもの。
改善幅は AQE より大きいようです。
やはり実行時の情報を使って partition pruning を行い、不要な partition の参照を減らすという方法。</p>
<p>主に <a href="https://ja.wikipedia.org/wiki/%E3%82%B9%E3%82%BF%E3%83%BC%E3%82%B9%E3%82%AD%E3%83%BC%E3%83%9E">star schema</a> における join 時のように、静的には partition pruning が行えない場合を想定しています。
比較的小さいことが多いと思われる dimension table 側を broadcast する broadcast join において、broadcast された情報を fact table の partition pruning に利用するというやり口。</p>
<ul>
<li><a href="https://www.slideshare.net/databricks/dynamic-partition-pruning-in-apache-spark">Dynamic Partition Pruning in Apache Spark</a></li>
</ul>
<h2 id="structured-streaming-ui">Structured Streaming UI</h2>
<ul>
<li><a href="https://issues.apache.org/jira/browse/SPARK-29543">SPARK-29543</a></li>
</ul>
<p>&quot;Structured Streaming&quot; というタブが UI に追加された件。
Spark のドキュメントに例があります。</p>
<blockquote>
<p><img src="https://spark.apache.org/docs/3.0.0/img/webui-structured-streaming-detail.png" alt="Structured Streaming Query Statistics"></p>
</blockquote>

<blockquote>
  <p> </p>
  <footer>&#8212; Apache Spark <cite title="Structured Streaming Tab"><a rel="noopener nofollow" href="https://spark.apache.org/docs/3.0.0/web-ui.html#structured-streaming-tab">Structured Streaming Tab</a></cite></footer>
</blockquote>

<p>Spark 2.4 系では Structured Streaming を動かしていてもせいぜい job や stage が増えていくという味気ないものしか見えませんでした。
Spark 3.0.0 で実際に動かしてみたけど欲しかったやつ！という感じ。
ストリーム処理では入力データ量の変化の可視化がマストだと思ってます。</p>
<h2 id="catalog-plugin-api">Catalog plugin API</h2>
<ul>
<li><a href="https://issues.apache.org/jira/browse/SPARK-31121">SPARK-31121</a></li>
<li><a href="https://docs.google.com/document/d/1zLFiA1VuaWeVxeTDXNg8bL6GP3BVoOZBkewFtEnjEoo/edit">SPIP: Spark API for Table Metadata</a></li>
</ul>
<p>これまでは CTAS (Create Table As Select) の操作はあったが、外部のデータソースに対して DDL 的な操作をする API が足りていませんでした。
CTAS も挙動に実装依存の曖昧さがありました。
そこで <code>create</code>, <code>alter</code>, <code>load</code>, <code>drop</code> 等のテーブル操作をできるようにしたという話。</p>
<p>ドキュメントの <a href="https://spark.apache.org/docs/3.0.0/sql-ref-syntax.html#ddl-statements">DDL Statements</a> のあたりを読め何ができるかわかります。
以前のバージョンでも一部のデータソースについてはできた模様 (ex. <a href="https://spark.apache.org/docs/2.4.6/sql-migration-guide-hive-compatibility.html#supported-hive-features">Hive</a>)。</p>
<p>今の自分の業務では Spark から DDL を扱うようなことはしないのでそれほど恩恵は感じられません。
notebook からアドホックな Spark のバッチを動かすというような使い方をしていればうれしいかもしれません。</p>
<h2 id="add-an-api-that-allows-a-user-to-define-and-observe-arbitrary-metrics-on-batch-and-streaming-queries">Add an API that allows a user to define and observe arbitrary metrics on batch and streaming queries</h2>
<ul>
<li><a href="https://issues.apache.org/jira/browse/SPARK-29345">SPARK-29345</a></li>
</ul>
<p>クエリの途中の段階で何らかの metrics を仕込んでおいて callback 的にその metrics にアクセスできる仕組み。
<a href="https://spark.apache.org/docs/3.0.0/api/scala/org/apache/spark/sql/Dataset.html#observe(name:String,expr:org.apache.spark.sql.Column,exprs:org.apache.spark.sql.Column*):org.apache.spark.sql.Dataset%5BT%5D">Dataset#observe() の API ドキュメント</a> を読むのが一番早いです。
この例ではストリーム処理を扱っているが、バッチ処理の例を自分で書いて試してみました。</p>
<div class="highlight"><pre class="chroma"><code class="language-scala" data-lang="scala"><span class="c1">// Register listener
</span><span class="c1"></span><span class="n">spark</span>
  <span class="o">.</span><span class="n">listenerManager</span>
  <span class="o">.</span><span class="n">register</span><span class="o">(</span><span class="k">new</span> <span class="nc">QueryExecutionListener</span> <span class="o">{</span>
    <span class="k">override</span> <span class="k">def</span> <span class="n">onSuccess</span><span class="o">(</span><span class="n">funcName</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">qe</span><span class="k">:</span> <span class="kt">QueryExecution</span><span class="o">,</span> <span class="n">durationNs</span><span class="k">:</span> <span class="kt">Long</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{</span>
      <span class="k">val</span> <span class="n">num</span> <span class="k">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">observedMetrics</span>
        <span class="o">.</span><span class="n">get</span><span class="o">(</span><span class="s">&#34;my_metrics&#34;</span><span class="o">)</span>
        <span class="o">.</span><span class="n">map</span><span class="o">(</span><span class="k">_</span><span class="o">.</span><span class="n">getAs</span><span class="o">[</span><span class="kt">Long</span><span class="o">](</span><span class="s">&#34;num&#34;</span><span class="o">))</span>
        <span class="o">.</span><span class="n">getOrElse</span><span class="o">(-</span><span class="mf">100.0</span><span class="o">)</span>

      <span class="n">println</span><span class="o">(</span><span class="s">s&#34;num of data: </span><span class="si">$num</span><span class="s">&#34;</span><span class="o">)</span>
    <span class="o">}</span>

    <span class="k">override</span> <span class="k">def</span> <span class="n">onFailure</span><span class="o">(</span><span class="n">funcName</span><span class="k">:</span> <span class="kt">String</span><span class="o">,</span> <span class="n">qe</span><span class="k">:</span> <span class="kt">QueryExecution</span><span class="o">,</span> <span class="n">exception</span><span class="k">:</span> <span class="kt">Exception</span><span class="o">)</span><span class="k">:</span> <span class="kt">Unit</span> <span class="o">=</span> <span class="o">{}</span>
  <span class="o">})</span>

<span class="c1">// Make DataFrame
</span><span class="c1"></span><span class="k">val</span> <span class="n">df</span> <span class="k">=</span> <span class="nc">Seq</span>
  <span class="o">.</span><span class="n">range</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1000</span><span class="o">)</span>
  <span class="o">.</span><span class="n">map</span><span class="o">((</span><span class="k">_</span><span class="o">,</span> <span class="nc">Seq</span><span class="o">(</span><span class="s">&#34;a&#34;</span><span class="o">,</span> <span class="s">&#34;b&#34;</span><span class="o">,</span> <span class="s">&#34;c&#34;</span><span class="o">)(</span><span class="nc">Random</span><span class="o">.</span><span class="n">nextInt</span><span class="o">(</span><span class="mi">3</span><span class="o">)),</span> <span class="n">math</span><span class="o">.</span><span class="n">random</span><span class="o">()))</span>
  <span class="o">.</span><span class="n">toDF</span><span class="o">(</span><span class="s">&#34;id&#34;</span><span class="o">,</span> <span class="s">&#34;type&#34;</span><span class="o">,</span> <span class="s">&#34;value&#34;</span><span class="o">)</span>

<span class="c1">// Observe and process
</span><span class="c1"></span><span class="k">val</span> <span class="n">dfResult</span> <span class="k">=</span> <span class="n">df</span>
  <span class="o">.</span><span class="n">observe</span><span class="o">(</span><span class="s">&#34;my_metrics&#34;</span><span class="o">,</span> <span class="n">count</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;*&#34;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;num&#34;</span><span class="o">))</span>
  <span class="o">.</span><span class="n">groupBy</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;type&#34;</span><span class="o">)</span>
  <span class="o">.</span><span class="n">agg</span><span class="o">(</span><span class="n">avg</span><span class="o">(</span><span class="n">$</span><span class="s">&#34;value&#34;</span><span class="o">).</span><span class="n">as</span><span class="o">(</span><span class="s">&#34;avg_value&#34;</span><span class="o">))</span>

<span class="c1">// Run
</span><span class="c1"></span><span class="n">dfResult</span><span class="o">.</span><span class="n">show</span>
</code></pre></div><p>これを動かしたときの出力は次のようになりました。</p>
<pre><code>+----+------------------+
|type|         avg_value|
+----+------------------+
|   c|0.5129435063033314|
|   b|0.4693004460694317|
|   a|0.4912087482418599|
+----+------------------+

num of data: 1000
</code></pre><p><code>observe()</code> はその出力の DataFrame に対して schema やデータの中身を変更することはありません。
metrics を仕込むのみ。
logical plan を出力してみると <code>observe()</code> を入れることにより途中に <code>CollectMetrics</code> という plan が挿入されていました。
ソースを見ると accumulator を使っている模様。
なので <code>observe()</code> の集計のみで一度 job が動くわけではなく、クエリが2回走るという感じではありません。
全体の処理の中でひっそりと accumulator で脇で集計しておくといった趣でしょうか。</p>
<p>これは結構有用だと思います。
例えば何らかの集計をやるにしてもその最初や途中で、例えば入力データは何件あったか？みたいなことをログに出しておきたいことがあります。
というか accumulator で頑張ってそういうものを作ったことがある…
これがフレームワーク側でサポートされるのはうれしいです。</p>
<h2 id="まとめ">まとめ</h2>
<p>2つのダイナミックな最適化に期待大。
気が向いたら追加でまた調べるかもしれません。</p>

      </article>
      

      

    </div>
  </div>
</div>

  </main>
  <footer class="footer">
  <div class="ax-l-i max-w-6xl">
    <nav class="flex items-center justify-center">
      <a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href="/posts/">Posts</a>
      <a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href="/tags/">Tags</a>
      <a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href="/about/">About</a>
    </nav>
    <div class="footer-social flex items-center justify-center mt-4">
      <a class="block mx-3 w-6 h-6 text-raven-700 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="Twitter" href="https://twitter.com/soonraah"><svg class="fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M32 6.078c-1.2.522-2.458.868-3.78 1.036 1.36-.812 2.398-2.088 2.886-3.626a13.11 13.11 0 0 1-4.16 1.588C25.742 3.794 24.026 3 22.154 3a6.56 6.56 0 0 0-6.556 6.562c0 .52.044 1.02.152 1.496-5.454-.266-10.28-2.88-13.522-6.862-.566.982-.898 2.106-.898 3.316a6.57 6.57 0 0 0 2.914 5.452 6.48 6.48 0 0 1-2.964-.808v.072c0 3.188 2.274 5.836 5.256 6.446-.534.146-1.116.216-1.72.216-.42 0-.844-.024-1.242-.112.85 2.598 3.262 4.508 6.13 4.57a13.18 13.18 0 0 1-8.134 2.798c-.538 0-1.054-.024-1.57-.1C2.906 27.93 6.35 29 10.064 29c12.072 0 18.672-10 18.672-18.668 0-.3-.01-.57-.024-.848C30.014 8.56 31.108 7.406 32 6.078z"/></svg></a>
      <a class="block mx-3 w-6 h-6 text-raven-700 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="Github" href="https://github.com/soonraah"><svg class="fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M15.998 0C7.164 0 0 7.35 0 16.417 0 23.67 4.584 29.82 10.944 31.994c.8.15 1.092-.356 1.092-.79l-.022-2.792c-4.45.99-5.4-2.202-5.4-2.202-.726-1.896-1.776-2.4-1.776-2.4-1.454-1.018.108-.998.108-.998 1.606.117 2.45 1.693 2.45 1.693 1.428 2.507 3.746 1.784 4.658 1.363.144-1.06.558-1.784 1.016-2.195-3.552-.415-7.288-1.823-7.288-8.113 0-1.792.624-3.258 1.648-4.406-.166-.415-.714-2.085.156-4.344 0 0 1.344-.44 4.4 1.683 1.276-.364 2.644-.546 4.006-.552a14.98 14.98 0 0 1 4.006.554C23.062 6.37 24.404 6.8 24.404 6.8c.872 2.26.324 3.93.16 4.344 1.026 1.148 1.644 2.614 1.644 4.406 0 6.306-3.74 7.694-7.304 8.1.574.507 1.086 1.51 1.086 3.04l-.02 4.503c0 .44.288.95 1.1.788C27.42 29.817 32 23.667 32 16.417 32 7.35 24.836 0 15.998 0z"/></svg></a>
    </div>

    <div class="footer-copyright text-sm text-center text-gray-500 mt-4">
      &#169; 2020-2020 Froglog
    </div>
    <div class="text-sm sm:text-xs text-center text-gray-500 mt-2">
      Powered by <a href="https://www.axiomtheme.com/?utm_source=theme-footer&utm_medium=website&utm_campaign=referral">Axiom</a>
    </div>
  </div>
</footer>

<script src="/bundle.js?v=1595258565"></script>


</body>
</html>
