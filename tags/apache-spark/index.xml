<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Apache Spark on Froglog</title>
    <link>https://soonraah.github.io/tags/apache-spark/</link>
    <description>Recent content in Apache Spark on Froglog</description>
    <image>
      <title>Froglog</title>
      <url>https://soonraah.github.io/image/brand/soonraah_full.png</url>
      <link>https://soonraah.github.io/image/brand/soonraah_full.png</link>
    </image>
    <generator>Hugo -- 0.144.2</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 06 Sep 2020 16:30:00 +0900</lastBuildDate>
    <atom:link href="https://soonraah.github.io/tags/apache-spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと</title>
      <link>https://soonraah.github.io/posts/study-streaming-system/</link>
      <pubDate>Sun, 06 Sep 2020 16:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/study-streaming-system/</guid>
      <description>&lt;p&gt;ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。&lt;br&gt;
それにあたって独学で調べたことなどまとめておく。&lt;/p&gt;
&lt;h2 id=&#34;ストリーム処理とは&#34;&gt;ストリーム処理とは&lt;/h2&gt;
&lt;p&gt;そもそも &amp;ldquo;ストリーム処理&amp;rdquo; とは何を指しているのか。&lt;br&gt;
以下の引用が簡潔に示している。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a type of data processing engine that is designed with infinite data sets in mind. Nothing more.&lt;!-- raw HTML omitted --&gt;&lt;br&gt;
&amp;ndash; &lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/&#34;&gt;Streaming 101: The world beyond batch&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;こちらは &amp;ldquo;streaming system&amp;rdquo; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。&lt;/p&gt;
&lt;p&gt;例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。&lt;br&gt;
web サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。&lt;/p&gt;
&lt;p&gt;これに対して &amp;ldquo;1日分のユーザ行動ログ&amp;rdquo; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。&lt;br&gt;
ストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。&lt;br&gt;
この後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。&lt;/p&gt;
&lt;h2 id=&#34;なぜストリーム処理なのか&#34;&gt;なぜストリーム処理なのか&lt;/h2&gt;
&lt;p&gt;なぜストリーム処理なのか。&lt;br&gt;
ひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。&lt;br&gt;
迅速なフィードバックがビジネス上のメリットとなることは自明だ。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SNS の配信&lt;/li&gt;
&lt;li&gt;カーシェアリングにおける配車や料金設定&lt;/li&gt;
&lt;li&gt;クレジットカードや広告クリックなどの不正検知&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。&lt;br&gt;
まあ待っていられない。&lt;/p&gt;</description>
    </item>
    <item>
      <title>勉強会メモ: Spark Meetup Tokyo #3 Online</title>
      <link>https://soonraah.github.io/posts/spark-meetup-tokyo-3/</link>
      <pubDate>Sat, 01 Aug 2020 15:00:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/spark-meetup-tokyo-3/</guid>
      <description>&lt;p&gt;2020-07-31 にオンライン開催された &lt;a href=&#34;https://spark-meetup-tokyo.connpass.com/event/181422/&#34;&gt;Spark Meetup Tokyo #3 Online&lt;/a&gt; に参加した。&lt;br&gt;
感想などメモしておく。&lt;/p&gt;
&lt;h1 id=&#34;全体感&#34;&gt;全体感&lt;/h1&gt;
&lt;p&gt;トピックとしては主に&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Spark 3.0&lt;/li&gt;
&lt;li&gt;Spark + AI Summit 2020&lt;/li&gt;
&lt;li&gt;Spark 周辺要素&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;といったところだろうか。&lt;br&gt;
最近のコミュニティの動向や関心を日本語で聞くことができてよかった。&lt;/p&gt;
&lt;p&gt;運営 &amp;amp; スピーカーの皆様、ありがとうございます。&lt;/p&gt;
&lt;h1 id=&#34;発表&#34;&gt;発表&lt;/h1&gt;
&lt;p&gt;発表資料は公開されたら追加していく。&lt;/p&gt;
&lt;h2 id=&#34;sparkai-summit-2020-イベント概要&#34;&gt;SPARK+AI Summit 2020 イベント概要&lt;/h2&gt;
&lt;p&gt;スピーカー: &lt;a href=&#34;https://twitter.com/tokyodataguy&#34;&gt;@tokyodataguy&lt;/a&gt; さん&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Summit は金融業界の参加者が増えているらしい&lt;/li&gt;
&lt;li&gt;Spark で最も使われている言語は Python とのことだったが、Databricks の notebook サービスの話だった
&lt;ul&gt;
&lt;li&gt;プロダクションコードではまた違うのだろう&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Spark 3.0 の update をざっくりと&lt;/li&gt;
&lt;li&gt;Spark 周辺要素の話をざっくりと
&lt;ul&gt;
&lt;li&gt;Koalas&lt;/li&gt;
&lt;li&gt;Delta Lake&lt;/li&gt;
&lt;li&gt;Redash&lt;/li&gt;
&lt;li&gt;MLflow&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introducing-koalas-10&#34;&gt;Introducing Koalas 1.0&lt;/h2&gt;

&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/42rsX5ywWZbk5b&#34; width=&#34;510&#34; height=&#34;420&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a href=&#34;//www.slideshare.net/ueshin/introducing-koalas-10-and-11&#34; title=&#34;Introducing Koalas 1.0 (and 1.1)&#34; target=&#34;_blank&#34;&gt;Introducing Koalas 1.0 (and 1.1)&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a href=&#34;//www.slideshare.net/ueshin&#34; target=&#34;_blank&#34;&gt;Takuya UESHIN&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;

&lt;p&gt;スピーカー: &lt;a href=&#34;https://twitter.com/ueshin&#34;&gt;@ueshin&lt;/a&gt; さん&lt;/p&gt;</description>
    </item>
    <item>
      <title>Spark DataFrame クエリの弱い分離レベル</title>
      <link>https://soonraah.github.io/posts/weak_isolation_level_of_dataframe/</link>
      <pubDate>Sun, 19 Jul 2020 22:00:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/weak_isolation_level_of_dataframe/</guid>
      <description>&lt;p&gt;Spark バッチ処理の問題を調べていたら分離レベルという概念にたどりついた。&lt;br&gt;
分離レベルについて調べたので、Spark の問題の内容と絡めて記しておく。&lt;br&gt;
考えてみれば当たり前でたいした話ではない。&lt;/p&gt;
&lt;h1 id=&#34;分離レベルとは&#34;&gt;分離レベルとは&lt;/h1&gt;
&lt;h2 id=&#34;トランザクションの挙動についての暗黙の理解&#34;&gt;トランザクションの挙動についての暗黙の理解&lt;/h2&gt;
&lt;p&gt;アドホックな分析クエリやプロダクションコード中のクエリを書くとき、その単一のクエリのトランザクションにおいて「同時に実行されている別のクエリの commit 前の状態や commit 結果に影響され、このクエリの結果がおかしくなるかもしれない」ということは通常考えない。&lt;br&gt;
トランザクションはデータベースのある時点の状態に対して正しく処理される、というほぼ無意識の理解をおそらくほとんどの開発者が持っている。&lt;/p&gt;
&lt;p&gt;多くの場合この理解は間違っていない。&lt;br&gt;
それはなぜかというと DB 等のデータ処理フレームワークがある強さの分離レベルを提供しているからである。&lt;/p&gt;
&lt;h2 id=&#34;いろいろな分離レベル&#34;&gt;いろいろな分離レベル&lt;/h2&gt;
&lt;p&gt;ACID 特性のうちの1つ、分離性 (Isolation) の程度を表すのが分離レベル。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;トランザクション中に行われる操作の過程が他の操作から隠蔽されることを指し、日本語では分離性、独立性または隔離性ともいう。より形式的には、独立性とはトランザクション履歴が直列化されていることと言える。この性質と性能はトレードオフの関係にあるため、一般的にはこの性質の一部を緩和して実装される場合が多い。 &lt;!-- raw HTML omitted --&gt;&lt;br&gt;
&amp;ndash; &lt;!-- raw HTML omitted --&gt;&lt;a href=&#34;https://ja.wikipedia.org/wiki/ACID_%28%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E7%A7%91%E5%AD%A6%29&#34;&gt;Wikipedia ACID (コンピュータ科学)&lt;/a&gt;&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;分離レベルには名前のついたものがいくつかあり、分離性の保証の強さが異なる。&lt;br&gt;
具体的にはトランザクションの並行性の問題への対応力が異なる。&lt;br&gt;
名著「&lt;a href=&#34;https://www.amazon.co.jp/gp/product/4873118700/ref=as_li_tl?ie=UTF8&amp;amp;camp=247&amp;amp;creative=1211&amp;amp;creativeASIN=4873118700&amp;amp;linkCode=as2&amp;amp;tag=froglog02-22&amp;amp;linkId=19bf71b38427997bd19423b1bb219d3f&#34;&gt;データ指向アプリケーションデザイン&lt;/a&gt;」の第7章で分離レベルについて詳しく述べられているので、以下ではそちらからの引用。&lt;/p&gt;

&lt;a target=&#34;_blank&#34;  href=&#34;https://www.amazon.co.jp/gp/product/4873118700/ref=as_li_tl?ie=UTF8&amp;camp=247&amp;creative=1211&amp;creativeASIN=4873118700&amp;linkCode=as2&amp;tag=froglog02-22&amp;linkId=4d28525a2e352660b372d4d1027b72fb&#34;&gt;&lt;img border=&#34;0&#34; src=&#34;//ws-fe.amazon-adsystem.com/widgets/q?_encoding=UTF8&amp;MarketPlace=JP&amp;ASIN=4873118700&amp;ServiceVersion=20070822&amp;ID=AsinImage&amp;WS=1&amp;Format=_SL250_&amp;tag=froglog02-22&#34; &gt;&lt;/a&gt;&lt;img src=&#34;//ir-jp.amazon-adsystem.com/e/ir?t=froglog02-22&amp;l=am2&amp;o=9&amp;a=4873118700&#34; width=&#34;1&#34; height=&#34;1&#34; border=&#34;0&#34; alt=&#34;&#34; style=&#34;border:none !important; margin:0px !important;&#34; /&gt;
&lt;br&gt;

&lt;p&gt;分離レベルを弱い順に並べる。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;read uncommitted&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;このレベルではダーティライトは生じませんが、ダーティリードは妨げられません。&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;read committed&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;データベースからの読み取りを行った際に見えるデータは、コミットされたもののみであること（ダーティリードは生じない）。&lt;/li&gt;
&lt;li&gt;データベースへの書き込みを行う場合、上書きするのはコミットされたデータのみであること（ダーティライトは生じない）。&lt;/li&gt;
&lt;/ol&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;snapshot isolation&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;スナップショット分離の考え方は、それぞれのトランザクションがデータベースの一貫性のあるスナップショットから読み取りを行うというものです。すなわち、トランザクションが読み取るデータは、すべてそのトランザクションの開始時点のデータベースにコミット済みのものだけということです。&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;serializability&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;この分離レベルはトランザクションが並行して実行されていても、最終的な答えはそれぞれが1つずつ順番に、並行ではなく実行された場合と同じになることを保証します。&lt;/p&gt;&lt;/blockquote&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;日本語で「分離レベル」を検索すると snapshot isolation の代わりに repeatable read が出てくる事が多い。&lt;br&gt;
しかし repeatable read の名前は実装によって意味が違っていたりして扱いが難しいらしい。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Spark 3.0.0 について調べた</title>
      <link>https://soonraah.github.io/posts/study-spark-3-0-0/</link>
      <pubDate>Sun, 12 Jul 2020 11:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/study-spark-3-0-0/</guid>
      <description>&lt;h2 id=&#34;はじめに&#34;&gt;はじめに&lt;/h2&gt;
&lt;p&gt;Apache Spark 3.0.0 がリリースされました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://spark.apache.org/releases/spark-release-3-0-0.html&#34;&gt;Spark Release 3.0.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;release note を見て個人的に気になったところなど簡単に調べました。&lt;br&gt;
書いてみると Databricks の記事へのリンクばっかになってしまった…&lt;/p&gt;
&lt;h2 id=&#34;全体感&#34;&gt;全体感&lt;/h2&gt;
&lt;p&gt;こちらの記事を読めば全体感は OK.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://databricks.com/jp/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html&#34;&gt;Introducing Apache Spark 3.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;公式の release note には&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Python is now the most widely used language on Spark.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;とあってそうなん？ってなったけど、こちらの記事だと&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;と書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。&lt;br&gt;
プロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
