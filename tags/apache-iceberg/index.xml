<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Apache Iceberg on Froglog</title>
    <link>https://soonraah.github.io/tags/apache-iceberg/</link>
    <description>Recent content in Apache Iceberg on Froglog</description>
    <image>
      <title>Froglog</title>
      <url>https://soonraah.github.io/image/brand/soonraah_full.png</url>
      <link>https://soonraah.github.io/image/brand/soonraah_full.png</link>
    </image>
    <generator>Hugo -- 0.147.3</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 03 Dec 2023 22:00:00 +0900</lastBuildDate>
    <atom:link href="https://soonraah.github.io/tags/apache-iceberg/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CDC &#43; Apache Iceberg で Amazon Athena にデータを取り込む</title>
      <link>https://soonraah.github.io/posts/ingest-data-into-athena-by-cdc-and-iceberg/</link>
      <pubDate>Sun, 03 Dec 2023 22:00:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/ingest-data-into-athena-by-cdc-and-iceberg/</guid>
      <description>&lt;h2 id=&#34;このポストについて&#34;&gt;このポストについて&lt;/h2&gt;
&lt;p&gt;このポストは &lt;a href=&#34;https://qiita.com/advent-calendar/2023/distributed-computing&#34;&gt;Distributed computing Advent Calendar 2023&lt;/a&gt; の3日目の記事になります。&lt;br&gt;
1日目、2日目に続いて Apache Iceberg について書きますが、このポストでは Iceberg の実用例を書きます。&lt;/p&gt;
&lt;p&gt;AWS DMS による CDC の結果を Apache Iceberg 形式にして Amazon Athena でクエリできるようにするという内容になります。&lt;br&gt;
やっていることとしては &lt;a href=&#34;https://aws.amazon.com/jp/blogs/big-data/perform-upserts-in-a-data-lake-using-amazon-athena-and-apache-iceberg/&#34;&gt;Perform upserts in a data lake using Amazon Athena and Apache Iceberg | AWS Big Data Blog&lt;/a&gt; で紹介されている内容と近いですが、実務としての背景や工夫したところなどを書いていきます。&lt;/p&gt;
&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;私の所属する事業会社では日々プロダクトから様々なデータが発生しており、プロダクトの分析やレポーティング、ML など様々な用途で利用されている。&lt;br&gt;
それを支える基盤としてデータ基盤が存在している。&lt;/p&gt;
&lt;p&gt;データ基盤ではクエリエンジンとして &lt;a href=&#34;https://docs.aws.amazon.com/athena/latest/ug/what-is.html&#34;&gt;Amazon Athena&lt;/a&gt; を使っている。&lt;br&gt;
ストレージとしては S3 を使用しており、主に分析用として Parquet 形式でデータが置かれる。&lt;/p&gt;
&lt;p&gt;ここに業務用の operational な database から日次でデータを取り込んでいる。&lt;br&gt;
データソースは RDS (Aurora MySQL) であり、比較的大きなデータとなっている。&lt;/p&gt;
&lt;p&gt;これまではこの RDS -&amp;gt; S3 のデータ取り込みには RDS の &lt;a href=&#34;https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ExportSnapshot.html&#34;&gt;S3 snapshot export&lt;/a&gt; という機能を利用していた。&lt;br&gt;
この機能では比較的簡単な設定により、バックアップ用のスナップショットの内容を S3 に export することができる。&lt;br&gt;
ちなみに対象 database のスナップショットのサイズは数十 TB ある。&lt;/p&gt;</description>
    </item>
    <item>
      <title>near real time で更新される Apache Iceberg の table のメンテナンス</title>
      <link>https://soonraah.github.io/posts/maintain-iceberg-table-updated-in-near-real-time/</link>
      <pubDate>Sun, 28 May 2023 09:00:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/maintain-iceberg-table-updated-in-near-real-time/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;../update-iceberg-table-in-near-real-time&#34;&gt;前回のポスト&lt;/a&gt;では merge on read で Apache Iceberg の table を near real time で更新するということを行った。&lt;br&gt;
このポストではそのメンテナンスについて触れて、かつそれを実行してみる。&lt;/p&gt;
&lt;h2 id=&#34;merge-on-read-の課題&#34;&gt;merge on read の課題&lt;/h2&gt;
&lt;p&gt;merge on read で table を更新する場合、copy on write の場合と違い table 全体を洗い替えする必要はなく差分のみを追記することになる。&lt;br&gt;
したがって更新にかかる時間は copy on write よりも短くなる。&lt;br&gt;
一方で merge on read の名のとおり読み出し時に積み重なった差分とベースを merge して最新の snapshot とするため、読み出しの速度は copy on write より遅くなる。&lt;br&gt;
長時間更新され差分がたくさん存在しているとなおさら遅い。&lt;br&gt;
なので&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;更新頻度が低く、参照頻度が高いユースケース -&amp;gt; copy on write&lt;/li&gt;
&lt;li&gt;更新頻度が高く、参照頻度が低いユースケース -&amp;gt; merge on write&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;という使い分けがよいとされている。&lt;/p&gt;
&lt;p&gt;前回ポストの例では一晩更新を続けた後の merge on read の table に対して簡単な &lt;code&gt;select&lt;/code&gt; 文を実行したところ、6分程度かかってしまった。&lt;br&gt;
レコード数はたかだか128件程度であることを考えるとかなり遅いと言える。&lt;br&gt;
このままでは使い物にならない。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Apache Iceberg の table を near real time で更新する</title>
      <link>https://soonraah.github.io/posts/update-iceberg-table-in-near-real-time/</link>
      <pubDate>Thu, 11 May 2023 01:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/update-iceberg-table-in-near-real-time/</guid>
      <description>&lt;p&gt;Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。&lt;/p&gt;
&lt;h2 id=&#34;apache-iceberg-とは&#34;&gt;Apache Iceberg とは&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://iceberg.apache.org/&#34;&gt;Apache Iceberg&lt;/a&gt; (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。&lt;br&gt;
特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。&lt;br&gt;
これにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。&lt;/p&gt;
&lt;figure class=&#34;center&#34;&gt;
    &lt;img loading=&#34;lazy&#34; src=&#34;https://soonraah.github.io/image/iceberg/iceberg_metadata.png&#34;
         alt=&#34;Apache Iceberg&#34;/&gt; &lt;figcaption&gt;
            &lt;p&gt;Apache Iceberg
                    &lt;a href=&#34;https://iceberg.apache.org/spec/&#34;&gt;Iceberg Table Spec&lt;/a&gt;&lt;/p&gt;
        &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;詳しくは公式ドキュメントを参照のこと。&lt;br&gt;
最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/smartnews-inc/flink-based-iceberg-real-time-data-lake-in-smartnews-part-i-19a7628ce110&#34;&gt;Flink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
