<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>A/B Testing on Froglog</title>
    <link>https://soonraah.github.io/tags/a/b-testing/</link>
    <description>Recent content in A/B Testing on Froglog</description>
    <image>
      <title>Froglog</title>
      <url>https://soonraah.github.io/image/brand/soonraah_full.png</url>
      <link>https://soonraah.github.io/image/brand/soonraah_full.png</link>
    </image>
    <generator>Hugo -- 0.138.0</generator>
    <language>ja</language>
    <lastBuildDate>Sun, 23 Aug 2020 12:30:00 +0900</lastBuildDate>
    <atom:link href="https://soonraah.github.io/tags/a/b-testing/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A/B テストの運用が重くてつらいという話</title>
      <link>https://soonraah.github.io/posts/heavy-ab-testing-operation/</link>
      <pubDate>Sun, 23 Aug 2020 12:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/heavy-ab-testing-operation/</guid>
      <description>&lt;h2 id=&#34;前提&#34;&gt;前提&lt;/h2&gt;
&lt;p&gt;ここでは web システムで使われている機械学習のモデルやアルゴリズムを改善するための online の A/B テストを考える。&lt;br&gt;
具体的に述べると web 広告における CTR 予測や EC サイトのレコメンデーション等が対象である。&lt;br&gt;
よくあるやつ。&lt;/p&gt;
&lt;p&gt;web システムにおいて online の A/B テストは KPI 改善の根幹でありとても重要だ。&lt;br&gt;
それが重くなるとつらい、という話。&lt;br&gt;
ここで「重い」と言っているのは計算資源のことではなく、A/B テストを実施する担当者の運用コストについて。&lt;/p&gt;
&lt;h2 id=&#34;ab-テストの運用が重い場合のデメリット&#34;&gt;A/B テストの運用が重い場合のデメリット&lt;/h2&gt;
&lt;h3 id=&#34;デメリット-1-kpi-改善が遅くなる&#34;&gt;デメリット 1. KPI 改善が遅くなる&lt;/h3&gt;
&lt;p&gt;デメリットと言えばこれが一番大きい。&lt;br&gt;
単純に A/B テストを1回まわすのに時間がかかってしまうし、それがゆえに online の A/B テストに入るまでの offline のテストが厚くなりここでも時間がかかってしまう。&lt;br&gt;
KPI 改善に時間がかかるというのはつまり売上や利益を大きくするのに時間がかかってしまうということである。&lt;/p&gt;
&lt;h3 id=&#34;デメリット-2-kpi-改善における-offline-テストの比重が大きくなる&#34;&gt;デメリット 2. KPI 改善における offline テストの比重が大きくなる&lt;/h3&gt;
&lt;p&gt;前述のとおりだが online の A/B テストが重いとそこで失敗できなくなり、結果としてその前段の offline のテストを厚くするということになる。&lt;br&gt;
offline のテストが厚いことの何が問題だろうか。&lt;/p&gt;
&lt;p&gt;ここで前提としている CTR 予測やレコメンデーションのようなタスクの場合、offline のデータは既存のモデルやアルゴリズムの影響を受けることになる。&lt;br&gt;
例えばレコメンデーションの場合を考えると、新しいモデルを offline で評価するための実験データの正例 (コンテンツの閲覧等) は既存モデルによって生み出される。&lt;br&gt;
既存モデルが「このコンテンツがいいよ」といってユーザに出したリスト、その中からコンテンツの閲覧が行われ正例となるからだ。&lt;br&gt;
このような状況下での offline テストにおいては既存モデルと近い好みを持ったモデルのスコアが高くなる傾向がある。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
