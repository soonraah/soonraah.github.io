<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ふつうのデータ基盤移行 on Froglog</title>
    <link>https://soonraah.github.io/tags/%E3%81%B5%E3%81%A4%E3%81%86%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%9F%BA%E7%9B%A4%E7%A7%BB%E8%A1%8C/</link>
    <description>Recent content in ふつうのデータ基盤移行 on Froglog</description>
    <image>
      <title>Froglog</title>
      <url>https://soonraah.github.io/image/brand/soonraah_full.png</url>
      <link>https://soonraah.github.io/image/brand/soonraah_full.png</link>
    </image>
    <generator>Hugo -- 0.147.3</generator>
    <language>ja</language>
    <lastBuildDate>Thu, 18 Sep 2025 07:30:00 +0900</lastBuildDate>
    <atom:link href="https://soonraah.github.io/tags/%E3%81%B5%E3%81%A4%E3%81%86%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%9F%BA%E7%9B%A4%E7%A7%BB%E8%A1%8C/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ふつうのデータ基盤移行 - Part 5. IaC と CI/CD 編</title>
      <link>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-5/</link>
      <pubDate>Thu, 18 Sep 2025 07:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-5/</guid>
      <description>&lt;h2 id=&#34;このポストについて&#34;&gt;このポストについて&lt;/h2&gt;
&lt;p&gt;データ基盤移行について書いていくシリーズです。&lt;br&gt;
シリーズ一覧は&lt;a href=&#34;https://soonraah.github.io/tags/%E3%81%B5%E3%81%A4%E3%81%86%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%9F%BA%E7%9B%A4%E7%A7%BB%E8%A1%8C/&#34;&gt;こちら&lt;/a&gt;から。&lt;/p&gt;
&lt;p&gt;前回 &lt;a href=&#34;https://soonraah.github.io/posts/ordinary-data-platform-migration-part-4/&#34;&gt;Part 4. AI ワークフローで移行作業効率化編&lt;/a&gt;では移行するための苦労と効率化について書きました。&lt;br&gt;
今回はがらっと変わって IaC と CI/CD について書きます。&lt;/p&gt;
&lt;h2 id=&#34;スコープ&#34;&gt;スコープ&lt;/h2&gt;
&lt;p&gt;今回は開発寄りの話です。&lt;br&gt;
データ基盤の構築にあたり Terraform を使って IaC (Infrastructure as Code) を実現し、さらにそれに基づいて GitHub Actions による CI/CD (Continuous Integration &amp;amp; Continuous Derivery) 環境を作ったという話をしていきます。&lt;/p&gt;
&lt;p&gt;IaC で作りたいアーキテクチャは AWS 上の Databricks 環境とその周辺です。&lt;br&gt;
アーキテクチャについて詳しくは &lt;a href=&#34;https://soonraah.github.io/posts/ordinary-data-platform-migration-part-3/&#34;&gt;Part 3. アーキテクチャ編&lt;/a&gt;などをご参照ください。&lt;/p&gt;
&lt;p&gt;だいたい以下の図のような話です。&lt;/p&gt;
&lt;p&gt;&lt;img alt=&#34;CI/CD&#34; loading=&#34;lazy&#34; src=&#34;https://soonraah.github.io/image/ordinary-data-plagform-migration/ci_cd.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;お気持ち表明&#34;&gt;お気持ち表明&lt;/h2&gt;
&lt;p&gt;こんにちは、初手で絶対に CI/CD 環境を構築するマンです。&lt;br&gt;
初手で絶対に CI/CD 環境を構築するマンは、初手で絶対に CI/CD 環境を構築するぞ！という強い気持ちを持っています。&lt;/p&gt;
&lt;p&gt;Databricks 上にデータ基盤を構築するにあたり、他社事例でインフラ構築を自動化していないケースを見たこともあります。&lt;br&gt;
しかし我々のチームでは PoC 終了後の構築最初期から IaC としてインフラをコード化し、それを CI/CD の仕組みで自動でデプロイすることを決めていました。&lt;br&gt;
次のような理由からです。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;リリースの数だけ自動化のリターンがあるので、最初から自動化しておくのが最もリターンが大きい&lt;/li&gt;
&lt;li&gt;チームにはジュニアなメンバーもおり、手動の運用はオペミスや production, staging などの環境差発生のリスクが大きい&lt;/li&gt;
&lt;li&gt;社内で Terraform や GitHub Actions などがよく使われており、導入できる下地があった&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;まだ Databricks にそこまで慣れていない導入初期にこれらの仕組みを入れるのはそれなりにたいへんです。&lt;br&gt;
しかしそのたいへんさ以上のメリットがあると判断しました。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ふつうのデータ基盤移行 - Part 4. AI ワークフローで移行作業効率化編</title>
      <link>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-4/</link>
      <pubDate>Wed, 18 Jun 2025 07:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-4/</guid>
      <description>&lt;h2 id=&#34;このポストについて&#34;&gt;このポストについて&lt;/h2&gt;
&lt;p&gt;データ基盤移行について書いていくシリーズです。&lt;br&gt;
シリーズ一覧は&lt;a href=&#34;https://soonraah.github.io/tags/%E3%81%B5%E3%81%A4%E3%81%86%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%9F%BA%E7%9B%A4%E7%A7%BB%E8%A1%8C/&#34;&gt;こちら&lt;/a&gt;から。&lt;/p&gt;
&lt;p&gt;前回 &lt;a href=&#34;https://soonraah.github.io/posts/ordinary-data-platform-migration-part-3/&#34;&gt;Part 3. アーキテクチャ編&lt;/a&gt;ではどういったシステム構成にしたかを書きました。&lt;br&gt;
今回はその技術スタックへと移行するための苦労と効率化について書きます。&lt;/p&gt;
&lt;p&gt;(次は CI/CD の話をすると書きましたが…スマンありゃウソだった)&lt;/p&gt;
&lt;h2 id=&#34;スコープ&#34;&gt;スコープ&lt;/h2&gt;
&lt;p&gt;今回はやや小さいスコープの話です。&lt;br&gt;
データ基盤における ETL (ELT) 処理の移行作業を対象としています。&lt;br&gt;
移行作業における工数的な課題を AI ワークフローを作って効率化して軽減したという話になります。&lt;br&gt;
ETL 以外の移行作業は今回はスコープ外となります。&lt;/p&gt;
&lt;h2 id=&#34;課題&#34;&gt;課題&lt;/h2&gt;
&lt;p&gt;旧データ基盤から新データ基盤へと table およびそれを更新するための処理を移行するにあたり工数面での課題が2つあります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;技術スタックの移行&lt;/li&gt;
&lt;li&gt;column 命名などの標準化&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これらについて述べます。&lt;/p&gt;
&lt;h3 id=&#34;技術スタックの移行&#34;&gt;技術スタックの移行&lt;/h3&gt;
&lt;p&gt;データ基盤の移行において、新旧の環境で技術スタックは次のようになっています。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;旧データ基盤
&lt;ul&gt;
&lt;li&gt;ETL: Glue Job&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;新データ基盤
&lt;ul&gt;
&lt;li&gt;ELT: dbt-databricks&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;つまり Glue Job の Python コードを dbt model、つまり SQL に翻訳する必要があり、それなりに手間がかかります。&lt;br&gt;
さらにこの Python コードは次のような問題もあり、移行のハードルを上げます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UDF を実装して特殊な処理を行っているケースがある&lt;/li&gt;
&lt;li&gt;Spark の API だけでなく Glue の API をふんだんに使っている (なるべく Spark に寄せればいいものを…)&lt;/li&gt;
&lt;li&gt;(ここ数年の業務で見た中で一番というぐらいに) コード品質が低い&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;column-命名などの標準化&#34;&gt;column 命名などの標準化&lt;/h3&gt;
&lt;p&gt;旧データ基盤は利用者への配慮があまりない状態で table の schema が作られており、利用者にとって使いにくいものとなっていました。&lt;br&gt;
それを改善するため、新データ基盤では次のようなルールを導入しました。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ふつうのデータ基盤移行 - Part 3. アーキテクチャ編</title>
      <link>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-3/</link>
      <pubDate>Wed, 11 Jun 2025 08:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-3/</guid>
      <description>&lt;h2 id=&#34;このポストについて&#34;&gt;このポストについて&lt;/h2&gt;
&lt;p&gt;データ基盤移行について書いていくシリーズです。&lt;br&gt;
シリーズ一覧は&lt;a href=&#34;https://soonraah.github.io/tags/%E3%81%B5%E3%81%A4%E3%81%86%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%9F%BA%E7%9B%A4%E7%A7%BB%E8%A1%8C/&#34;&gt;こちら&lt;/a&gt;から。&lt;/p&gt;
&lt;p&gt;前回 &lt;a href=&#34;https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/&#34;&gt;Part 2. 技術選定編&lt;/a&gt;では技術選定について書きました。&lt;br&gt;
今回はそれを踏まえた結果としてどのようなアーキテクチャになったかを書きます。&lt;/p&gt;
&lt;h2 id=&#34;スコープ&#34;&gt;スコープ&lt;/h2&gt;
&lt;p&gt;前回の記事ではプラットフォームとして Databricks を選定したことやその経緯について記載しました。&lt;br&gt;
一方、それより詳細な技術スタックを含むシステムアーキテクチャについては示していませんでした。&lt;br&gt;
例えばデータ基盤では通常次のような技術スタックについて考える必要があります。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;データ取込&lt;/li&gt;
&lt;li&gt;workflow orchestration&lt;/li&gt;
&lt;li&gt;ELT (or ETL)&lt;/li&gt;
&lt;li&gt;storage&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;これらについて述べ、またデータ基盤の階層構造についても説明します。&lt;/p&gt;
&lt;h2 id=&#34;システムアーキテクチャ&#34;&gt;システムアーキテクチャ&lt;/h2&gt;
&lt;p&gt;データ基盤のシステム・アーキテクチャです。&lt;br&gt;
よく混同されがちですが、&lt;a href=&#34;https://soonraah.github.io/posts/dmbok-chapter-4/&#34;&gt;データアーキテクチャ&lt;/a&gt;ではありません。&lt;/p&gt;
&lt;p&gt;AWS + Databricks の構成をベースとして構築されています。&lt;/p&gt;
&lt;h3 id=&#34;概要図&#34;&gt;概要図&lt;/h3&gt;
&lt;p&gt;&lt;img alt=&#34;system architecture&#34; loading=&#34;lazy&#34; src=&#34;https://soonraah.github.io/image/ordinary-data-plagform-migration/system-architecture.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;データ取込&#34;&gt;データ取込&lt;/h3&gt;
&lt;p&gt;現時点ではデータソースとしては S3 に置かれた半構造化データ (JSON)、RDS がメインとなっています。&lt;br&gt;
これら2つの取込方法について述べます。&lt;/p&gt;
&lt;p&gt;まず、S3 のデータは SQL の &lt;code&gt;copy into&lt;/code&gt; 文により取り込んでいます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.databricks.com/aws/en/ingestion/cloud-object-storage/copy-into/&#34;&gt;Get started using COPY INTO to load data | Databricks Documentation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.databricks.com/aws/en/ingestion/cloud-object-storage/auto-loader&#34;&gt;Auto Loader&lt;/a&gt; を使う方が Databricks 的でありそれも検討したのですが、schema evolution や冪等性など検討した結果として &lt;code&gt;copy into&lt;/code&gt; を採用しました。&lt;/p&gt;
&lt;p&gt;RDS からのデータ取込は foreign catalog 経由で行います。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ふつうのデータ基盤移行 - Part 2. 技術選定編</title>
      <link>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/</link>
      <pubDate>Mon, 16 Dec 2024 00:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/</guid>
      <description>&lt;h2 id=&#34;このポストについて&#34;&gt;このポストについて&lt;/h2&gt;
&lt;p&gt;データ基盤移行について書いていくシリーズです。&lt;br&gt;
シリーズ一覧は&lt;a href=&#34;https://soonraah.github.io/tags/%E3%81%B5%E3%81%A4%E3%81%86%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%9F%BA%E7%9B%A4%E7%A7%BB%E8%A1%8C/&#34;&gt;こちら&lt;/a&gt;から。&lt;/p&gt;
&lt;p&gt;前回は戦略策定 (実際は戦術) までのところを書きました。&lt;br&gt;
今回はそれを踏まえた技術選定、およびその後の予算獲得について書いていきます。&lt;/p&gt;
&lt;p&gt;また、こちらは &lt;a href=&#34;https://qiita.com/advent-calendar/2024/databricks&#34;&gt;Databricks Advent Calendar 2024&lt;/a&gt; シリーズ 2 の16日目の記事にもなっています。&lt;br&gt;
はいそうです、出落ちですが技術選定として Databricks を選ぶことになります。&lt;/p&gt;
&lt;h2 id=&#34;スコープ&#34;&gt;スコープ&lt;/h2&gt;
&lt;p&gt;前回 &lt;a href=&#34;https://soonraah.github.io/posts/ordinary-data-platform-migration-part-1/&#34;&gt;Part 1. 戦略策定編&lt;/a&gt;では概ねのロードマップが決まり、まずはデータ基盤のリアーキテクチャをやっていくことになりました。&lt;br&gt;
リアーキテクチャにおいてはどのような技術スタックを使っていくかが重要な選択になります。&lt;br&gt;
データ基盤においてはデータ処理のためのストレージとコンピュートの選択がとても重要です。&lt;br&gt;
以降ではこの2つをあわせた DWH 製品の選定について書いていきます。&lt;br&gt;
「DHW 製品」という言葉は適切ではないかもしれませんが、ここではストレージ + コンピュートが組み合わさったものぐらいに考えてください。&lt;/p&gt;
&lt;p&gt;もちろんデータ基盤には他の技術要素もあり、それらも軽くない選択ですがこのポストでは割愛します。&lt;br&gt;
(気が向いたら別記事で書くかも)&lt;/p&gt;
&lt;h2 id=&#34;技術選定の目的&#34;&gt;技術選定の目的&lt;/h2&gt;
&lt;p&gt;まず何のために技術スタックの置き換え、ひいては技術選定をするかの目的を明確にしておく必要があります。&lt;br&gt;
旧データ基盤では次のような技術スタックになっていました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ストレージ: S3&lt;/li&gt;
&lt;li&gt;コンピュート: Glue Job, Athena&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;この構成には次のような課題がありました。&lt;br&gt;
主にこれらの課題を解決するために DWH 製品の乗り換えを検討することになりました。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;dbt との親和性の低さ&lt;/li&gt;
&lt;li&gt;一貫したガバナンスの欠如&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;dbt-との親和性の低さ&#34;&gt;dbt との親和性の低さ&lt;/h3&gt;
&lt;p&gt;前回作成した&lt;a href=&#34;https://soonraah.github.io/posts/ordinary-data-platform-migration-part-1/#%e3%83%ad%e3%83%bc%e3%83%89%e3%83%9e%e3%83%83%e3%83%97%e4%bd%9c%e6%88%90&#34;&gt;ロードマップ&lt;/a&gt;において、dbt の導入が課題解決における重要なポイントになっています。&lt;br&gt;
dbt の周辺エコシステムがデータ基盤の課題の解決に大きく貢献すると考えています。&lt;/p&gt;
&lt;p&gt;また、データパイプラインの開発・運用の負荷も dbt 導入で軽減できそうです。&lt;br&gt;
旧データ基盤では Glue Job と Athena クエリを組み合わせた複雑なパイプラインになっており、table を1つ追加するだけでもいろいろなコードに手をいれる必要があります。&lt;br&gt;
ほぼ SQL で実装でき、かつ宣言的にパイプライン構築できる dbt は魅力的です。&lt;/p&gt;
&lt;p&gt;仮に旧データ基盤に dbt を導入するとなると &lt;a href=&#34;https://docs.getdbt.com/docs/core/connect-data-platform/athena-setup&#34;&gt;dbt-athena&lt;/a&gt; を使うことになります。&lt;br&gt;
ただ dbt による Athena のサポートはやや弱く、dbt-athena はコミュニティ版から少し前に移管されたものですし、これを書いている2024年12月の時点で dbt Cloud の Athena のサポートはまだプレビューです。&lt;br&gt;
反論がある方もいらっしゃるかもしれませんが、モダンなデータ基盤構築において Athena はやや影が薄い印象があり、dbt のサポートの弱さもこれが原因だと思います。&lt;br&gt;
(ただし直近の re:Invent 2024 の内容からすると潮目が変わる可能性もありそうです)&lt;/p&gt;</description>
    </item>
    <item>
      <title>ふつうのデータ基盤移行 - Part 1. 戦略策定編</title>
      <link>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-1/</link>
      <pubDate>Sun, 01 Dec 2024 22:30:00 +0900</pubDate>
      <guid>https://soonraah.github.io/posts/ordinary-data-platform-migration-part-1/</guid>
      <description>&lt;h2 id=&#34;このポストについて&#34;&gt;このポストについて&lt;/h2&gt;
&lt;p&gt;データ基盤移行について書かれた各社の技術ブログなど見かけることがありますが、割とさらっと書かれていることが多いように思います。&lt;br&gt;
本当はいろんな面で苦労があり、記事に表れていない辛さや工夫などがあるはず。&lt;/p&gt;
&lt;p&gt;ということで今自分が経験している普通の会社の普通のデータ基盤移行について、詳しく記事にしてみようと考えました。&lt;br&gt;
何回かに分けてデータ基盤移行のいろいろな側面を、うまくいったこともいかなかったことも含めて書いていきます。&lt;br&gt;
とはいえ現在進行形なので、全編書き終わるのはかなり先になりそうです。&lt;/p&gt;
&lt;p&gt;データ基盤移行のシリーズ一覧は&lt;a href=&#34;https://soonraah.github.io/tags/%E3%81%B5%E3%81%A4%E3%81%86%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E5%9F%BA%E7%9B%A4%E7%A7%BB%E8%A1%8C/&#34;&gt;こちら&lt;/a&gt;から。&lt;/p&gt;
&lt;h2 id=&#34;移行の背景&#34;&gt;移行の背景&lt;/h2&gt;
&lt;h3 id=&#34;組織&#34;&gt;組織&lt;/h3&gt;
&lt;p&gt;まずイメージしやすいよう、どういった組織におけるデータ基盤移行なのかについて軽く触れておきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;社員規模: 〜100名&lt;/li&gt;
&lt;li&gt;web 系の B2C ビジネス&lt;/li&gt;
&lt;li&gt;データチームの構成
&lt;ul&gt;
&lt;li&gt;マネージャ: 1名 (データエンジニアリングの経験はほぼない)&lt;/li&gt;
&lt;li&gt;データエンジニア: 2 -&amp;gt; 3名 (途中で採用)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;中小のベンチャー？企業ではありますが、意思決定プロセスは JTC 感があります。&lt;br&gt;
私はデータエンジニアのポジションとなっており、その視点からの話であることにご留意ください。&lt;br&gt;
小さい組織ということで私は移行の計画から設計、開発その他のあらゆるフェーズに中心的に関わっています。&lt;br&gt;
どこもそうだと思いますが、人員的にはまあまあきびしい。&lt;/p&gt;
&lt;p&gt;よくある中小 IT 企業のよくあるデータ基盤移行の話だと思っていただきたく。&lt;br&gt;
大企業ではないのでそこまでちゃんとはしていません。&lt;/p&gt;
&lt;p&gt;(ちなみに自分のブログで本件を記事にしていいかは上長に確認の上、OK をもらっています)&lt;/p&gt;
&lt;h3 id=&#34;旧データ基盤&#34;&gt;旧データ基盤&lt;/h3&gt;
&lt;p&gt;一連のポストでは移行前のデータ基盤のことを「旧データ基盤」と表記するものとします。&lt;br&gt;
旧データ基盤は AWS 上で構築されており、アーキテクチャについて簡単に挙げると&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;storage: S3&lt;/li&gt;
&lt;li&gt;ETL: Glue Job, Athena&lt;/li&gt;
&lt;li&gt;SQL engine: Athena&lt;/li&gt;
&lt;li&gt;workflow orchestration: MWAA&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;のようになっていました。&lt;/p&gt;
&lt;p&gt;旧データ基盤の開発・運用側 (データエンジニア) としても、また社内の利用者側としてもいろいろと問題が挙がってきてはいました。&lt;br&gt;
しかしそれをうまく集約・言語化できていないという状況でした。&lt;br&gt;
そんな中でエライ人の鶴の一声で移行しようぜ！ということになり、データ基盤の移行を検討することに相成りました。&lt;/p&gt;
&lt;h2 id=&#34;移行計画を考えるにあたり&#34;&gt;移行計画を考えるにあたり&lt;/h2&gt;
&lt;h3 id=&#34;まず考えたこと&#34;&gt;まず考えたこと&lt;/h3&gt;
&lt;p&gt;データ基盤の移行は組織におけるデータマネジメントにおいて重要な位置づけとなるはず。&lt;br&gt;
したがって単なる技術スタックの置き換えというスコープで考えるのはもったいないです。&lt;br&gt;
組織のデータマネジメントの未来を想定して、戦略を持って開発・運用を進めるべきであると考えました。&lt;/p&gt;
&lt;p&gt;そのためにはイシューを明確化しないといけません。&lt;br&gt;
でもどの抽象度レベルで？&lt;/p&gt;
&lt;h3 id=&#34;ボトムアップの戦術策定&#34;&gt;ボトムアップの戦術策定&lt;/h3&gt;
&lt;p&gt;まずは現場感覚、ボトムアップでの課題を明らかにすることを考えました。&lt;br&gt;
本来は後述する戦略レベルから先に考えるべきですが、実際に目に見えている課題があり、取り組みやすかったというところで戦術のレベルから考え始めています。(良し悪しはある)&lt;br&gt;
現状のアーキテクチャと運用では戦略策定への対応が難しいため、せめてそのための地ならしとして今見えている課題に対応できる状態にしたいというのもありました。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
