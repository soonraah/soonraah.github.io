[{"content":"「データレイク」という言葉は使う人によって異なった意味があるように感じており、気になっていた。\nこのポストではアーキテクチャ目線でのデータレイクと内容物目線でのデータレイクの違いについて書いてみる。\n便宜上前者を「データレイク」、後者を「データレイク層」と呼ぶことにする。\nアーキテクチャ目線の「データレイク」 「データレイク」については以前こちらのポストで書いたのでここでは詳しく触れない。\n詳細はリンク先を見ていただきたい。\nここでキーとなるのが、\n  加工前データや非構造化データを含むあらゆるデータを保存     一元的なデータ管理   という部分だ。\nあらゆるデータを一元的に管理するという思想であり、これができるアーキテクチャがデータレイクということだ。\n例えば AWS や Azure のドキュメントを見るとデータレイクの中が zone に分けられており、生データを保持する raw zone や加工されたデータを置いておく curated zone などがある。\n(zone の命名にもいくつかの流派があるようだ…)\n Reference architecture - Data Analytics Lens Data lake zones and containers - Cloud Adoption Framework | Microsoft Docs  次の Robinhood 社の例でもデータレイク中に生データとその派生データが存在している。\n Fresher Data Lake on AWS S3 | by Balaji Varadarajan | Robinhood  内容物目線の「データレイク層」 一方でデータレイクには生データのみを置くべき、という考えもある。\n 　本書におけるデータレイク（DataLake）層とは、元のデータをコピーして、1つのシステムに集約したものを指します。 データソース（＝水源）から流れてきたデータを蓄える場所なのでレイク（湖）と呼びます。\nECサイトの注文履歴データを、分析用DBにコピーしている場合、それがデータレイクと言えます。データレイクのデータは、データソースと一対一の関係にあります。何も加工していない、ただのコピーだからです。\n何も加工していない、ただのコピーであることが重要です。仮にデータの中身に誤りがあったとしても、修正や加工をせず、そのまま集約しましょう。\n\u0026ndash; ゆずたそ,渡部 徹太郎,伊藤 徹郎. 実践的データ基盤への処方箋〜 ビジネス価値創出のためのデータ・システム・ヒトのノウハウ (Japanese Edition) (pp.57-58). Kindle 版. こちらの書籍にならってこのポストではこれを「データレイク層」と呼ぶことにする。\nこの考え方では生データの「データレイク層」の他に加工されたデータを置くための「DWH 層」「データマート層」がある。\n本書においてはアーキテクチャというよりは中に何を入れるかで「データレイク層」が規定される。\nこの「データレイク層」の考えは日本企業でよく見かける気がしている。(が、私が知らないだけで海外事例もあるかもしれない)\n以下はその例。\n 分析者から見た使いにくいデータ基盤の話 | リクルート　メンバーズブログ データの民主化を目指して ~ データ基盤ができるまで ~ - LIFULL Creators Blog  「データレイク」と「データレイク層」の比較 「データレイク」も「データレイク層」もやっていることは同じで、ただ何を「データレイク (層)」と呼んでいるかが違っている。\nどちらも生データ、加工データ等を zone や層として分けて管理する。\n以下のようなニュアンスの違いがあると認識している。\n    データレイク データレイク層     内容物 生データ、加工データ 生データのみ   アーキテクチャ オブジェクトストレージ等で一元的 データレイク層と DWH 層は別でもよい   使われている場所 海外 国内？    個人的には「データレイク層」は「raw data 層」というような命名の方が混乱を避けつつ実を表しておりいいのではという感じがする。\n(つまり raw zone ですね…)\n一方で「データレイク層」と呼びたい気持ちもわかる。\nまとめ 誰かが「データレイク」についてしゃべっているときはどちらの「データレイク」のことを言っているのか、気をつけた方がよい。\nもっと言うと世の中にはまた別の定義もあるかもしれない。\n私がこれまで一緒に仕事をしたエンジニアの中でも優秀な人たちは言葉の定義に敏感な人が多かった。\nこういったところ気をつけていきたい。\n","permalink":"https://soonraah.github.io/posts/data-lake-and-data-lake-layer/","summary":"「データレイク」という言葉は使う人によって異なった意味があるように感じており、気になっていた。\nこのポストではアーキテクチャ目線でのデータレイクと内容物目線でのデータレイクの違いについて書いてみる。\n便宜上前者を「データレイク」、後者を「データレイク層」と呼ぶことにする。\nアーキテクチャ目線の「データレイク」 「データレイク」については以前こちらのポストで書いたのでここでは詳しく触れない。\n詳細はリンク先を見ていただきたい。\nここでキーとなるのが、\n  加工前データや非構造化データを含むあらゆるデータを保存     一元的なデータ管理   という部分だ。\nあらゆるデータを一元的に管理するという思想であり、これができるアーキテクチャがデータレイクということだ。\n例えば AWS や Azure のドキュメントを見るとデータレイクの中が zone に分けられており、生データを保持する raw zone や加工されたデータを置いておく curated zone などがある。\n(zone の命名にもいくつかの流派があるようだ…)\n Reference architecture - Data Analytics Lens Data lake zones and containers - Cloud Adoption Framework | Microsoft Docs  次の Robinhood 社の例でもデータレイク中に生データとその派生データが存在している。\n Fresher Data Lake on AWS S3 | by Balaji Varadarajan | Robinhood  内容物目線の「データレイク層」 一方でデータレイクには生データのみを置くべき、という考えもある。","title":"「データレイク」と「データレイク層」"},{"content":"ポエムです。\n事業フェーズごとのデータサイエンティストの役割 まずはこちらの発表。\n 事業立ち上げにデータサイエンティストは必要なのか？ | CA BASE NEXT  とても納得できる内容だった。\n一部抜き出して要約すると\n 事業の立ち上げフェーズ  データがまだなかったり、整備されていない状態 データサイエンスによる改善がしにくい   事業のグロースフェーズ  大規模なデータが使える状態 データサイエンスによる改善がやりやすい    とのこと。異論はない。\nでは事業が立ち上がり、グロースが落ち着いたその後の成熟フェーズではどうなのだろうかという話。\n成熟フェーズにおける改善の難しさ 端的に言うと成熟フェーズでは ML によるさらなる改善は困難になってくると思う。\nここで言う成熟フェーズにおいてはプロダクトの進化とともに機械学習もそれなりに適用されてきたものとする。\n成熟フェーズということで既存の ML モデル、特にビジネスインパクトが大きい箇所はこれまでいろいろな改善が重ねられてきている。\nそのモデルの精度をさらに上げるとなると、より高度なアルゴリズム、より複雑なデータ等を扱う必要がある。\nしかし技術的によっぽど大きなブレークスルーがない限りは精度の改善幅はグロースフェーズよりもかなり小さいものとなるだろう。\n精度が上がれば上がるほど、次の1%を上げるためのコストは大きくなっていく。\n改善が進むほどに次の改善業務は困難になっていく。\n(蛇足だがある程度大きな組織でなければ高度で state-of-the-art な ML アルゴリズムは運用しない方がいいと考えている)\nでは既存ではない新しい適用箇所に ML を使えばいいのではとなるかもしれない。\nしかしやはりそれも難しい。\nビジネスインパクトが大きく、かつわかりやすい適用箇所にはおそらくすでに ML が適用されているからだ。\nその状態から更によい適用箇所を見つけるには深いドメイン知識が必要になったりする。\nという感じでいわゆるキラキラした「ML でビジネスをドライブ！」みたいなことは成熟フェーズでは難しいことが多いのではないか。\nしかしデータサイエンティストにやることがないわけではない。\n成熟フェーズで何ができるか ぱっと思いつくのは次のような仕事。\n データドリブンな施策の立案・評価  これは事業フェーズ問わずあるべき ドメイン知識が必要   ML エンジニアリング  パイプラインの改善や属人性をなくすお仕事   ML モデルの受動的なメンテナンス  精度が変化したときの調査 内部的・外部的要因によるデータの変化への対応   やっぱり ML モデルの精度改善  成熟フェーズということでビジネスもスケールしていれば 0.1% の精度改善でも売上的なインパクトは大きいかもしれない    いわゆる狭義のデータサイエンスではなく、ドメイン知識であったりアナリストやエンジニア的な視点が絡んだ仕事が増えてくる。\nよくある「ML だけじゃなく◯◯もできると強いよね」みたいな話になってしまった。\nおわりに …という話が少し前に Twitter で知人との話題に上がった。\n若者が歴史的にいろんな人が改善に取り組んできた ML モデルの改善にアサインされている、というのが近いところで観測されたのでたいへんそうだなあと思いつつこの件を思い出したので書いてみた。\nここまで書いて思ったけど、成熟フェーズでキラキラしたことがやりづらくなるのはデータサイエンティストだけじゃないよな。\nでも狭義のデータサイエンスのスキルは特に、事業の存続期間と比べて大きく貢献できる期間が短いのかもしれない、と個人的には考えている。\n成熟フェーズでは高度なスキル、高い賃金に見合ったプロダクトへの貢献が得にくくなっていくのではないだろうろうか。\nでも反論もいっぱいありそうな気はします。\n「ML でビジネスインパクトどっかんどっかんやで！！」みたいな仕事をしたい人はそれなりの頻度で事業部を移る or 転職するというのが賢い動きになるんでしょうかね。\n","permalink":"https://soonraah.github.io/posts/ds-in-maturation-phase/","summary":"ポエムです。\n事業フェーズごとのデータサイエンティストの役割 まずはこちらの発表。\n 事業立ち上げにデータサイエンティストは必要なのか？ | CA BASE NEXT  とても納得できる内容だった。\n一部抜き出して要約すると\n 事業の立ち上げフェーズ  データがまだなかったり、整備されていない状態 データサイエンスによる改善がしにくい   事業のグロースフェーズ  大規模なデータが使える状態 データサイエンスによる改善がやりやすい    とのこと。異論はない。\nでは事業が立ち上がり、グロースが落ち着いたその後の成熟フェーズではどうなのだろうかという話。\n成熟フェーズにおける改善の難しさ 端的に言うと成熟フェーズでは ML によるさらなる改善は困難になってくると思う。\nここで言う成熟フェーズにおいてはプロダクトの進化とともに機械学習もそれなりに適用されてきたものとする。\n成熟フェーズということで既存の ML モデル、特にビジネスインパクトが大きい箇所はこれまでいろいろな改善が重ねられてきている。\nそのモデルの精度をさらに上げるとなると、より高度なアルゴリズム、より複雑なデータ等を扱う必要がある。\nしかし技術的によっぽど大きなブレークスルーがない限りは精度の改善幅はグロースフェーズよりもかなり小さいものとなるだろう。\n精度が上がれば上がるほど、次の1%を上げるためのコストは大きくなっていく。\n改善が進むほどに次の改善業務は困難になっていく。\n(蛇足だがある程度大きな組織でなければ高度で state-of-the-art な ML アルゴリズムは運用しない方がいいと考えている)\nでは既存ではない新しい適用箇所に ML を使えばいいのではとなるかもしれない。\nしかしやはりそれも難しい。\nビジネスインパクトが大きく、かつわかりやすい適用箇所にはおそらくすでに ML が適用されているからだ。\nその状態から更によい適用箇所を見つけるには深いドメイン知識が必要になったりする。\nという感じでいわゆるキラキラした「ML でビジネスをドライブ！」みたいなことは成熟フェーズでは難しいことが多いのではないか。\nしかしデータサイエンティストにやることがないわけではない。\n成熟フェーズで何ができるか ぱっと思いつくのは次のような仕事。\n データドリブンな施策の立案・評価  これは事業フェーズ問わずあるべき ドメイン知識が必要   ML エンジニアリング  パイプラインの改善や属人性をなくすお仕事   ML モデルの受動的なメンテナンス  精度が変化したときの調査 内部的・外部的要因によるデータの変化への対応   やっぱり ML モデルの精度改善  成熟フェーズということでビジネスもスケールしていれば 0.","title":"成熟フェーズの事業におけるデータサイエンティスト"},{"content":"ストリーム処理のフレームワークが備える backpressure という機能がある。\nこのポストでは Apache Flink の backpressure について調べたことを記載する。\nBackpressure の目的 backpressure はストリーム処理システムにおける負荷管理の仕組みの一つ。\n一時的な入力データ量の増大に対応する。\nインターネットユーザの行動履歴やセンサーデータなどは常に一定量のデータが流れているわけではなく、単位時間あたりのデータ量は常に変動している。\n一時的にスパイクしてデータ量が増大するようなことも起こりうる。\n複数の operator からなる dataflow graph により構成されるストリーム処理システムにおいては、処理スピードのボトルネックとなる operator が存在する。\n一時的に入力データ量が増えてボトルネックの operator の処理速度を上回ってしまった場合に、データの取りこぼしが発生するのを防ぐのが backpressure の目的となる。\nBackpressure の仕組み Buffer-based ここでは以前のブログでも紹介した、ストリーム処理で必要とされる機能について書かれた Fragkoulis et al. 1 を引用して一般論としての backpressure について述べたい。\n上流／下流の operator をそれぞれ producer, consumer とする。\nproducer, consumer (それらの subtask と言ってもいいかも) がそれぞれ異なる物理マシンに deploy されているケースが Figure 12b となる。\n各 subtask は input と output の buffer を持っており、\n producer は処理結果を output buffer に書き出す TCP 等の物理的な接続でデータを送信 consumer 側の output buffer にデータを格納 consumer がそれを読み込んで処理する  というような流れになる。\nbuffer はマシンごとの buffer pool で管理されており、input/output で buffer が必要となった場合はこの buffer pool に buffer が要求される。\nここで赤い丸で示されている subtask の処理速度が入力データの速度よりも遅かったとする。\nconsumer 側の input buffer の待機列が長くなり、さらにこの状況が続くとやがて buffer pool の buffer を使い果たす。\nすると producer 側から新しいデータを送信することができなくなり、producer 側の output buffer を使い始める。\n同様に producer 側でも output buffer を追加できなくなると producer は処理を待たざるを得なくなる。\nこのようにボトルネックとなる operator から上流に向かって buffer が埋まっていくことになる。\nこれが backpressure だ。\ndataflow graph を構成する operator 全体、物理的にはそれらのマシンのメモリにより一時的なデータ量の増加を buffer するという形になる。\nFigure 2a は producer と consumer が同じマシンにある場合の例であり、この場合はネットワークを介さずに buffer 上でやりとりができる。\nボトルネックがあれば同様に buffer を使い切り、それが上流に向かって伝播していくことになる。\nCredit-based 上記のような buffer-based な流量制御の場合、複数の channel が同じ下流のマシンにデータを送信する場合、同じ TCP socket を使うことになる。\n下流のある一部の channel が遅延して backpressure が働くと (data skew) 上流のすべての channel が影響を受けるという問題がある。\nこれを解決するのが credit-based な流量制御であり、Figure 13 はそれを示したものである。\nデータ送信を試みる前に credit という形で consumer 側から producer 側に buffer 状況を送信する。\nある channel で consumer の buffer がなくなると credit=0 となり、producer 側でその channel に送信できなるなり backpressure が発生する。\n一方、並列する他の channel には backpressure はかからず、TCP socket は利用可能となっている。\nFlink の Backpressure 残念ながら Flink 公式のドキュメントには backpressure についてあまり詳しく説明されていない。\nモニタリングについて書かれているのみである。\n Monitoring Back Pressure  backpressure が起こっているかどうかは web UI 上から確認できるとのことだ。\n一方で Flink のブログや Alibaba のブログ等では内部的な挙動が詳しく書かれている。\n Analysis of Network Flow Control and Back Pressure: Flink Advanced Tutorials A Deep-Dive into Flink\u0026rsquo;s Network Stack  前述のように buffer-based な仕組みの上に credit-based な挙動が採用されていることがわかる。\nここで Flink の設定の中で backpressure に影響がありそうなものを見ておく。\n taskmanager.network.memory.buffers-per-channel  こちらは channel 単位の排他的な buffer の数を指定する。\nskew 発生時において、この値が大きすぎると遅延している channel 以外で buffer が遊ぶことになり、逆に小さすぎると遅延していない channel でも処理が滞りやすくなると考えられる。\n taskmanager.network.memory.floating-buffers-per-gate  すべての input channel で共有される floating buffer の数。\nこの部分で skew をある程度吸収しようとするのだろう。\n taskmanager.network.memory.max-buffers-per-channel  channel ごとの最大 buffer 数。\n最大 buffer 数を制限することにより skew 時に backpressure が起こりやすくなり、結果として checkpoint のアラインメントを速くする効果があるとのこと。\n最大 buffer 数の制限がゆるいとボトルネックの operator で長い待ち行列を待つ必要があり、checkpoint barrier が移動するのに時間がかかってしまうということだろうか。\n web.backpressure.cleanup-interval web.backpressure.delay-between-samples web.backpressure.num-samples web.backpressure.refresh-interval  上の4つは web UI によるモニタリング関連の設定値であり、backpressure 関連の挙動に直接影響を与えるものではない。\n…と書いてみたものの通常はこれらの値をチューニングすることはあまりないのではという印象。\nまとめ Flink の backpressure がどのように働くかがだいたい概観できた。\nそもそもなぜ backpressure を調べたかというと今開発している Flink アプリケーションで checkpoint size が増大し続ける問題があって backpressure の影響を疑っていた。\n結局 backpressure は関係なさそうだな…\n  Fragkoulis, M., Carbone, P., Kalavri, V., \u0026amp; Katsifodimos, A. (2020). A Survey on the Evolution of Stream Processing Systems.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n   ","permalink":"https://soonraah.github.io/posts/backpressure-for-flink/","summary":"ストリーム処理のフレームワークが備える backpressure という機能がある。\nこのポストでは Apache Flink の backpressure について調べたことを記載する。\nBackpressure の目的 backpressure はストリーム処理システムにおける負荷管理の仕組みの一つ。\n一時的な入力データ量の増大に対応する。\nインターネットユーザの行動履歴やセンサーデータなどは常に一定量のデータが流れているわけではなく、単位時間あたりのデータ量は常に変動している。\n一時的にスパイクしてデータ量が増大するようなことも起こりうる。\n複数の operator からなる dataflow graph により構成されるストリーム処理システムにおいては、処理スピードのボトルネックとなる operator が存在する。\n一時的に入力データ量が増えてボトルネックの operator の処理速度を上回ってしまった場合に、データの取りこぼしが発生するのを防ぐのが backpressure の目的となる。\nBackpressure の仕組み Buffer-based ここでは以前のブログでも紹介した、ストリーム処理で必要とされる機能について書かれた Fragkoulis et al. 1 を引用して一般論としての backpressure について述べたい。\n上流／下流の operator をそれぞれ producer, consumer とする。\nproducer, consumer (それらの subtask と言ってもいいかも) がそれぞれ異なる物理マシンに deploy されているケースが Figure 12b となる。\n各 subtask は input と output の buffer を持っており、\n producer は処理結果を output buffer に書き出す TCP 等の物理的な接続でデータを送信 consumer 側の output buffer にデータを格納 consumer がそれを読み込んで処理する  というような流れになる。","title":"Apache Flink の Backpressure の仕組みについて調べた"},{"content":"はじめに 前回のポストではデータレイクとはどういうものかというのを調べた。\n今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。\n以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。\n  大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05）  from NTT DATA Technology \u0026amp; Innovation    Delta Lake Apache Hudi Apache Kudu  これらはすべて論理的なストレージレイヤーを担う。\nこちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。\n当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。\nDelta Lake https://delta.io/\n Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.\n    Delta Lake\n  Delta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。\nDatabricks が作り、2019年4月に v0.1.0 がリリースされたのが最初だ。\n使い方はめちゃ簡単で、dependency を設定した上で Spark で\ndataframe .write .format(\u0026#34;delta\u0026#34;) .save(\u0026#34;/data\u0026#34;) のように読み書きすればよい。\nデータレイク化が進むと多種多様なデータが一元的に管理され、それらデータに対して横断的なクエリを実行できるようになる。\n各データの更新タイミングも様々であり、そのような状況では ACID 特性の中でも特に Isolation (独立性) が問題となってくる。\nSpark を処理エンジンとして使う場合、データソース・読み方によっては isolation level が弱くなってしまうことがあるというのは過去のポストでも述べた。\nおそらくこのことが Delta Lake の開発の強い動機となっているのではないだろうか。\nDelta Lake は最も強い isolation level である \u0026ldquo;serializability\u0026rdquo; を提供する。\nACID transaction の他には schema に合わないデータを弾いたり過去のデータのスナップショットにアクセスしたりなどの機能がある。\nどれもデータレイクの治安を守る方向であり、データスワンプ化に抵抗したいようだ。\nこれらを実現しているのが transaction log という仕組みとのこと。\nDelta Lake は table に対する変更の transaction を atomic な commit という単位に分け、commit ごとに操作を JSON file に書き出していく。\nJSON file には 000000.json, 000001.json のように連番が振られており、2つの application が同時に table を更新するような場合は各 application が次の番号の JSON file を作れるかどうかで衝突を制御している。\nJSON file はずっと蓄積していくため再計算のコストが大きくなっていくが、その時点での table の完全な状態を parquet にした checkpoint file というものを時折出力するという、compaction のようなことも行われる。\n(Delta Lake は parquet 形式のデータ保存を前提としている)\n詳しくは Databricks の blog を参照。\n Diving Into Delta Lake: Unpacking The Transaction Log  Apache Hudi https://hudi.apache.org/\n Hudi brings stream processing to big data, providing fresh data while being an order of magnitude efficient over traditional batch processing.\n    Apache Hudi\n  Apache Hudi で何ができるかを一言で説明するのは難しい。\n簡単にまとめると HDFS や S3 等にある table にリアルタイムに近いデータ取り込みと、処理速度とデータの新鮮さのトレードオフに配慮した読み込みを提供する。\n2016年から Uber が開発をしており、2020年に Apache Software Fundation の top-level project となった。\nデータレイクではあらゆる種類のデータを一元管理するが、その中には当然リアルタイム性の高いデータも含むことになる。\nデータレイク中のリアルタイム性の高いデータについては次のような要求が出てくる。\n table へのデータの取り込みはリアルタイムに近いスピードで細かくやりたい 分析クエリ等の table の読み込みにおけるクエリの速度は速くしたい (例えば列指向形式で保存されたデータの様に) 取り込まれたデータをすぐに読めるようにしたい  Hudi はこれに応えるものとなっている。\nこれらを実現するのが Merge On Read のデータ構造だ。\nHudi の table には Copy On Write と Merge On Read の2種類がある。\nここでは Hudi の肝である後者について触れておきたい。\n  Apache Hudi Merge On Read TablePermalink\n  table に加えられた変更についての情報は timeline に追加される。\n時系列になった変更についてのメタデータのようなものだろうか。\nこの timeline によって snapshot isolation が保証される。\n最初にデータが追加されたときは parquet 等の列指向のフォーマットで保存される。\nその一方でその後のデータの追加・更新については Avro 等の行指向のフォーマットの delta log に記載される。\nここがミソであり、列指向のフォーマットでは1レコードずつなどの細かい追加・更新が高コストになるのでその部分を行指向の delta log にまかせている。\n追加・更新が増えてくると delta log がどんどん長くなってしまうので、あるタイミングで compaction を行って直近までの delta log の変更内容を反映した列指向ファイルを作成する。\nこれを読む方法は2通りある。\nSnapshot Queries では読み取り時に列指向ファイルと行指向の delta log をどちらも読んで merge して最新の結果を返す。\n(これが \u0026ldquo;Merge On Read\u0026rdquo; ということ)\n一方で Read Optimized Queries では直近で compaction が行われた時点での列指向ファイルだけを読み、その時点の結果を返す。\nつまりデータの新鮮さが重要な場合は Snapshot Queries, データの新鮮さよりもクエリの速度を優先したい場合は Read Optimized Queries が有利ということだ。\nこれらはトレードオフとなるので状況に応じて使いわけることになる。\n2通りと述べたが実際はもう1つ、 Incremental Queries というものもある。\nこれはある時点からの差分のみを読み出して処理するというものとなっている。\nevent time と processing time の差があるものを DFS 上に書き出すのに適している。\nちなみに Merge On Read ではないもう1つの table type である Copy On Write は、Merge On Read の構造から delta log を消したものとなっている。\nすなわち書き込み時に常に列指向ファイルの更新がおこり、新しく作り直される。(という意味で \u0026ldquo;Copy On Write\u0026rdquo;)\n書き込みのたびに常に compaction が発生していると言ってもよい。\n更新頻度が低いデータならこちらの table type を使うのが適しているだろう。\nHudi の table は Spark, Hive, Presto 等からクエリすることができる。\n公式ドキュメント的には Spark 推しの感がある。\nApache Kudu https://kudu.apache.org/\n Apache Kudu is an open source distributed data storage engine that makes fast analytics on fast and changing data easy.\n Apache Kudu はストリーム処理などの追加・更新の速いデータをすぐに分析できるようにすることを目的としている。\nCloudera 社の内部プロジェクトとして始まり、2016年から Apache Software Foundation の top-level project となった。\nKudu の目指すところは Hudi とよく似ているが、次の点で異なっている。\n Kudu は OLTP つまり小さなデータアクセスを大量にさばくのにも向いている Kudu は Hudi の incremental queries のようなことはできない Kudu は HDFS や S3 のような cloud storage 上にデータを持つのでははく、Raft の合意で制御された独自のサーバー群を要する  Kudu では各 table のデータが tablet という単位により構成される。\ntablet はいわゆる partition によく似た概念となっており、key の範囲による分割、ハッシュ値による分割、またはその組み合わせにより分割される。\n1つの tablet は複数の tablet server に replication されており、そのうちの1つが leader として振る舞い書き込みを受け付ける。\nleader と follower の関係は Raft 合意アルゴリズム により管理される。\n一方で master server では tablet のメタデータ等が管理されており、client はまず master と通信することになる。\n  Apache Kudu Architectural Overview\n  読み書きに関する内部的な振る舞いについては Cloudera 社のブログ記事 (日本語訳) が参考になる。\n  CLOUDERA Blog Apache Kudu Read \u0026amp; Write Paths\n  client 側からはおそらく見えないが、内部的には\n メモリ上の MemRowSet, DeltaMemStore 列指向の base data file 差分を表す delta file (UNDO/REDO records)  の3段の構成になっている。 (それと WAL も)\ndelta file を使うのは Hudi 等と同じだが一度メモリ上で変更を受けるという段があるのが特徴的だ。\n挿入はある tablet のメモリ上の MemRowSet にまず追加される。\nまた任意の timestamp の snapshot を得るために、MemRowSet 上のデータへの更新・削除はの差分は REDO records へと保存される。\nMemRowSet がいっぱいになると最新の状態が列指向の base data file へ書き出され、更新・削除前の状態は UNDO records へと書き出される。\n読み取りのときは MemRowSet とディスク上の base data file + delta file をスキャンすることになる。\nしたがって delta file の数やサイズが大きくなると遅くなる。\nやはりここでも compaction が必要となってくる。\nこのように memory を使うため server が必要であり、データレイクでよく言われるコンピューティングとストレージの分離が完全にはできない。\nCloudera 的と言えるかもしれない。\n読み取りには2つのモードがある。\nデフォルトは READ_LATEST であり、名前のとおり snapshot をとってすぐにデータを読むとのこと。\nREAD_LATEST は比較的弱い read committed の isolation level を示す。\nこれはおそらく Raft や WAL を経て変更が可視になるまでに時間を要するためだ。\nread committed は実用では問題が起こることもある。(ex. Spark クエリの分離レベル)\nもう一つは READ_AT_SNAPSHOT であり、明示的 (推奨) または暗黙的に読み取る対象の timestamp を指定する。\n書き込みの operation が完了し、その timestamp までの変更が安全に読めるようになるまで待って結果を返すことになる。\nisolation level はおそらく最も強い serializable となっている。\nしたがって2つのモードはデータの新鮮さと isolation level (consistency も？) のトレードオフとなっている。\nまとめ Delta Lake, Apache Hudi, Apache Kudu の3つを見比べて見てとても面白いのは、課題感は少しずつ違っているのにどれも列指向ファイル + 差分ファイル (delta file) というアーキテクチャを中心に置いているということだ。\nDelta Lake では transaction を重視している一方で Hudi ではリアルタイムデータをすぐに分析することを目指し、かつ Kudu ではさらに OLTP もサポートする。\nおそらく導入は Delta Lake が最も簡単であり、Kudu に至っては server を用意する必要があるのでハードルが1段高い。\n同じアーキテクチャということもあり、例えば time travel の機能などは共通して提供されている。\nバランス的には Apache Hudi がよさそうだが、どれを使うべきかは work load 次第だろう。\nhourly のデータ更新に慣れすぎていて fast data - fast analysis の需要に気づけないといこともよくありそう。\n","permalink":"https://soonraah.github.io/posts/oss-for-data-lake/","summary":"はじめに 前回のポストではデータレイクとはどういうものかというのを調べた。\n今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。\n以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。\n  大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05）  from NTT DATA Technology \u0026amp; Innovation    Delta Lake Apache Hudi Apache Kudu  これらはすべて論理的なストレージレイヤーを担う。\nこちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。\n当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。\nDelta Lake https://delta.io/\n Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.\n    Delta Lake\n  Delta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。","title":"データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu"},{"content":"最近よく聞かれるようになった「データレイク」という概念にあまりついていけていなかったため、いまさらながらざっと調べてみた。\nデータレイクとは Wikipedia によると最初にこの言葉を使ったのは Pentaho 社の CTO である James Dixon らしい。\nその時の彼のブログ (10年前…) を読むと、既にあったデータマートに対して\n  Only a subset of the attributes are examined, so only pre-determined questions can be answered. The data is aggregated so visibility into the lowest levels is lost\n\u0026ndash;Pentaho, Hadoop, and Data Lakes - James Dixon’s Blog   というような問題意識からデータレイクというコンセプトを提案したようだ。\n最近？のデータレイクについてはベンダー等の記事が参考になる。\n データレイクとは - AWS データレイクとは？ - talend データレイクとは？データレイクの落とし穴と効果 - Informatica  書籍だと『AWSではじめるデータレイク: クラウドによる統合型データリポジトリ構築入門』がいいだろうか。\nデータレイクの概要と AWS が考えている構築・運用がざっとわかる。\nAmazon で検索した限りだと現時点でタイトルに「データレイク」を含む和書はこれのみだった。\n上に挙げたような文献ではデータレイクはデータウェアハウスとの対比という形でよく語られている。\n共通している内容は概ね以下のとおり。\n 加工前データや非構造化データを含むあらゆるデータを保存  データウェアハウスでは加工され構造化されたデータのみを含む データレイクでは加工前の半構造化、非構造化データも含む ex. ログ、画像、音声   Scheme on Read  書き込み時にデータの構造を決める (Scheme on Write) のではなく、使用時に決める なので詳細なスキーマ設計なしに様々なデータを置いていくことができる   一元的なデータ管理  データがサイロ化しないよう、組織全体のデータを一元的に管理 なのでデータへのアクセス権の管理が重要になる   多様な分析用途に対応  データウェアハウスはビジネスアナリストが決まったレポートを出すために使われる データレイクでは機械学習など更に高度な分析をデータサイエンティストが行う    機械学習の普及がデータレイクを強く後押ししているように思う。\n機械学習をやっていれば様々な特徴量を扱いたいというのは自然な欲求であり、データレイクはそれを実現する。\nまた、クラウドベンダーは以下のような点も強調している。\n 従量課金のクラウドストレージによるメリット  運用開始前の時点でどんな生データがどれだけ来るか、見積もるのはとても難しい 従量課金のクラウドストレージ (Amazon S3, Google Cloud Storage, etc.) なら必要なときに必要なサイズだけ追加できる 安価なクラウドストレージの普及がデータレイクを後押し   ストレージとコンピューティングの分離  処理側のリソースを処理内容に応じて確保できる 処理側のバージョンアップや変更が容易 (オンプレ Hadoop クラスタのバージョンアップの辛さを思い出してください)    なるほどです。\n沼にはまらないために データレイクとの対比でデータスワンプ (沼) という言葉がある。\n以下の説明がわかりやすいだろうか。\n データスワンプ（Data Swamp）とは、データの沼地（Swamp）という意味です。これの対比語としてデータレイク（Data Lake：データの湖）があります。沼には、いろんな魚が住んでいるかもしれませんが、水が濁っているため、どこにどんな魚がいるか全く見えません。また、全く見えないため「魚が住んでいないんじゃないか」とも思い、魚を捕るのも諦めてしまいがちです。その一方で、湖は、水が澄んでいるため、魚を見ることができ「おっ！魚がいるな。何とか捕まえてみよう」と思えます。\nこの沼と湖にいる魚を、データの例えとして使っているのが、データスワンプと、データレイクという言葉です。\n\u0026ndash; データスワンプ - Realize データスワンプにならないようにということについては次の資料が参考になる。\n The difference between a data swamp and a data lake? 5 signs Metadata Separates Data Lakes From Data Swamps From Data-Swamp to Data-Lake on AWS (Part 1)  すごくざっくりまとめるとデータレイクの構築・運用に当たって次の点に配慮するとよい。\n メタデータ、カタログの整備  どんなに優れたデータレイクを構築したとしても、利用者がどこに何のデータがあるかわからないと意味がない 多種のデータ資産を一元的に管理するデータレイクにおいて目的のデータを見つけるために必要な機能   データガバナンス  誰がどのデータに対して何ができるのか 統制をきつくしすぎると自由度が減るため、これらのバランスを考慮しないといけない   その他、常識的な運用  クラウドベンダーが推進するデータレイク クラウドベンダーがどのようなデータレイクを考えているかというのも見ておく。\nGCP   Google Cloud データレイクとしての Cloud Storage\n  データレイクとしての Cloud Storage というドキュメントに GCP が考えるデータレイクの構成が記載されている。\n構成としては以下のとおり。\n 保存: Cloud Storage 変換: Cloud Dataproc, Cloud Dataprep, Cloud Dataflow 分析: BigQuery, Cloud ML Engine, Cloud Datalab, etc.  データ保存のストレージとして、みんな大好きな BigQuery ではなく Cloud Storage を想定しているのは非構造化データを扱うためだろう。\nいわゆるリレーショナル的なものより Cloud Storage や S3 のようなオブジェクトストレージの方がこの要件に適している。\nもちろん Cloud Storage に保存された生データを処理してから BigQuery のデータウェアハウスに再びつっこむのも悪くない。\n変換や分析には様々なサービスが使えるし、今後も幅は広がっていくと考えられる。\nクラウドにおけるストレージとコンピューティングの分離の恩恵と言えるだろう。\n現時点ではこのドキュメントにはカタログ化についての記述はないが、GCP には Data Catalog というサービスがあり Cloud Storage のメタデータを扱えるようだ。\nAWS   AWS Sample AWS data lake platform\n  前述の書籍『AWSではじめるデータレイク: クラウドによる統合型データリポジトリ構築入門』に加え、Building Big Data Storage Solutions (Data Lakes) for Maximum Flexibility も読んでおくとよい。\n 保存: Amazon S3 (, AWS Glue Data Catalog) 変換: AWS Glue ETL, Amazon EMR, AWS Lambda, etc. 分析: Amazon Athena, Amazon Redshift Spectrum, Amazon ML, etc.  やはり中心となるのは S3 だ。\nGCP も AWS もストレージのコストメリットを推している。\nGlue Data Catalog がメタデータを管理する。\nGCP 同様、変換・分析には様々なオプションがある。\nBuilding Big Data Storage Solutions (Data Lakes) for Maximum Flexibility には記載がないのだが、AWS Lake Formation というサービスもある。\n上に挙げたようなサービスの上に一枚被せて、データレイクとして運用しやすくするといったようなものらしい。\n特に権限管理的な意味合いが強いように思う。\n組織のデータを一元的に管理するデータレイクには様々な部署・役割の人からのアクセスがある。\nどのデータを誰が扱えるのか、複数のサービスを横断して IAM で権限を管理のはかなりきつそうな印象でそういうのを楽にしてくれるのだろう。\nまとめ データレイクの概観やベンダーが考えていることがわかった。\n普段業務で使っているということもあり、全体的に AWS 寄りになってしまったように思うのでその点をご留意していただきたい。\nこの後はデータレイク関連の OSS について調べておきたいところ。\n","permalink":"https://soonraah.github.io/posts/what-is-a-data-lake/","summary":"最近よく聞かれるようになった「データレイク」という概念にあまりついていけていなかったため、いまさらながらざっと調べてみた。\nデータレイクとは Wikipedia によると最初にこの言葉を使ったのは Pentaho 社の CTO である James Dixon らしい。\nその時の彼のブログ (10年前…) を読むと、既にあったデータマートに対して\n  Only a subset of the attributes are examined, so only pre-determined questions can be answered. The data is aggregated so visibility into the lowest levels is lost\n\u0026ndash;Pentaho, Hadoop, and Data Lakes - James Dixon’s Blog   というような問題意識からデータレイクというコンセプトを提案したようだ。\n最近？のデータレイクについてはベンダー等の記事が参考になる。\n データレイクとは - AWS データレイクとは？ - talend データレイクとは？データレイクの落とし穴と効果 - Informatica  書籍だと『AWSではじめるデータレイク: クラウドによる統合型データリポジトリ構築入門』がいいだろうか。\nデータレイクの概要と AWS が考えている構築・運用がざっとわかる。","title":"いまさらながらのデータレイク"},{"content":"ストリーム処理における CSV ファイルの読み込み Apache Flink は unbounded なストリームデータを処理するためのフレームワークだ。\nしかし現実的な application を開発する場合、ストリームデータに加えて static なファイルや DB 等を読み込みたいこともある。\nstar schema における dimension table 的な情報をストリームに結合したい場合 等が考えられる。\nこのポストでは Flink で DataStream API ベースでの実装において CSV ファイルを読むことを考える。\nFlink は現時点の stable である v1.11 を想定。\nCSV ファイルを読む方法 DataStream API ベースの実装で CSV ファイルを読むには StreamExecutionEnvironment のメソッドである readFile() を使う。\noverload された同名のメソッドがいくつか存在するが、次の2つの引数が特に重要だろう。\nまず1つめは FileInputFormat\u0026lt;OUT\u0026gt; inputFormat であり、こちらは data stream の生成に用いる入力フォーマットを指定する。\nおそらく最も一般的なのが TextInputFormat だと思われる。\nもちろん単なる text として CSV ファイルを読み込み、後続の処理で各レコードを parse することも可能だが CSV 用の入力フォーマットがいくつか用意されているようだ。\n PojoCsvInputFormat RowCsvInputFormat TupleCsvInputFormat  なんとなく名前でわかると思うが、それぞれ readFile() の結果として返される DataStreamSource が内包する型が異なる。\nこれについては後述の実験にて確認する。\n次に FileProcessingMode watchType も見ておきたい。\nこの引数ではデータソースの監視についてのモードを指定する。\nモードは2つある。\n FileProcessingMode.PROCESS_CONTINUOUSLY  対象のファイルが更新され、その更新に追随する必要がある場合に利用 指定のインターバルでファイルの更新をチェック 更新があった場合はファイル全体を読む   FileProcessingMode.PROCESS_ONCE  対象のファイルの更新がない、更新について考えない場合に利用 最初に一度だけファイルを読む    おそらく多くの場合は前者が必要になるのではないだろうか。\n利用にあたっては更新があった場合にファイル全体が読まれるということに注意が必要だ。\n例えばファイル末尾にレコードを1件追加するような更新であったとしても、全レコードが再度ストリームに流されるということである。\n詳しくは ドキュメント を参照。\nこれはファイル全体で1つの atomic な単位だとみなされているものと思われる。\nレコード単位で処理していくストリーム処理にファイルというバルクな単位のデータを流そうとしているのでこうなってしまう。\nそう考えるとやはり static なファイルのデータは dimension table として情報を付加するような、ストリームの本川に合流する支川のような使い方が想定されているのだろう。\nちなみに CsvReader というものもあるが、こちらは DataSet API、つまりバッチ処理向けのようなので今回は扱わない。\n実験 実際にコードを書いて readFile() で CSV を読んでみる。\nここでは PojoCsvInputFormat と TupleCsvInputFormat を切り替えられるようにした。\nコード package com.example.entry import org.apache.flink.api.common.typeinfo.BasicTypeInfo import org.apache.flink.api.java.io.{PojoCsvInputFormat, TupleCsvInputFormat} import org.apache.flink.api.java.tuple.Tuple3 import org.apache.flink.api.java.typeutils.{PojoField, PojoTypeInfo, TupleTypeInfo} import org.apache.flink.core.fs.Path import org.apache.flink.streaming.api.functions.source.FileProcessingMode import org.apache.flink.streaming.api.scala.{StreamExecutionEnvironment, createTypeInformation} import scala.collection.JavaConverters._ import scala.concurrent.duration._ /** * The experiment to read CSV file by Flink. * It reads CSV file as POJOs or tuples and just prints on console. */ object ReadCsvFileExperimentRunner { /** POJO */ case class Company(name: String, ticker: String, numEmployees: Int) /** Tuple */ type CompanyTuple = Tuple3[String, String, Int] def main(args: Array[String]): Unit = { val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(2) val companiesFilePath = \u0026#34;data/companies.csv\u0026#34; val interval = 10.seconds args.headOption match { case None | Some(\u0026#34;pojo\u0026#34;) =\u0026gt; val inputFormat = createPojoCsvInputFormat(companiesFilePath) env .readFile(inputFormat, companiesFilePath, FileProcessingMode.PROCESS_CONTINUOUSLY, interval.toMillis) .map(_.toString) .print() case Some(\u0026#34;tuple\u0026#34;) =\u0026gt; val inputFormat = createTupleCsvInputFormat(companiesFilePath) env .readFile(inputFormat, companiesFilePath, FileProcessingMode.PROCESS_CONTINUOUSLY, interval.toMillis) .map(_.toString) .print() case _ =\u0026gt; throw new RuntimeException(s\u0026#34;Unsupported input format: ${args(0)}\u0026#34;) } env.execute() } private def createPojoCsvInputFormat(csvFilePath: String): PojoCsvInputFormat[Company] = { val clazz = classOf[Company] val pojoFields = Seq( new PojoField(clazz.getDeclaredField(\u0026#34;name\u0026#34;), BasicTypeInfo.STRING_TYPE_INFO), new PojoField(clazz.getDeclaredField(\u0026#34;ticker\u0026#34;), BasicTypeInfo.STRING_TYPE_INFO), new PojoField(clazz.getDeclaredField(\u0026#34;numEmployees\u0026#34;), BasicTypeInfo.INT_TYPE_INFO) ).asJava val pojoTypeInfo = new PojoTypeInfo[Company](clazz, pojoFields) val fieldNames = Array(\u0026#34;name\u0026#34;, \u0026#34;ticker\u0026#34;, \u0026#34;numEmployees\u0026#34;) val inputFormat = new PojoCsvInputFormat[Company](new Path(csvFilePath), pojoTypeInfo, fieldNames) inputFormat.setSkipFirstLineAsHeader(true) inputFormat } private def createTupleCsvInputFormat(csvFilePath: String): TupleCsvInputFormat[CompanyTuple] = { val types = Seq( BasicTypeInfo.STRING_TYPE_INFO, BasicTypeInfo.STRING_TYPE_INFO, BasicTypeInfo.INT_TYPE_INFO ) val tupleTypeInfo = new TupleTypeInfo[CompanyTuple](classOf[CompanyTuple], types: _*) val inputFormat = new TupleCsvInputFormat[CompanyTuple](new Path(csvFilePath), tupleTypeInfo) inputFormat.setSkipFirstLineAsHeader(true) inputFormat } } ポイントは POJO 版も tuple 版も型情報を作ってやる必要があるということだ。\nそれぞれ PojoTypeInfo, TupleTypeInfo を用意してやる必要があり、これがやや癖があって面倒。\nあるフィールドを数値として読むことは可能だが、日付の parse のようなことはできないようである。\nというのを考えると TextInputFormat で読んで自分で parse するのと比べてあまりうれしくないような…\nデータ 実験用のデータとして会社情報を示す簡単な CSV ファイルを適当に作って data/companies.csv に配置。\nname,ticker,num_employees Alphabet Inc,GOOG,98771 Apple Inc,AAPL,147000 Facebook Inc,FB,49942 Amazon.com Inc,AMZN,798000 実行 まずは POJO 版を実行してみた。\nプログラムが起動するとすぐに以下が出力された。\n[info] running com.example.entry.ReadCsvFileExperimentRunner pojo 2\u0026gt; Company(Alphabet Inc,GOOG,98771) 1\u0026gt; Company(Facebook Inc,FB,49942) 2\u0026gt; Company(Apple Inc,AAPL,147000) 1\u0026gt; Company(Amazon.com Inc,AMZN,798000) Company インスタンスとして CSV ファイルの内容を取得できている。\nプログラムは止まっていないが CSV ファイルの内容を一通り吐き出したところで出力は止まった。\nここで CSV ファイルに次の1行を追加してみる。\nMicrosoft Corporation,MSFT,163000 すると出力は\n[info] running com.example.entry.ReadCsvFileExperimentRunner pojo 2\u0026gt; Company(Alphabet Inc,GOOG,98771) 1\u0026gt; Company(Facebook Inc,FB,49942) 2\u0026gt; Company(Apple Inc,AAPL,147000) 1\u0026gt; Company(Amazon.com Inc,AMZN,798000) 2\u0026gt; Company(Alphabet Inc,GOOG,98771) 1\u0026gt; Company(Amazon.com Inc,AMZN,798000) 2\u0026gt; Company(Apple Inc,AAPL,147000) 1\u0026gt; Company(Microsoft Corporation,MSFT,163000) 2\u0026gt; Company(Facebook Inc,FB,49942) となり、最初に出力された4行に加えて新たに5行追加された。\nCSV ファイルには1行追加しただけだが、既存の行も含む CSV ファイル全体が再度出力された。\nドキュメントに記載されているとおりの仕様となっている。\ntuple 版で実行すると出力は次のようになった。\n[info] running com.example.entry.ReadCsvFileExperimentRunner tuple 1\u0026gt; (Facebook Inc,FB,49942) 1\u0026gt; (Amazon.com Inc,AMZN,798000) 2\u0026gt; (Alphabet Inc,GOOG,98771) 2\u0026gt; (Apple Inc,AAPL,147000) tuple として読めているようだ。\nwatchType が同じなので CSV ファイルの更新についての挙動は同様だった。\nちなみに実行可能なプロジェクトは GitHub に置いている。\nsbt 'runMain com.example.entry.ReadCsvFileExperimentRunner pojo'  または sbt 'runMain com.example.entry.ReadCsvFileExperimentRunner tuple'  で実行できる。\n(Ctrl + C で終了)\nまとめ TextInputFormat で読んで自分で parse するのと比べ、*CsvInputFormat を使う方法はコーディングとしてはあまりメリットが感じられなかった。\nまた、ストリーム処理においてやはりファイルというデータソースは傍流なんだなという感じ。\nちなみに Table API で CSV を読むこともおそらく可能。\n気が向いたら書く。\n","permalink":"https://soonraah.github.io/posts/read-csv-by-flink-datastream-api/","summary":"ストリーム処理における CSV ファイルの読み込み Apache Flink は unbounded なストリームデータを処理するためのフレームワークだ。\nしかし現実的な application を開発する場合、ストリームデータに加えて static なファイルや DB 等を読み込みたいこともある。\nstar schema における dimension table 的な情報をストリームに結合したい場合 等が考えられる。\nこのポストでは Flink で DataStream API ベースでの実装において CSV ファイルを読むことを考える。\nFlink は現時点の stable である v1.11 を想定。\nCSV ファイルを読む方法 DataStream API ベースの実装で CSV ファイルを読むには StreamExecutionEnvironment のメソッドである readFile() を使う。\noverload された同名のメソッドがいくつか存在するが、次の2つの引数が特に重要だろう。\nまず1つめは FileInputFormat\u0026lt;OUT\u0026gt; inputFormat であり、こちらは data stream の生成に用いる入力フォーマットを指定する。\nおそらく最も一般的なのが TextInputFormat だと思われる。\nもちろん単なる text として CSV ファイルを読み込み、後続の処理で各レコードを parse することも可能だが CSV 用の入力フォーマットがいくつか用意されているようだ。\n PojoCsvInputFormat RowCsvInputFormat TupleCsvInputFormat  なんとなく名前でわかると思うが、それぞれ readFile() の結果として返される DataStreamSource が内包する型が異なる。","title":"Apache Flink の DataStream API 利用時の CSV ファイル読み込み"},{"content":"ちょっと昔話 かつて参画したプロジェクトの話。\nそのプロジェクトでは他社から受注した受託開発として機械学習系のシステムを開発していた。\n当時としては新しいフレームワークを使い、かなり頑張ってなんとか納期内で完成させた。\nその中の1つの機能として A/B テストができるようにしていた。\nパラメータチューニングによりパフォーマンスを改善することを想定していた。\nしかし結局その機能は使われることがなかった。\nなぜか。\nA/B テストを実施するためのクライアントの追加の予算がつかなかったためである。\n受託なのでなおさらなのだが、売上にならなければ工数をかけるこはできない。\n工数を使ってパフォーマンス改善することはできなかった。\n手はあるのに。\n機械学習の精度は必ずしも利益に結びつかない この昔話で何が言いたいかというと、機械学習の精度改善は必ずしも利益に結びつかないということである。\nそのことを示しているとても素晴らしい資料がこちら。\n  機械学習の精度と売上の関係  from Tokoroten Nakayama  前述の昔話の例はこの資料で言うところの③ロジスティック型 (=外注) となる。\nいったん売上が立った後、追加予算がつかなかったので精度改善では売上は増えなかったのだ。\n倫理感による精度改善 受託開発を主としている組織であれば工数にはシビアなので、売上の立たない工数をかけることはあまりないだろう。\n(よっぽどの炎上鎮火とかでなければ)\nしかし自社で製品やサービスを作って提供しているような組織の場合、利益にならない精度改善をしているのを時折見かける。\nなぜそのようなことが起こるかと言うと多くの場合はデータサイエンティスト／機械学習エンジニアとしての倫理感からなのではないだろうか。\n「◯◯予測という機能なのでできるだけ良い予測精度を示すべきだ」\n「ユーザには気づかれない部分だが精度が悪いので改善したい」\n倫理感や興味が先行してしまっているのだ。\nしかしその精度を上げた先に利益があるとは限らない。\n機械学習で職を得ている人間は自分の仕事を機械学習の精度を上げるゲームだとみなす傾向があるように思う。\n例えばインターネット広告の CTR 予測。\nこれは予測精度が高いほど利益は改善するし、広告主に価値も提供できる。\n精度改善に倫理と利益が伴っている、とても機械学習がハマる例だと思う。\n本来はこれらを兼ね備えているのが良い適用先であるはずだ。\nイシューは行き渡っているのか 利益に結びつかない、または間接的にしか結びつかないような精度改善をやることが許されるというのは組織に余裕があるということで悪いことではないのかもしれない。\nしかし単によいイシューの設定ができてないだけという可能性もある。\n自社で製品やサービスを作って提供しているような組織において、単純なロジスティック回帰でコアなところのビジネスを大きく加速させることができた時期を過ぎると機械学習で解くのに適したよい問題を恒常的に見つけ出すのは実は難しいのではないだろうかと最近考えるようになった。\nビジネスの領域拡大よりも既存領域への機械学習の適用の方が速いということは十分ありうる。\nもちろんチームの規模にもよる。\n機械学習チームの人的リソースの規模に対して機械学習で解くべきよいイシューを見つけ出せているのか、ということだ。\n少し前にちょっと話題になったこちらの件もイシューが大事だと言っている。\n 全ての機械学習の論文は新しいアルゴリズムを提案しているのですか？ - Quora  キャリアの行く末 事業会社においてビジネスの領域拡大よりも既存領域への機械学習の適用の方が速く、よいイシューを提供しにくいということがよく起こるのであれば、機械学習チームのリソースは余剰気味になりやすいということになる。\nこれが続くと今後機械学習しかやらない人材の市場価値は下がっていくのかもしれない。\nもしくは自社で製品やサービスを持っている組織ではなく、受託開発やコンサルが主戦場になっていくのかもしれない。\n何にせよ特定のプロダクトに commit したいのであれば機械学習エンジニアは機械学習以外のスキルも磨いていく必要があるように思う。\nおわりに 見える範囲にいる人が利益にならない精度改善をしているのを横目で見てこのようなことを考えていた。\n難しいけどできるだけ金を生んでいきたい。\n","permalink":"https://soonraah.github.io/posts/ml-accuracy-profit-ethic-issue/","summary":"ちょっと昔話 かつて参画したプロジェクトの話。\nそのプロジェクトでは他社から受注した受託開発として機械学習系のシステムを開発していた。\n当時としては新しいフレームワークを使い、かなり頑張ってなんとか納期内で完成させた。\nその中の1つの機能として A/B テストができるようにしていた。\nパラメータチューニングによりパフォーマンスを改善することを想定していた。\nしかし結局その機能は使われることがなかった。\nなぜか。\nA/B テストを実施するためのクライアントの追加の予算がつかなかったためである。\n受託なのでなおさらなのだが、売上にならなければ工数をかけるこはできない。\n工数を使ってパフォーマンス改善することはできなかった。\n手はあるのに。\n機械学習の精度は必ずしも利益に結びつかない この昔話で何が言いたいかというと、機械学習の精度改善は必ずしも利益に結びつかないということである。\nそのことを示しているとても素晴らしい資料がこちら。\n  機械学習の精度と売上の関係  from Tokoroten Nakayama  前述の昔話の例はこの資料で言うところの③ロジスティック型 (=外注) となる。\nいったん売上が立った後、追加予算がつかなかったので精度改善では売上は増えなかったのだ。\n倫理感による精度改善 受託開発を主としている組織であれば工数にはシビアなので、売上の立たない工数をかけることはあまりないだろう。\n(よっぽどの炎上鎮火とかでなければ)\nしかし自社で製品やサービスを作って提供しているような組織の場合、利益にならない精度改善をしているのを時折見かける。\nなぜそのようなことが起こるかと言うと多くの場合はデータサイエンティスト／機械学習エンジニアとしての倫理感からなのではないだろうか。\n「◯◯予測という機能なのでできるだけ良い予測精度を示すべきだ」\n「ユーザには気づかれない部分だが精度が悪いので改善したい」\n倫理感や興味が先行してしまっているのだ。\nしかしその精度を上げた先に利益があるとは限らない。\n機械学習で職を得ている人間は自分の仕事を機械学習の精度を上げるゲームだとみなす傾向があるように思う。\n例えばインターネット広告の CTR 予測。\nこれは予測精度が高いほど利益は改善するし、広告主に価値も提供できる。\n精度改善に倫理と利益が伴っている、とても機械学習がハマる例だと思う。\n本来はこれらを兼ね備えているのが良い適用先であるはずだ。\nイシューは行き渡っているのか 利益に結びつかない、または間接的にしか結びつかないような精度改善をやることが許されるというのは組織に余裕があるということで悪いことではないのかもしれない。\nしかし単によいイシューの設定ができてないだけという可能性もある。\n自社で製品やサービスを作って提供しているような組織において、単純なロジスティック回帰でコアなところのビジネスを大きく加速させることができた時期を過ぎると機械学習で解くのに適したよい問題を恒常的に見つけ出すのは実は難しいのではないだろうかと最近考えるようになった。\nビジネスの領域拡大よりも既存領域への機械学習の適用の方が速いということは十分ありうる。\nもちろんチームの規模にもよる。\n機械学習チームの人的リソースの規模に対して機械学習で解くべきよいイシューを見つけ出せているのか、ということだ。\n少し前にちょっと話題になったこちらの件もイシューが大事だと言っている。\n 全ての機械学習の論文は新しいアルゴリズムを提案しているのですか？ - Quora  キャリアの行く末 事業会社においてビジネスの領域拡大よりも既存領域への機械学習の適用の方が速く、よいイシューを提供しにくいということがよく起こるのであれば、機械学習チームのリソースは余剰気味になりやすいということになる。\nこれが続くと今後機械学習しかやらない人材の市場価値は下がっていくのかもしれない。\nもしくは自社で製品やサービスを持っている組織ではなく、受託開発やコンサルが主戦場になっていくのかもしれない。\n何にせよ特定のプロダクトに commit したいのであれば機械学習エンジニアは機械学習以外のスキルも磨いていく必要があるように思う。\nおわりに 見える範囲にいる人が利益にならない精度改善をしているのを横目で見てこのようなことを考えていた。\n難しいけどできるだけ金を生んでいきたい。","title":"機械学習の精度と利益と倫理とイシューと"},{"content":"はじめに このポストではストリーム処理の survay 論文の話題に対して Apache Flink における例を挙げて紹介する。\n論文概要 Fragkoulis, M., Carbone, P., Kalavri, V., \u0026amp; Katsifodimos, A. (2020). A Survey on the Evolution of Stream Processing Systems.\n2020年の論文。\n過去30年ぐらいのストリーム処理のフレームワークを調査し、その発展を論じている。\nストリーム処理に特徴的に求められるいくつかの機能性 (functionality) についてその実現方法をいくつか挙げ、比較的古いフレームワークと最近のフレームワークでの対比を行っている。\nこのポストのスコープ このポストでは前述のストリーム処理システムに求められる機能性とそれがなぜ必要となるかについて簡単にまとめる。\n論文ではそこからさらにその実現方法がいくつか挙げられるが、ここでは個人的に興味がある Apache Flink ではどのように対処しているかを見ていく。\nちなみに論文中では Apache Flink はモダンなフレームワークの1つとしてちょいちょい引き合いに出されている。\nここでは Flink v1.11 をターゲットとする。\n以下では論文で挙げられている機能性に沿って記載していく。\nOut-of-order Data Management Out-of-order ストリーム処理システムにやってくるデータの順序は外的・内的要因により期待される順序になっていないことがある。\n外的要因としてよくあるのはネットワークの問題。\nデータソース (producer) からストリーム処理システムに届くまでのルーティング、負荷など諸々の条件により各レコードごとに転送時間は一定にはならない。\n各 operator の処理などストリーム処理システムの内的な要因で順序が乱されることもある。\nout-of-order は処理の遅延や正しくない結果の原因となることがある。\nout-of-order を管理するためにストリーム処理システムは処理の進捗を検出する必要がある。\n\u0026ldquo;進捗\u0026rdquo; とはある時間経過でレコードの処理がどれだけ進んだかというもので、レコードの順序を表す属性 A (ex. event time) により定量化される。\nある期間で処理された最古の A を進捗の尺度とみなすことができる。\nApache Flink の場合 Flink ではこの進捗を測るのに watermark という概念が使われている。\n Event Time and Watermarks    Apache Flink Event Time and Watermarks\n  (図が見にくい場合はページ上部の太陽みたいなマークをクリックして light mode にしてください)\nこちらの図でストリーム中の破線で描かれているのが watermark であり、W(11) の wartermark は「timestamp が11以下の event はこの後もう来ないものとみなす」ということを下流の operator に伝えるものである。\nwatermark は metadata 的なものだが、通常の event と同じようにストリーム中を流れている (これを panctuation という)。\n下流の operator が window 処理をしていた場合、W(11) が届いた時点で timestamp が11までのところの window 処理を完結してさらに下流に output することができる。\nwatermark がいつ・どのような値で発生するかについては Flink application の開発者の実装次第ということになる。\nしかし現実的には Writing a Periodic WatermarkGenerator の例にある BoundedOutOfOrdernessGenerator のように、 WatermarkGenerator にやってきた event の event time を元に決めることが多いと思われる。\nState Management ストリーム処理における状態 \u0026ldquo;状態\u0026rdquo; とは継続的なストリーム処理の中で内部的な副作用をとらえたもの。\nアクティブな window、レコードのかたまり、aggregation の進捗など。\nユーザ定義のものも含まれる。\n状態については以下のようなトピックがある。\n Programmability  プログラミングモデルにおいて状態がどのように定義・管理されるか 定義と管理についてそれぞれシステムとユーザの場合がある   Scalability and Persistency  最近のストリーム処理は scalable の時流を汲んでおり、scale out するときに状態をどのように扱うか 内外の記憶装置に状態を永続化するという方法がよく取られる   Consistency  transaction level の保証について    Apache Flink の場合 ドキュメントの TOP ページ における Flink を表す一文\n Apache Flink is a framework and distributed processing engine for stateful computations over unbounded and bounded data streams.\n においても \u0026ldquo;stateful\u0026rdquo; という言葉が使われているとおり、状態の扱いは Flink の設計思想の中でもかなり重要な部分となっている。\nFlink における状態の扱いについてはこちらを参照。\n Stateful Stream Processing  Programmability Flink では application 開発者が任意の状態を定義することができる。\n Working with State  一方で状態の管理はフレームワーク側でやってくれるので、開発者は checkpoint や restore 等のことは特に配慮する必要はない。\n論文中ではこれを \u0026ldquo;User-Declared System-Managed State\u0026rdquo; と呼んでおり、最近のストリーム処理システムの傾向となっている。\nScalability Flink では keyBy() により key-level の状態を持つことができる。\nkey ごとに並列 task 内での partitioning し、分散することが可能ということである。\nPersistency 論文では永続化については scalability と絡めて述べられていたが、Flink のドキュメントでは fault tolerance の文脈で永続化について書かれている。\nFlink の fault tolerance の肝は stream replay と checkpointing である。\ncheckpointing とはストリームと operator の状態の一貫性のあるスナップショットをとることである。\n Apache Flink Snapshotting Operator State\n  この checkpoint を作成する過程で各 operator の状態が state backend へと永続化される。\nstate backend では RocksDB の key/value store に各 checkpoint, 各 operator の状態が保存される。\n(RocksDB 以外にもメモリやファイルシステムなどもある)\nConsistency Flink では checkpoint のインターバルの期間の単位 (epoch という) で一貫性のある状態を永続化する。\n上図の barriers がその単位を決めている。\nChandy Lamport algorithm という分散スナップショットの手法がインスパイアされており、unaligned/aligned で各 operator の状態のスナップショットを取るようになっている。\nFault Tolerance \u0026amp; High Availability Fault Tolerance ストリーム処理システムにとって fault tolerance は2つの理由から重要である。\n ストリーム処理システムは stateful な計算を終わりのないデータに対して行っている  fault tolerance がなければ、障害があったときに最初から状態を計算しなおさなければならない 一方で、多くの場合過去に処理されたデータは既に失われている   最近のストリーム処理システムは分散アーキテクチャを採用している  物理マシンの数だけ問題が起こりやすくなる    output commit problem についても考慮する必要がある。\nこれは出力が公開された位置から状態を復元できることが確かな場合のみ、システムは外界に出力を公開するというもの。\n言い換えると、障害からの復旧時などに同じ出力を2回してしまわない、出力を exactly-once にできるかというものである。\nHigh Availability 過去の研究においてストリーム処理システムの可用性は recovery time, performance overhead (throughput \u0026amp; latency), resource utilization により定量化されてきた。\nこの論文では\n A streaming system is available when it can provide output based on the processing of its current input.\n を可用性の定義として提案する。\n時間ごとの processing time と event time の差により定量化される。\nApache Flink の場合 Fault Tolerance 論文中では Flink は output commit problem については Kafka などの出力先の外部システムの責任とするスタンスだとしている。\nKafka には idempotent producer という機能があり、たぶんこれのことを言っている。\nまた一方で TwoPhaseCommitSinkFunction の2相コミットによって exectly-once semantics を提供するという方法も示されている。\n An Overview of End-to-End Exactly-Once Processing in Apache Flink (with Apache Kafka, too!)  checkpointing における JobManager を2相コミットの coordinator とみなし、checkpoint barrier が最後の operator に到達するまでをコミット要求相、その後の JobManager からの checkpointing 完了通知をコミット相としている。\nコミット相において外部システムへの書き出しの transaction が完了する形となる。\nfault tolerance については State Management の項も参照。\nHigh Availability Flink のプロセスには JobManager と TaskManager があり、前者は cluster に1つだけ動く。\nしたがって JobManager が SPOF になり、可用性に影響しうる。\nhigh availability (高可用性) を実現するためには JobManager が SPOF となることを避けることができる。\nstandalone または YARN の cluster として deploy した場合は JobManager が SPOF となることを避けることができる。\n以下は standalone の例。\n1つの JobManager が leader として動いているが、それが crash すると standby のインスタンスが leader を引き継ぐ。\n(論文中では passive replication として紹介)\n Apache Flink Standalone Cluster High Availability\n  Load Management, Elasticity \u0026amp; Reconfiguration Load Management ストリーム処理システムは、外部のデータソースがデータを送る流速を制御することができない。\n入力データの流速がシステムのキャパより大きいことによるパフォーマンス劣化を防ぐための対応が必要となる。\n次のような手法がある。\n load shedding  多すぎる入力データを落とす方法   back-pressure  入力データを落とせないときに buffering と組み合わせて使う dataflow graph 上に速度制限が波及していく   elasticity  分散アーキテクチャと cloud にもとづく方法 いわゆる scale out    Apache Flink の場合 Flink では back pressure および elasticity の組み合わせとなっている。\nback pressure は一時的な入力データの増加に対応する。\n各 operator (subtask?) は入出力の buffer を持っており、これにより operator 間の処理速度の違いをある程度吸収できる。\nしかし入力データが著しく多くなると\n ボトルネックとなる operator の処理が滞る その operator の入力 buffer がいっぱいになる (ボトルネックではない) 上流の operator の出力 buffer がいっぱいになる 上流の operator の処理が滞る (以降繰り返し)  のように、dataflow graph の上流へ上流へと遅延が波及する。\nelasticity の面では、JobManager や TaskManager の追加や削除ができるようになっている。\n Adding JobManager/TaskManager Instances to a Cluster  TaskManager の追加や削除においては状態の再配分が行われる。\n再配分される状態は key group という単位で partitioning されており、consistent hash 的な方法で各 TaskManager 配下の operator へと配分される。\nちなみに AWS が提供する Flink の managed service である Amazon Kinesis Data Analytics for Apache Flink では CPU 使用率をモニタリングして自動的に scale out が行われるようになっている。\n Application Scaling in Kinesis Data Analytics for Apache Flink  まとめ バッチ処理ではあまりクリティカルにならないような問題でもストリーム処理では重大な影響を及ぼすことがある。\nストリーム処理に求められる機能性を実現するに当たり、Apache Flink では checkpoint の仕組みが中心的な役割を果たしているということが理解できた。\n","permalink":"https://soonraah.github.io/posts/functionality-of-streaming-system/","summary":"はじめに このポストではストリーム処理の survay 論文の話題に対して Apache Flink における例を挙げて紹介する。\n論文概要 Fragkoulis, M., Carbone, P., Kalavri, V., \u0026amp; Katsifodimos, A. (2020). A Survey on the Evolution of Stream Processing Systems.\n2020年の論文。\n過去30年ぐらいのストリーム処理のフレームワークを調査し、その発展を論じている。\nストリーム処理に特徴的に求められるいくつかの機能性 (functionality) についてその実現方法をいくつか挙げ、比較的古いフレームワークと最近のフレームワークでの対比を行っている。\nこのポストのスコープ このポストでは前述のストリーム処理システムに求められる機能性とそれがなぜ必要となるかについて簡単にまとめる。\n論文ではそこからさらにその実現方法がいくつか挙げられるが、ここでは個人的に興味がある Apache Flink ではどのように対処しているかを見ていく。\nちなみに論文中では Apache Flink はモダンなフレームワークの1つとしてちょいちょい引き合いに出されている。\nここでは Flink v1.11 をターゲットとする。\n以下では論文で挙げられている機能性に沿って記載していく。\nOut-of-order Data Management Out-of-order ストリーム処理システムにやってくるデータの順序は外的・内的要因により期待される順序になっていないことがある。\n外的要因としてよくあるのはネットワークの問題。\nデータソース (producer) からストリーム処理システムに届くまでのルーティング、負荷など諸々の条件により各レコードごとに転送時間は一定にはならない。\n各 operator の処理などストリーム処理システムの内的な要因で順序が乱されることもある。\nout-of-order は処理の遅延や正しくない結果の原因となることがある。\nout-of-order を管理するためにストリーム処理システムは処理の進捗を検出する必要がある。\n\u0026ldquo;進捗\u0026rdquo; とはある時間経過でレコードの処理がどれだけ進んだかというもので、レコードの順序を表す属性 A (ex. event time) により定量化される。","title":"ストリーム処理システムに求められる機能性、および Apache Flink におけるその対応"},{"content":"ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。\nそれにあたって独学で調べたことなどまとめておく。\nストリーム処理とは そもそも \u0026ldquo;ストリーム処理\u0026rdquo; とは何を指しているのか。\n以下の引用が簡潔に示している。\n a type of data processing engine that is designed with infinite data sets in mind. Nothing more.\u0026ndash; Streaming 101: The world beyond batch こちらは \u0026ldquo;streaming system\u0026rdquo; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。\n例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。\nweb サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。\nこれに対して \u0026ldquo;1日分のユーザ行動ログ\u0026rdquo; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。\nストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。\nこの後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。\nなぜストリーム処理なのか なぜストリーム処理なのか。\nひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。\n迅速なフィードバックがビジネス上のメリットとなることは自明だ。\n SNS の配信 カーシェアリングにおける配車や料金設定 クレジットカードや広告クリックなどの不正検知  もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。\nまあ待っていられない。\n一般的なストリーム処理の構成 モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。\n producer broker consumer  producer は最初にレコードを生成する、ストリームデータの発生源となるものである。\n例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。\nproducer は絶え間なくログを生成し、それを broker へと送る。\nbroker は producer から送られたログを格納し、任意のタイミングで取り出せるようにするものである。\n誤解を恐れずに言うとメッセージキューに近いイメージだ。\nApache Kafka クラスタや Amazon Kinesis Data Streams 等がこれに該当する。\nconsumer は broker からログを取り出し、それに対し何かしらの処理を行うものだ。\ntime window 集計であったりログからの異常検知であったり、処理した結果として何かビジネス上意味があるものを得るのである。\nこれを行うフレームワークとしては Spark Streaming や Apache Flink 等がメジャーなのだろうか。\nproducer と consumer の間に broker を挟むメリットとしては次のようなことが挙げられる。\n producer が M 個、consumer が N 個の場合に M * N の関係になるところを broker を挟めば M + N にできる  producer, consumer に多数のシステムがあったとしても各自は broker との接続だけを考えればよい   任意のタイミングでデータを読み出せる producer または consumer に問題が発生してもデータロスが起こりにくくできる  その分 broker には高い可用性が求められる  Kafka はクラスタで冗長構成 Kinesis Data Streams は複数 AZ でレプリケーション      時間の概念 ストリーム処理では時間の概念がいくつかあり、集計などの処理をどの時間をベースにして実行するのか、意識する必要がある。\n event time  producer 側でログイベントが発生した時間   ingestion time  broker にそのログイベントのレコードが挿入された時間   processing time  consumer 側でレコードを処理した時間    processing time を使うのが一番簡単なのだが、おそらく分析系の処理であれば window 集計等では event time を使うことが多いのではないだろうか。\ningestion time はおそらく実際のプロダクトではあまり使われないのではと思われる。\n(ネットワークのパフォーマンスを見るぐらい？)\nWindowing ストリーム処理の中で sum, count などを伴う集計処理を行う場合、通常は時間方向の window で切って処理するということになるのではないだろうか。\nwindow で切らずに完全なデータセットがそろうまで待つことはできないし、データが来るたびに逐次的に全体の結果を更新するしていくというのも割に合わない。\nwindow の切り方もいくつかある。\n tumbling window  固定長でオーバーラップしない   sliding window  固定長でオーバーラップを含む   session window  いわゆる web の session のように、ある種のイベントがある期間発生しないことにより window が区切られる    これらについては Flink のドキュメントが図もあってわかりやすい。\n個人的な感想だが、この time window の集計がない単なる map 的なストリーム処理であれば traditional なアーキテクチャでも難しくはない。\nしかし time window 集計が必要となった場合は Spark Streaming 等のモダンなフレームワークが威力を発揮してくる。\nWatermark 時間で window を切るときは、前述のどの時間の定義を用いるかを考えなければいけない。\nprocessing time を用いる場合は簡単だが event time はやや難しい。\nconsumer 側では event のレコードがどれくらい遅れてやってくるかわからないためだ。\nネットワークその他の影響により、event のレコードが producer -\u0026gt; broker -\u0026gt; consumer という経路で consumer に届くまでの時間というのは一定にはならない。\nまた、古い event が新しい event より後に届くというように順番が前後することも起こりうる。\nここで \u0026ldquo;watermark\u0026rdquo; という考え方が必要になってくる。\n A watermark with a value of time X makes the statement: \u0026quot;all input data with event times less than X have been observed.\u0026quot;\u0026ndash; Streaming 102: The world beyond batch ある processing time において「event time X より前のレコードはすべて到着したよ」というのが watermark である。\n別の言い方をすると watermark により event のレコードがどの程度遅延してもよいかが定義される。\nevent time X より前のレコードが真の意味ですべて到着した、というのは難しい。\n実際には heuristic にどの程度遅れていいかを決め、それより遅れた場合はある event time 期間における window 処理には含めないということになる。\nwatermark の決め方はフレームワーク次第だろうか。\n例えば Spark Structured Streaming の例だと図もあって比較的わかりやすい。\nSchema Evolution 何らかの業務システムや web システム等をある程度運用したことがある人ならわかると思うが、データの schema というのはナマモノだ。\n一度決めたら終わりというわけではなくプロダクトやビジネスの変化に応じて変化していく。\nカラムが増えたり、削除されたり、名前や型が変わったり…\nこのようにデータの構造が変化していくこと、またはそれを扱うことを \u0026ldquo;schema evolution\u0026rdquo; という。\nバッチ処理において schema の変更に追従することを考えるのはそれほど難しくない。\nhourly のバッチ処理であったとしても、バッチ処理とバッチ処理の間の時間で application を更新すればいいだけだ。\n(が、実際に行うのは困難が伴うことも多い)\nではストリーム処理ではどうだろうか。\nいわゆるストリーム処理においては処理と処理の間というものがなく、application がずっと稼働しっぱなしということになる。\nバッチ処理のような更新はできない。\nもっと言うと producer で生まれた新しい schema のレコードがいつ届くかもわからない。\nおそらくこの問題には2つの対応方法がある。\n1つめは consumer 側のシステムで前方互換性を保つという方法である。\nこの場合、新しいフィールドは必ず末尾に追加される等、producer 側での schema 更新についてある程度のルールが必要となるだろう。\nproducer 側で生成されるレコードの schema の変更が必ず事前にわかるというのであれば後方互換性でもいいが、多くの場合は難しい。\nところで前方互換と後方互換、どっちがどっちなのか覚えられません。\n2つめの方法として schema 情報をレコード自体に入れ込んでしまうという方法もある。\nApach Avro のような serialization の方法を取っているとレコード自体に schema の情報を付与することができる。\nおそらく最もエレガントにこれをやるのが Confluent の Schema Registry という機能だ。\nproducer から送出されるレコードには schema ID を付与する。\nschema の実体は Schema Registry という broker とは別の場所で管理されており、consumer 側では受け取ったレコードに付与されている schema ID と Schema Registry に登録されている shcema の実体を参照してレコードを deserialize することができる。\nDeploy ストリーム処理を行うシステムは終わりのないデータを処理するためのものであり、ずっと動き続けることが期待されている。\nしかし通常システムは一度立ち上げれば終わりということではなく、運用されている中で更新していく必要がある。\nずっと動かしながらどのように deploy, release するのか。\nこの問題は主に consumer 側のシステムで配慮が必要になると思われる。\n正直これについてはちゃんと調べられていないが、2点ほど述べておきたい。\nまず1点目、application を中断・更新・再開するのにどの程度の時間がかかるのかを知っておく必要があるということ。\nアーキテクチャやフレームワーク、処理の内容や checkpoint (後述) を使うか等によりこの時間は変わってくる。\n一例だが、AWS 環境において\n AWS Glue + Spark Structured Streaming Amazon Kinesis Data Analytics + Flink  の比較をしたことがある。\n前者は再開に数分かかったのに対し、後者は1分未満で再開できた。\n再開までの時間が十分に短いと判断できるのであればそのまま deploy, release してしまっていいだろう。\n一方そうでない場合はどうすべきかという話が2点目。\n再開までの時間が長く、システム要件的に許容できないというのであれば、release 時は二重で動かすというような措置が必要かもしれない。\nおそらく Blue-Green Deployment のようなことを考えることになるだろう。\nCheckpoint 前述のとおり、ストリーム処理を行うシステムはずっと動き続けることが期待されている。\nしかし予定された application の更新や不測のエラー等、何らかの理由で一時的に中断されるということが実際の運用中には起こる。\n中断されたとき速やかに復帰する仕組みとして \u0026ldquo;checkpoint\u0026rdquo; というものがいくつかの consumer 側のフレームワークで提供されている。\n雑に説明すると、処理のある時点における進捗や内部状態などをディスク等に永続化し、そこから処理を再開できるようにするものである。\n Recovering from Failures with Checkpointing - Apache Spark Checkpointing - Apache Flink  上記は Spark Structured Streaming と Flink の例だ。\ncheckpoint には次のようなメリットがあり、運用上有用だと言える。\n 内部の状態を保持しているため、速やかに復帰できる 中断した位置から再開できるので出力に穴が開かない  一方で落とし穴もある。\ncheckpoint では内部の状態が永続化されるわけだが、内部の状態というのは当然 application の実装が決めているものである。\napplication のコードを変更したとき、変更の内容によっては永続化された checkpoint と application が合わなくなることがあるのだ。\n未定義の挙動となることもあるので、checkpoint の運用には十分に配慮する必要がある。\nどのような変更なら checkpoint が安全に利用できるのかはフレームワークのドキュメントに記載があるので確認しておきたい。\nRDB の世界との折り合い みんな大好きな RDB の世界では table を操作してデータの処理を行う。\n基本的には table というものはある時点における完全なデータセットを表すものである。 (ex. isolation)\n他方、ストリーム処理はやってきたデータを逐次的に処理するものである (mini-batch の場合もあるが)。\n直感的にこの2つは相性が悪そうに見える。\nしかし Spark や Flink では table ベースの操作でストリーム処理を行うための API が提供されている。\nおそらく\n ストリーム処理の周辺のデータソースとして RDB が存在する RDB 的な table 操作があまりにも浸透している  というところが API が必要である理由なのだろう。\nストリームデータを table 的に扱うというのが、やや直感的な理解をしにくいものとなっている。\nフレームワークのドキュメントを確認しておきたい。\n例えば Spark Structured Streaming であれば処理の出力のための3つの output mode が示されている。\n Append mode: 追加された行だけ出力 Complete mode: table 全体を出力 Update mode: 更新された行だけ出力  どれを選ぶかにより必要とする内部メモリの大きさも影響される。\nまとめ 思ったより長文になってしまった。\n結局ストリーム処理の難しさは以下の2点に尽きるだろう。\n 複数の時間の概念 常時稼働のシステム  独学なので抜け漏れがあったり、話が新しくなかったりすることもあると思われる。\n参考  Streaming 101: The world beyond batch  Apache Beam PMC によるストリーム処理の解説ポスト。必読   Streaming 102: The world beyond batch  上の続きであり watermark について触れている   Analytics Lens - AWS Well-Architected Framework  AWS の資料。ストリーム処理のシステムの全体感がつかめる   Structured Streaming Programming Guide - Apache Spark  Spark Structured Streaming のドキュメント。consumer の気持ちがわかる   Flink DataStream API Programming Guide - Apache Flink  Flink のドキュメントの方がより詳しい。DataStream API の解説を中心に読むとよい    ","permalink":"https://soonraah.github.io/posts/study-streaming-system/","summary":"ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。\nそれにあたって独学で調べたことなどまとめておく。\nストリーム処理とは そもそも \u0026ldquo;ストリーム処理\u0026rdquo; とは何を指しているのか。\n以下の引用が簡潔に示している。\n a type of data processing engine that is designed with infinite data sets in mind. Nothing more.\u0026ndash; Streaming 101: The world beyond batch こちらは \u0026ldquo;streaming system\u0026rdquo; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。\n例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。\nweb サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。\nこれに対して \u0026ldquo;1日分のユーザ行動ログ\u0026rdquo; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。\nストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。\nこの後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。\nなぜストリーム処理なのか なぜストリーム処理なのか。\nひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。\n迅速なフィードバックがビジネス上のメリットとなることは自明だ。\n SNS の配信 カーシェアリングにおける配車や料金設定 クレジットカードや広告クリックなどの不正検知  もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。\nまあ待っていられない。\n一般的なストリーム処理の構成 モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。\n producer broker consumer  producer は最初にレコードを生成する、ストリームデータの発生源となるものである。","title":"バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと"},{"content":"前提 ここでは web システムで使われている機械学習のモデルやアルゴリズムを改善するための online の A/B テストを考える。\n具体的に述べると web 広告における CTR 予測や EC サイトのレコメンデーション等が対象である。\nよくあるやつ。\nweb システムにおいて online の A/B テストは KPI 改善の根幹でありとても重要だ。\nそれが重くなるとつらい、という話。\nここで「重い」と言っているのは計算資源のことではなく、A/B テストを実施する担当者の運用コストについて。\nA/B テストの運用が重い場合のデメリット デメリット 1. KPI 改善が遅くなる デメリットと言えばこれが一番大きい。\n単純に A/B テストを1回まわすのに時間がかかってしまうし、それがゆえに online の A/B テストに入るまでの offline のテストが厚くなりここでも時間がかかってしまう。\nKPI 改善に時間がかかるというのはつまり売上や利益を大きくするのに時間がかかってしまうということである。\nデメリット 2. KPI 改善における offline テストの比重が大きくなる 前述のとおりだが online の A/B テストが重いとそこで失敗できなくなり、結果としてその前段の offline のテストを厚くするということになる。\noffline のテストが厚いことの何が問題だろうか。\nここで前提としている CTR 予測やレコメンデーションのようなタスクの場合、offline のデータは既存のモデルやアルゴリズムの影響を受けることになる。\n例えばレコメンデーションの場合を考えると、新しいモデルを offline で評価するための実験データの正例 (コンテンツの閲覧等) は既存モデルによって生み出される。\n既存モデルが「このコンテンツがいいよ」といってユーザに出したリスト、その中からコンテンツの閲覧が行われ正例となるからだ。\nこのような状況下での offline テストにおいては既存モデルと近い好みを持ったモデルのスコアが高くなる傾向がある。\nもしかしたら既存モデルの影響を受けないようなデータをあえて用意しているような場合もあるかもしれないが、レアケースだろう。\n既存モデルの影響を受けないということは恩恵を受けないということなのでトレードオフでもある。\nデメリット 3. 新モデル／アルゴリズムを却下しにくくなる A/B テストの運用が重いと何度も繰り返すことができない。\nなので一発の A/B テストで既存モデル／アルゴリズムを置き換える成果を出さなければならないという圧が強くかかってしまう。\n既存モデル／アルゴリズムが勝って新しいものが負けてしまったときの埋没費用が大きいからだ。\nそうなると次のような事が起こる。\n 「新モデルをチューニングしてみよう！」  数ヶ月前のデータでチューニングされていない既存モデル vs. 直近のデータでチューニングされた新モデル   「新モデルが KPI で勝っている間に意思決定しよう！」  勝ったり負けたりする中で…    つまりフェアなテストではなくなってしまう。\nなぜ A/B テスト運用が重くなるのか 理由 1. リリース作業のコスト A/B テストの運用が重くなる理由の1として、A/B テストを始めるときのオペレーション、つまり新しいモデル／アルゴリズムをリリースする際の作業コストが重いことが挙げられる。\nこれにはモデル／アルゴリズムが web のシステムに対してどのような形でデプロイされているかが影響する。\nmercari が次のような資料を公開しているので参考にしたい。\n 機械学習システムの設計パターンを公開します。  例えば Synchronous pattern のように web サーバと推論をする場所が分離している場合に比べて Web single pattern のように一体化している場合は新しいモデル／アルゴリズムのリリースに繊細にならざるを得ないのではないだろうか。\nコードベースもそうだし、マシンリソースの管理も後者の方が難しい。\n特にリリース担当者がデータサイエンティスト的な人だった場合、リリースの心理的障壁が上がる。\n理由 2. はっきりしない指標 A/B テストするときはテストの指標として何らかの KPI を置く。\nこの KPI が複数ある場合がある。\n例えば web 広告における CTR 予測モデルであれば CTR と impression 等。\n現実のビジネスは複雑なので複数の KPI があるのは珍しくないと思われる。\n一方で KPI が複数になると評価が難しくなる。\n「KPI A は5上がったけど B は3下がった、この場合はどうなの？」ということになり \u0026ldquo;マネージャの肌感\u0026rdquo; みたいなものが必要になってしまう。\n当然機械的に判定することによる自動化なども行えない。\nA/B テストの経過における現状の良し悪しの判断にコストがかかってしまうことになる。\nまた判断基準が複雑なことによりおとり効果のようなことも発生しうるだろう。\nこれについての1つの解として OEC: Overall Evaluation Criterion という考え方がある。\n What does \u0026ldquo;Overall Evaluation Criterion\u0026rdquo; mean?  複数の KPI を重みをつけて組み合わせてただ1つの値として評価できるようにする、というものらしい。\n逆に考えると OEC を定義せずに複数の KPI で A/B テストをするということは KPI 間のバランスの合意なしで走ってしまっているということになる。\n理由 3. 煩雑な流量オペレーション これは実際に見たことだが、A/B テストの運用に際して組織の一部の人間しか理解していない煩雑なオペレーションを伴うことがある。\n最初は control group を 0.1% だけ流して、1日経って問題がなければ 1% に上げて、その次は5%で…などのような操作を求められるのである。\n担当者にすればまあまあのストレスだし、時間がかかってしまう。\nまとめ ソフトウェア開発の分野でも大きな変更をえいやーでリリースするのはキツイということで git-flow であったり GitHub Flow であったりが導入されてきたはず。\nA/B テストが重いということはそれの逆をいっている状態となる。つらい。\n","permalink":"https://soonraah.github.io/posts/heavy-ab-testing-operation/","summary":"前提 ここでは web システムで使われている機械学習のモデルやアルゴリズムを改善するための online の A/B テストを考える。\n具体的に述べると web 広告における CTR 予測や EC サイトのレコメンデーション等が対象である。\nよくあるやつ。\nweb システムにおいて online の A/B テストは KPI 改善の根幹でありとても重要だ。\nそれが重くなるとつらい、という話。\nここで「重い」と言っているのは計算資源のことではなく、A/B テストを実施する担当者の運用コストについて。\nA/B テストの運用が重い場合のデメリット デメリット 1. KPI 改善が遅くなる デメリットと言えばこれが一番大きい。\n単純に A/B テストを1回まわすのに時間がかかってしまうし、それがゆえに online の A/B テストに入るまでの offline のテストが厚くなりここでも時間がかかってしまう。\nKPI 改善に時間がかかるというのはつまり売上や利益を大きくするのに時間がかかってしまうということである。\nデメリット 2. KPI 改善における offline テストの比重が大きくなる 前述のとおりだが online の A/B テストが重いとそこで失敗できなくなり、結果としてその前段の offline のテストを厚くするということになる。\noffline のテストが厚いことの何が問題だろうか。\nここで前提としている CTR 予測やレコメンデーションのようなタスクの場合、offline のデータは既存のモデルやアルゴリズムの影響を受けることになる。\n例えばレコメンデーションの場合を考えると、新しいモデルを offline で評価するための実験データの正例 (コンテンツの閲覧等) は既存モデルによって生み出される。\n既存モデルが「このコンテンツがいいよ」といってユーザに出したリスト、その中からコンテンツの閲覧が行われ正例となるからだ。","title":"A/B テストの運用が重くてつらいという話"},{"content":"前回の記事 では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。\n今回の記事では Table API の temporal table function を用いた実験を行う。\nTable API Table API は名前のとおりで class Table を中心として SQL-like な DSL により処理を記述するという、DataStream API より high-level な API となっている。\nこれらの関係は Apaceh Spark の RDD と DataFrame (DataSet) の関係に似ている。\nSQL-like な API で記述された処理が実行時に最適化されて low-level API の処理に翻訳されるところも同じだ。\nRDB の table の概念を元にしているものと考えられるが、本質的に table の概念とストリーム処理はあまりマッチしないと思う。\ntable はある時点のデータセット全体を表すのに対し、ストリーム処理ではやってくるレコードを逐次的に処理したい。\nここを合わせているため、ストリーム処理における Table API による処理の挙動の理解には注意が必要だ。\nStreaming Concepts 以下のドキュメントを確認しておきたい。\nTemporal Table Function star schema における、変更されうる dimension table を stream data と結合する方法として、temporal table という仕組みが提供されている。\nドキュメントでは為替レートの例が示されている。\nstream でやってくる fact table 的なレコードに対して、為替のように時々刻々と変化する dimension table をそのレコードの時刻における snap shot としてぶつけるような形となる。\nレコードの時刻としては processing time または event time を扱うことができる。\nevent time の場合であっても watermark で遅延の許容を定義できるため dimension table のすべての履歴を状態として保持する必要はなく、processing time または event time の watermark に応じて過去の履歴は捨てることが可能となっている。\nTable API において temporal table を使うには temporal table function という形を取ることになる。\n実験 実験概要 やることは 前回の記事 とまったく同じで乱数で作った株価のデータを扱う。\n前回と違うのは DataStream API ではなく Table API で処理を記述したところである。\nコード 上記を実行するためのコードを以下に示す。\n実行可能なプロジェクトは GitHub に置いておいた。\nEntry Point toTable() により入力データの DataStream を Table に変換した後、処理を記述した。\nfunc が temporal table function に当たる。\n今回は processing time を基準として join しているが、実際のシステムでは event time を基準としたいことが多いのではないだろうか。\npackage example import org.apache.flink.api.java.io.TextInputFormat import org.apache.flink.api.scala._ import org.apache.flink.core.fs.Path import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration import org.apache.flink.streaming.api.TimeCharacteristic import org.apache.flink.streaming.api.functions.source.FileProcessingMode import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment} import org.apache.flink.table.api.bridge.scala.{StreamTableEnvironment, _} import org.apache.flink.table.api.{AnyWithOperations, EnvironmentSettings, FieldExpression, call} import org.apache.flink.test.util.MiniClusterWithClientResource object FlinkTableJoinTest { // See https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/testing.html#testing-flink-jobs  private val FlinkCluster = new MiniClusterWithClientResource( new MiniClusterResourceConfiguration .Builder() .setNumberSlotsPerTaskManager(2) .setNumberTaskManagers(1) .build ) def main(args: Array[String]): Unit = { FlinkCluster.before() // for batch programs use ExecutionEnvironment instead of StreamExecutionEnvironment  val env = StreamExecutionEnvironment.getExecutionEnvironment env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime) env.setParallelism(2) // create settings  val setting = EnvironmentSettings .newInstance() .useBlinkPlanner() .inStreamingMode() .build() // create a TableEnvironment  val tableEnv = StreamTableEnvironment.create(env, setting) // create a Table instance for Company  val companiesMasterFilePath = \u0026#34;data/companies.csv\u0026#34; val companies = readCompaniesMaster(companiesMasterFilePath, env) .toTable(tableEnv, $\u0026#34;ticker\u0026#34;.as(\u0026#34;c_ticker\u0026#34;), $\u0026#34;name\u0026#34;, $\u0026#34;c_proc_time\u0026#34;.proctime) // temporal table function  val func = companies.createTemporalTableFunction($\u0026#34;c_proc_time\u0026#34;, $\u0026#34;c_ticker\u0026#34;) // create a Table instance for Stock  val stocks = env .fromCollection(new UnboundedStocks) .toTable(tableEnv, $\u0026#34;ticker\u0026#34;.as(\u0026#34;s_ticker\u0026#34;), $\u0026#34;price\u0026#34;, $\u0026#34;s_proc_time\u0026#34;.proctime) // join with a temporal table function  val results = stocks .joinLateral(call(func, $\u0026#34;s_proc_time\u0026#34;), $\u0026#34;s_ticker\u0026#34; === $\u0026#34;c_ticker\u0026#34;) .select($\u0026#34;s_ticker\u0026#34;, $\u0026#34;name\u0026#34;, $\u0026#34;price\u0026#34;) .toAppendStream[(String, String, Double)] .print env.execute() FlinkCluster.after() } private def readCompaniesMaster(companiesMasterFilePath: String, env: StreamExecutionEnvironment): DataStream[Company] = { env .readFile( new TextInputFormat(new Path(companiesMasterFilePath)), companiesMasterFilePath, FileProcessingMode.PROCESS_CONTINUOUSLY, 10 * 1000 ) .map { line =\u0026gt; val items = line.split(\u0026#34;,\u0026#34;) Company(items(0), items(1)) } } } 実行結果 上記を実行すると以下のような stream と static が結合された結果レコードが流れ続ける。\n2\u0026gt; (AMZN,Amazon,110.05826176785374) 2\u0026gt; (AMZN,Amazon,237.82717323588966) 1\u0026gt; (FB,Facebook,147.96046700184428) 1\u0026gt; (GOOGL,Google,393.58555322242086) 2\u0026gt; (AMZN,Amazon,104.18843434881401) 前回と同様に data/companies.csv の中身を更新するとその結果が反映される。\n削除が反映されないのも同じだった。\nおそらく physical な処理としてはほぼ同じようになっていると思われる。\nまとめ 前回と同様の stream data と static data の join を、Table API + temporal table function で行えることを確認した。\ntemporal table function の概念さえ把握できれば Straem API のときに比べて簡潔に処理を記述できた。\n","permalink":"https://soonraah.github.io/posts/flink-join-by-temporal-table-function/","summary":"前回の記事 では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。\n今回の記事では Table API の temporal table function を用いた実験を行う。\nTable API Table API は名前のとおりで class Table を中心として SQL-like な DSL により処理を記述するという、DataStream API より high-level な API となっている。\nこれらの関係は Apaceh Spark の RDD と DataFrame (DataSet) の関係に似ている。\nSQL-like な API で記述された処理が実行時に最適化されて low-level API の処理に翻訳されるところも同じだ。\nRDB の table の概念を元にしているものと考えられるが、本質的に table の概念とストリーム処理はあまりマッチしないと思う。\ntable はある時点のデータセット全体を表すのに対し、ストリーム処理ではやってくるレコードを逐次的に処理したい。\nここを合わせているため、ストリーム処理における Table API による処理の挙動の理解には注意が必要だ。","title":"Apache Flink の Temporary Table Function を用いた stream data と static data の join"},{"content":"star schema における fact table と dimension table の join のようなことを Apache Flink におけるストリーム処理で行いたい。\nstream data と static data の join ということになる。\nただし dimension table 側も更新されるため、完全な static というわけではない。\nこのポストでは Flink v1.11 を前提とした。\njoin の方法 今回は DataStream API でこれを実現することを考える。\nFlink のドキュメントを読むと broadcast state pattern でできそうだ。\n The Broadcast State Pattern  やり方としては次のようになる。\n static data のファイルを FileProcessingMode.PROCESS_CONTINUOUSLY で読み込み DataStream 化 1 を broadcast() stream data の DataStream と 2 を connect()  static data を PROCESS_CONTINUOUSLY で読むのは変更を得るため。\nPROCESS_ONCE で読んでしまうとストリーム処理の開始時に1回読むだけになり、dimension table の変更を得られない。\nこのあたりの仕様については Data Sources を参照。\nその後は broadcast state pattern にそのまま従う。\nしたがって BroadcastProcessFunction or KeyedBroadcastProcessFunction を実装する必要がある。\nその中で static data を取り込んで state として持ち、stream data 側で参照すればよい。\n2つのデータの各 term に対する関係性を以下に示す。\n   in star schema stream or static broadcast or not     dimension table static data broadcasted   fact table stream data non-broadcasted    実験 実験概要 stream data として株価のデータを考える。\n適当に乱数で作った株価が \u0026ldquo;GOOGL\u0026rdquo; 等の ticker とともに流れてくる。\n一方、会社情報が記載された dimension table 的なファイルも用意する。\n流れ続ける株価データに対して ticker を key にして会社情報を紐付ける、ということを行う。\nコード 上記を実行するためのコードを以下に示す。\n実行可能なプロジェクトを GitHub に置いたので興味があればどうぞ。\nEntry Point main() の実装。\nMiniClusterWithClientResource は本来は単体テスト用だが、簡単に local で cluster を動かすためにここで使用している。\npackage example import org.apache.flink.api.common.state.MapStateDescriptor import org.apache.flink.api.java.io.TextInputFormat import org.apache.flink.core.fs.Path import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration import org.apache.flink.streaming.api.functions.source.FileProcessingMode import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment, createTypeInformation} import org.apache.flink.test.util.MiniClusterWithClientResource object FlinkJoinTest { // See https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/testing.html#testing-flink-jobs  private val FlinkCluster = new MiniClusterWithClientResource( new MiniClusterResourceConfiguration .Builder() .setNumberSlotsPerTaskManager(2) .setNumberTaskManagers(1) .build ) def main(args: Array[String]): Unit = { FlinkCluster.before() val env = StreamExecutionEnvironment.getExecutionEnvironment env.setParallelism(2) val companiesMasterFilePath = \u0026#34;data/companies.csv\u0026#34; val companies = readCompaniesMaster(companiesMasterFilePath, env) .broadcast(new MapStateDescriptor( \u0026#34;CompanyState\u0026#34;, classOf[String], // ticker  classOf[String] // name  )) // the broadcast state pattern  // See https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/broadcast_state.html  env .fromCollection(new UnboundedStocks) .connect(companies) .process(new StockBroadcastProcessFunction) .print() env.execute(\u0026#34;flink join test\u0026#34;) FlinkCluster.after() } private def readCompaniesMaster(companiesMasterFilePath: String, env: StreamExecutionEnvironment): DataStream[Company] = { env .readFile( new TextInputFormat(new Path(companiesMasterFilePath)), companiesMasterFilePath, FileProcessingMode.PROCESS_CONTINUOUSLY, 10 * 1000 ) .map { line =\u0026gt; val items = line.split(\u0026#34;,\u0026#34;) Company(items(0), items(1)) } } } Records 各種レコードを表す case class。\nUnboundedStocks は一定のインターバルで Stock を無限に返す iterator であり、stream data 生成に利用する。\ncase class Company(ticker: String, name: String) case class Stock(ticker: String, price: Double) /** * Iterator to generate unbounded stock data */ class UnboundedStocks extends Iterator[Stock] with Serializable { override def hasNext: Boolean = true // unbounded  override def next(): Stock = { Thread.sleep(1000) val tickers = Seq(\u0026#34;GOOGL\u0026#34;, \u0026#34;AAPL\u0026#34;, \u0026#34;FB\u0026#34;, \u0026#34;AMZN\u0026#34;) val ticker = tickers(Random.nextInt(tickers.size)) // one of GAFA  val price = 100 + Random.nextDouble() * 300 // random price  Stock(ticker, price) } } BroadcastProcessFunction 肝である BroadcastProcessFunction の実装。\npackage example import org.apache.flink.api.common.state.MapStateDescriptor import org.apache.flink.streaming.api.functions.co.BroadcastProcessFunction import org.apache.flink.util.Collector class StockBroadcastProcessFunction extends BroadcastProcessFunction[Stock, Company, (String, String, Double)] { private val StateDescriptor = new MapStateDescriptor( \u0026#34;CompanyState\u0026#34;, classOf[String], // ticker  classOf[String] // name  ) override def processElement(value: Stock, ctx: BroadcastProcessFunction[Stock, Company, (String, String, Double)]#ReadOnlyContext, out: Collector[(String, String, Double)]): Unit = { val companyName = ctx.getBroadcastState(StateDescriptor).get(value.ticker) out.collect((value.ticker, Option(companyName).getOrElse(\u0026#34;-\u0026#34;), value.price)) } override def processBroadcastElement(value: Company, ctx: BroadcastProcessFunction[Stock, Company, (String, String, Double)]#Context, out: Collector[(String, String, Double)]): Unit = { ctx.getBroadcastState(StateDescriptor).put(value.ticker, value.name) } } 実行結果 上記を実行すると以下のような stream と static が結合された結果レコードが流れ続ける。\n2\u0026gt; (FB,Facebook,158.76057838239333) 1\u0026gt; (GOOGL,Google,288.4271251901199) 2\u0026gt; (AAPL,Apple,191.00515338617706) 1\u0026gt; (FB,Facebook,121.98205452369652) 2\u0026gt; (FB,Facebook,140.05023554456997) この状態で会社情報が記載されている data/companies.csv を更新することを考える。\n例えば \u0026ldquo;GOOGL\u0026rdquo; の社名を \u0026ldquo;Google\u0026rdquo; から \u0026ldquo;Alphabet\u0026rdquo; に変更して保存してみた。\nするとしばらくしてその修正が反映された結果が流れてくるようになる。\n1\u0026gt; (GOOGL,Alphabet,288.1008081843843) 2\u0026gt; (AMZN,Amazon,137.11135563851838) 1\u0026gt; (GOOGL,Alphabet,121.78368168964735) 2\u0026gt; (FB,Facebook,236.53483047124948) 1\u0026gt; (FB,Facebook,220.44300865769645) static data の更新が反映されることが確認できた。\n今回は10秒に1回のインターバルで元ファイルを確認するようにファイルを読んでいるため、変更してからそれが反映されるまで最大10秒程度かかる。\n懸念点 join はできたが次のような懸念点がある。\n レコードの削除に対応していない  state を上書きしているだけなので companies.csv から削除されたレコードは感知できない   ファイルの更新時に処理が重くなる可能性がある  companies.csv の更新タイミングでその中の全レコードを処理してしまう   checkpoint が大きくなる  state が broadcast されているため、task ごとに重複した state が保存されてしまう See Important Considerations    まとめ このように broadcast state pattern によって stream data と static data との join 処理を行うことができた。\nただし、まだちゃんと調べていないが DataStream API ではなく Table API を使えばもう少しカジュアルな感じで近いことができるかもしれない。\n気が向いたらそちらも試してみる。\n追記 Table API を使った場合についての記事を追加しました。\n Apache Flink の Temporary Table Function を用いた stream data と static data の join  ","permalink":"https://soonraah.github.io/posts/flink-join-by-broadcast-state-pattern/","summary":"star schema における fact table と dimension table の join のようなことを Apache Flink におけるストリーム処理で行いたい。\nstream data と static data の join ということになる。\nただし dimension table 側も更新されるため、完全な static というわけではない。\nこのポストでは Flink v1.11 を前提とした。\njoin の方法 今回は DataStream API でこれを実現することを考える。\nFlink のドキュメントを読むと broadcast state pattern でできそうだ。\n The Broadcast State Pattern  やり方としては次のようになる。\n static data のファイルを FileProcessingMode.PROCESS_CONTINUOUSLY で読み込み DataStream 化 1 を broadcast() stream data の DataStream と 2 を connect()  static data を PROCESS_CONTINUOUSLY で読むのは変更を得るため。","title":"Apache Flink の Broadcast State Pattern を用いた stream data と static data の join"},{"content":"GitHub Flow ベースの開発においてはあまり大きな pull request を作ってほしくないという話。\nなんというか今更わざわざ言わなくてもいいんだけど…\n仕事で何度か大きな pull request が投げられているのを見てしまったので、それはあまりよくないよというのを自分でも指摘しやすくするためにまとめておく。\nReference 最初に参考資料を挙げておく。\n 100 Duck-Sized Pull Requests 「巨大プルリク1件vs細かいプルリク100件」問題を考える（翻訳） Optimal pull request size  これらを読めば特に私から言うこともないのだが…\nこれらに書いてあるとおりだが補足しておく。\nPull Request を小分けにしたときのメリット module を適切に切り出すモチベーションが得られる 次のような話がある。\n 共通化という考え方はアンチパターンを生み出すだけ説  これを理由に module を分けるべきところが分けられず、いろんなことができてしまうベタッと大きな module が生まれるのを見た。\nもちろんよく考えられていない共通化は駄目だが、上記ポストでは一方で\n ただし共通化という名の下におこなわれるのは「同じロジックを持つコードをまとめる」行為であって、抽象化のようにそのコード単位の意味を捉える作業はその範疇にない。抽象化というのはロジックを意味単位ごとにひとくくりにしていく行為で、これがどういうことなのかは次以降で述べていく。\u0026ndash; 共通化という考え方はアンチパターンを生み出すだけ説 - タオルケット体操 と述べており抽象化、つまりコードの意味を考慮した上で適切な単位でまとめておくことは否定していない。\npull request を小さく分けるという行為のためには module や機能を適度なまとまりで切り分けること、つまり抽象化を考えていくことが必要となる。\nしたがって何でもできてしまう大きな module が生まれるのを防ぐ方向に働く。\n(もちろんここで駄目な共通化がなされてしまうこともあるだろう)\nリリースまでの期間が短く済む 前述の参考資料においても pull request が大きいと\n Developers would put off reviews until they had time/energy and the development process would come to a halt.\u0026ndash; 100 Duck-Sized Pull Requests  development continues on the master branch, it often results in merge conflicts, rebases, and other fun.\u0026ndash; 100 Duck-Sized Pull Requests となると述べられている。\n仮にすぐにレビューされ、かつ conflict なども発生しなかっとしても大きな1つの pull request をレビューする場合とそれを3つに分けた場合の開発プロセスの進行を比較すると\n 大きな1つの pull request  全体の開発 全体のレビュー   3つに分割された pull request  part-1 の開発 part-1 のレビュー \u0026amp; part-2 の開発 part-2 のレビュー \u0026amp; part-3 の開発 part-3 のレビュー    のようになり、開発とレビューを並列で進められる部分があるので全体としての開発期間を短くすることができる。\nもちろんこれはうまく噛み合ったときの例だが。\n早めにフィードバックが得られるのも大きい。\nPull Request を小分けにしたときのデメリット 小分けにすることでレビュワーが全体感をつかみにくくなるというのはあるかもしれない。\npart-1 と part-2 で同じレビュワーになるとも限らない。\nこれに対しては開発に着手する前にまず全体のざっくりとした設計についてレビューを受けることで対応できる。\nこのステップを入れることで「とりあえず手を動かそう」となりにくくなる。\n手を動かすと仕事してる感が出るのでとりあえず手を動かしたくなりがちだが、ちょっと待てよと。\nまず何を作るか、全体の工程を考えましょうと。\n Working under these constraints causes developers to break problems down into incremental deliverables. It helps avoid the temptation of jumping into development without a clear plan.\u0026ndash; 100 Duck-Sized Pull Requests まとめ pull request を分けてくれ、頼む。\n","permalink":"https://soonraah.github.io/posts/no-more-huge-pull-request/","summary":"GitHub Flow ベースの開発においてはあまり大きな pull request を作ってほしくないという話。\nなんというか今更わざわざ言わなくてもいいんだけど…\n仕事で何度か大きな pull request が投げられているのを見てしまったので、それはあまりよくないよというのを自分でも指摘しやすくするためにまとめておく。\nReference 最初に参考資料を挙げておく。\n 100 Duck-Sized Pull Requests 「巨大プルリク1件vs細かいプルリク100件」問題を考える（翻訳） Optimal pull request size  これらを読めば特に私から言うこともないのだが…\nこれらに書いてあるとおりだが補足しておく。\nPull Request を小分けにしたときのメリット module を適切に切り出すモチベーションが得られる 次のような話がある。\n 共通化という考え方はアンチパターンを生み出すだけ説  これを理由に module を分けるべきところが分けられず、いろんなことができてしまうベタッと大きな module が生まれるのを見た。\nもちろんよく考えられていない共通化は駄目だが、上記ポストでは一方で\n ただし共通化という名の下におこなわれるのは「同じロジックを持つコードをまとめる」行為であって、抽象化のようにそのコード単位の意味を捉える作業はその範疇にない。抽象化というのはロジックを意味単位ごとにひとくくりにしていく行為で、これがどういうことなのかは次以降で述べていく。\u0026ndash; 共通化という考え方はアンチパターンを生み出すだけ説 - タオルケット体操 と述べており抽象化、つまりコードの意味を考慮した上で適切な単位でまとめておくことは否定していない。\npull request を小さく分けるという行為のためには module や機能を適度なまとまりで切り分けること、つまり抽象化を考えていくことが必要となる。\nしたがって何でもできてしまう大きな module が生まれるのを防ぐ方向に働く。\n(もちろんここで駄目な共通化がなされてしまうこともあるだろう)\nリリースまでの期間が短く済む 前述の参考資料においても pull request が大きいと\n Developers would put off reviews until they had time/energy and the development process would come to a halt.","title":"あまり大きな Pull Request を作ってほしくない"},{"content":"2020-07-31 にオンライン開催された Spark Meetup Tokyo #3 Online に参加した。\n感想などメモしておく。\n全体感 トピックとしては主に\n Spark 3.0 Spark + AI Summit 2020 Spark 周辺要素  といったところだろうか。\n最近のコミュニティの動向や関心を日本語で聞くことができてよかった。\n運営 \u0026amp; スピーカーの皆様、ありがとうございます。\n発表 発表資料は公開されたら追加していく。\nSPARK+AI Summit 2020 イベント概要 スピーカー: @tokyodataguy さん\n Summit は金融業界の参加者が増えているらしい Spark で最も使われている言語は Python とのことだったが、Databricks の notebook サービスの話だった  プロダクションコードではまた違うのだろう   Spark 3.0 の update をざっくりと Spark 周辺要素の話をざっくりと  Koalas Delta Lake Redash MLflow    Introducing Koalas 1.0   Introducing Koalas 1.0 (and 1.1)  from Takuya UESHIN  スピーカー: @ueshin さん\n What\u0026rsquo;s Koalas  open source の pure Python library pandas の API で Spark を動かせるようにする 小さいデータも大きなデータも同じように扱えるように   最近 v1.1 をリリース (個人的には pandas の API があまり好きではなく…)  SPARK+AI Summit 2020 のセッションハイライト   Spark + AI Summit 2020セッションのハイライト（Spark Meetup Tokyo #3 Online発表資料）  from NTT DATA Technology \u0026amp; Innovation  スピーカー: @masaru_dobashi さん\n Summit のセッションから case study 的なセッションを2つピックアップ USCIS の例  Lessons Learned from Modernizing USCIS Data Analytics Platform 古き良き Data Warehouse から Data Lake への移行 injection には Kafka も利用 諸々気にせずに気軽にデータをストレージに置きたい   Alibaba の例  Spark Structured Streming の上に SQL-like なものを載せた？ ストリームの mini-batch 処理の合間で compaction を行う (つらそう)   スライド中の「パイプラインの途中でモダンな技術に流し込めるかどうか？」という言葉が印象的だった  モダンなものに移行するとき現実的に重要    Spark v3.0の紹介 前半   Introduction new features in Spark 3.0  from Kazuaki Ishizaki  スピーカー: @kiszk さん\n SQL の性能に関わる7大機能の話  Query planの新しい表示方法 Join hintsの強化 Adaptive query execution Dynamic partitioning pruning nested column pruning \u0026amp; pushdown の強化 Aggregation のコード生成の改良 ScalaとJavaの新バージョンのサポート   実行計画が見やすくなるのは本当にうれしい 人がチューニングしていた部分が Adaptive Query Plan や Dynamic Partition Pruning で自動化されるのもうれしい  後半   Apache Spark 3.0新機能紹介 - 拡張機能やWebUI関連のアップデート（Spark Meetup Tokyo #3 Online）  from NTT DATA Technology \u0026amp; Innovation  スピーカー: @raspberry1123 さん\n Accelarator Aware Scheduling  Project Hydrogen   プラグイン機能  executor や driver の機能を user が拡張できる executor については Spark 2.4 からあったそうだが知らなかった…   Structured Straming web UI  ストリーム処理にはこういった chart が必要だと思う    SparkにPRを投げてみた   Sparkにプルリク投げてみた  from Noritaka Sekiyama  スピーカー: @moomindani さん\n スピーカーは AWS で Glue の開発をしている方 Glue は Spark に強く依存しているため、機能追加にモチベーションがあったとのこと 私も投げてみたい！  LT: td-spark internals: AirframeでSparkの機能を拡張するテクニック   td-spark internals: Extending Spark with Airframe - Spark Meetup Tokyo #3 2020  from Taro L. Saito  スピーカー: @taroleo さん\n Airframe とは Scala の application 開発用ツール群のようなもの？ Spark の機能を拡張  LT: Spark 3.1 Feature Expectation   LT: Spark 3.1 Feature Expectation  from Takeshi Yamamuro  スピーカー: @maropu さん\n 新機能  Support Filter Pushdown JSON  JSON の読み取りが早くなる   Better Handling for Node Shutdown  node 離脱時にその node が保持する shuffle や cache の情報が失われていた 計画された node の離脱に対して shuffle や cache ブロックを別 node に委譲      まとめ どんどん便利になっていくなという印象。\n手でパフォーマンスチューニングする要素はどんどん減っていくのだろう。\nDelta Lake が盛り上がっているように感じた。\nデータレイクについて勉強しないと…\n","permalink":"https://soonraah.github.io/posts/spark-meetup-tokyo-3/","summary":"2020-07-31 にオンライン開催された Spark Meetup Tokyo #3 Online に参加した。\n感想などメモしておく。\n全体感 トピックとしては主に\n Spark 3.0 Spark + AI Summit 2020 Spark 周辺要素  といったところだろうか。\n最近のコミュニティの動向や関心を日本語で聞くことができてよかった。\n運営 \u0026amp; スピーカーの皆様、ありがとうございます。\n発表 発表資料は公開されたら追加していく。\nSPARK+AI Summit 2020 イベント概要 スピーカー: @tokyodataguy さん\n Summit は金融業界の参加者が増えているらしい Spark で最も使われている言語は Python とのことだったが、Databricks の notebook サービスの話だった  プロダクションコードではまた違うのだろう   Spark 3.0 の update をざっくりと Spark 周辺要素の話をざっくりと  Koalas Delta Lake Redash MLflow    Introducing Koalas 1.0   Introducing Koalas 1.","title":"勉強会メモ: Spark Meetup Tokyo #3 Online"},{"content":"Spark バッチ処理の問題を調べていたら分離レベルという概念にたどりついた。\n分離レベルについて調べたので、Spark の問題の内容と絡めて記しておく。\n考えてみれば当たり前でたいした話ではない。\n分離レベルとは トランザクションの挙動についての暗黙の理解 アドホックな分析クエリやプロダクションコード中のクエリを書くとき、その単一のクエリのトランザクションにおいて「同時に実行されている別のクエリの commit 前の状態や commit 結果に影響され、このクエリの結果がおかしくなるかもしれない」ということは通常考えない。\nトランザクションはデータベースのある時点の状態に対して正しく処理される、というほぼ無意識の理解をおそらくほとんどの開発者が持っている。\n多くの場合この理解は間違っていない。\nそれはなぜかというと DB 等のデータ処理フレームワークがある強さの分離レベルを提供しているからである。\nいろいろな分離レベル ACID 特性のうちの1つ、分離性 (Isolation) の程度を表すのが分離レベル。\n トランザクション中に行われる操作の過程が他の操作から隠蔽されることを指し、日本語では分離性、独立性または隔離性ともいう。より形式的には、独立性とはトランザクション履歴が直列化されていることと言える。この性質と性能はトレードオフの関係にあるため、一般的にはこの性質の一部を緩和して実装される場合が多い。 \u0026ndash; Wikipedia ACID (コンピュータ科学) 分離レベルには名前のついたものがいくつかあり、分離性の保証の強さが異なる。\n具体的にはトランザクションの並行性の問題への対応力が異なる。\n名著「データ指向アプリケーションデザイン」の第7章で分離レベルについて詳しく述べられているので、以下ではそちらからの引用。\n分離レベルを弱い順に並べる。\n  read uncommitted\n このレベルではダーティライトは生じませんが、ダーティリードは妨げられません。\n   read committed\n  データベースからの読み取りを行った際に見えるデータは、コミットされたもののみであること（ダーティリードは生じない）。 データベースへの書き込みを行う場合、上書きするのはコミットされたデータのみであること（ダーティライトは生じない）。     snapshot isolation\n スナップショット分離の考え方は、それぞれのトランザクションがデータベースの一貫性のあるスナップショットから読み取りを行うというものです。すなわち、トランザクションが読み取るデータは、すべてそのトランザクションの開始時点のデータベースにコミット済みのものだけということです。\n   serializability\n この分離レベルはトランザクションが並行して実行されていても、最終的な答えはそれぞれが1つずつ順番に、並行ではなく実行された場合と同じになることを保証します。\n   日本語で「分離レベル」を検索すると snapshot isolation の代わりに repeatable read が出てくる事が多い。\nしかし repeatable read の名前は実装によって意味が違っていたりして扱いが難しいらしい。\n分離レベルと race condition の関係 以下に各分離レベルとトランザクションの並行性の問題 (race condition) の関係を示す。\n各 race condition の説明については割愛するが、複数のトランザクションが並行して実行されることにより起こりうる期待されていない挙動だと思えばよい。\n○はその分離レベルにおいてその race condition が発生しないことを示す。\n△は条件によっては発生する。\n    dirty read dirty write read skew (nonrepeatable read) lost update write skew phantom read     read uncommitted ○ - - - - -   read committed ○ ○ - - - -   snapshot isolation ○ ○ ○ △ - △   serializability ○ ○ ○ ○ ○ ○    下に行くほど強い分離レベルとなっている。\n分離レベルが強くなるほど race condition が発生しにくくなるが、一方で lock 等によりパフォーマンスが下がっていくというトレードオフがある。\n各種データベースの分離レベル ここでは MySQL と Hive においてどの分離レベルが提供されているかを見てみる。\nMySQL の場合 MySQL の分離レベルについては以下のドキュメントで述べられている。\n 15.7.2.1 Transaction Isolation Levels  MySQL (というか InnoDB?) では次の4つの分離レベルを設定することができる。\n READ UNCOMMITTED READ COMMITTED REPEATABLE READ (default) SERIALIZABLE  デフォルトの分離レベルは REPEATABLE READ だが、これは前述の snapshot isolation に相当するらしい。\n分離レベルは、例えば set transaction 構文により次のようにして指定できる。\nset transaction isolation level SERIALIZABLE; この場合は現在のセッション内で実行される次のトランザクションについて適用される。\nすべてのセッションやすべてのトランザクション等の指定もできる。\n詳しくは以下。\n 13.3.7 SET TRANSACTION Statement  Hive の場合 Hive についてはドキュメントに次のような記載がある。\n At this time only snapshot level isolation is supported. When a given query starts it will be provided with a consistent snapshot of the data.\u0026ndash; Hive Transactions Hive は snapshot isolation のみ提供しているとのこと。\n The default DummyTxnManager emulates behavior of old Hive versions: has no transactions and uses hive.lock.manager property to create lock manager for tables, partitions and databases.\u0026ndash; Hive Transactions lock は小さくとも partition の単位になるのだろうか。\nであるとすると予想通りだが MySQL よりもいかつい挙動になっている。\nこのように多くの DB では snapshot isolation の分離レベルが基本となっている。\nSpark クエリの分離レベル では Spark のクエリはどうだろうか。\nここからようやく本題となる。\nread committed 相当 Spark において DataFrame を用いたデータ処理を記述するとき、それは1つの SQL クエリを書くのと近い感覚になる。\nそもそも DataFrame は SQL-like な使い心地を目的として作られた API だから当然だ。\nDataFrame で記述された処理は実行時に RDD として翻訳されるが、分離レベルを考えるにあたって RDD の特性がキーとなってくる。\n By default, each transformed RDD may be recomputed each time you run an action on it.\u0026ndash; RDD Operations あまり良い説明を見つけられなかったが、1回の action を伴う処理においても同じ RDD が複数回参照されるとき、その RDD までの計算は通常やり直されることになる。\nしたがって例えば self join のようなことをするとき、同じデータソースを2回読みに行くということが起こってしまう。\nHDFS や S3 上のファイル、JDBC 経由の外部 DB など Spark は様々なデータソースを扱うことができるが、通常 Spark がその2回の読み込みに対して lock をかけたりすることはできない。\nつまり non-repeatable read や phantom read を防ぐことができない。\nread committed という弱い分離レベルに相当するということになってしまう。\n分離レベルという言葉はトランザクションという概念に対して使われるものであり、DataFrame のクエリをトランザクションと呼んでいいのかはわからない。\nなので分離レベルという言葉をここで使うのが適切でないかもしれないということは述べておく。\n検証 MySQL からデータを読み取り Spark で処理することを考える。\nまず local の MySQL で次のような table を用意する。\nmysql\u0026gt; describe employees; +---------------+---------+------+-----+---------+-------+ | Field | Type | Null | Key | Default | Extra | +---------------+---------+------+-----+---------+-------+ | id | int(11) | NO | PRI | NULL | | | salary | int(11) | YES | | NULL | | | department_id | int(11) | YES | | NULL | | +---------------+---------+------+-----+---------+-------+ 3 rows in set (0.03 sec) 部署 (department) ごとの給料 (salary) の平均から各従業員の給料がどれくらい離れているかの差分を見たいものとする。\nSpark のコードは次のようになる。\nSpark のバージョンはこれを書いている時点での最新 3.0.0 とした。\npackage com.example import org.apache.spark.sql.functions.avg import org.apache.spark.sql.SparkSession object IsolationLevelExperiment { def main(args: Array[String]): Unit = { // Prepare SparkSession  val spark = SparkSession .builder() .appName(\u0026#34;Isolation Level Experiment\u0026#34;) .master(\u0026#34;local[*]\u0026#34;) .getOrCreate() import spark.implicits._ // Read from MySQL  val dfEmployee = spark .read .format(\u0026#34;jdbc\u0026#34;) .option(\u0026#34;url\u0026#34;, \u0026#34;jdbc:mysql://localhost\u0026#34;) .option(\u0026#34;dbtable\u0026#34;, \u0026#34;db_name.employees\u0026#34;) .option(\u0026#34;user\u0026#34;, \u0026#34;user_name\u0026#34;) .option(\u0026#34;password\u0026#34;, \u0026#34;********\u0026#34;) .option(\u0026#34;driver\u0026#34;, \u0026#34;com.mysql.cj.jdbc.Driver\u0026#34;) .load .cache // Get average salary  val dfAvg = dfEmployee .groupBy($\u0026#34;department_id\u0026#34;) .agg(avg($\u0026#34;salary\u0026#34;).as(\u0026#34;avg_salary\u0026#34;)) // Calculate diff  val dfResult = dfEmployee .as(\u0026#34;e\u0026#34;) .join( dfAvg.as(\u0026#34;a\u0026#34;), $\u0026#34;e.department_id\u0026#34; === $\u0026#34;a.department_id\u0026#34;, \u0026#34;left_outer\u0026#34; ) .select( $\u0026#34;e.id\u0026#34;, $\u0026#34;e.department_id\u0026#34;, ($\u0026#34;e.salary\u0026#34; - $\u0026#34;a.avg_salary\u0026#34;).as(\u0026#34;salary_diff\u0026#34;) ) // Output results  dfResult.show spark.stop() } } このコードを実行する前に MySQL の general query log を ON にする。\nmysql\u0026gt; set global general_log = 'ON'; Query OK, 0 rows affected (0.02 sec) mysql\u0026gt; show global variables like 'general_log%'; +------------------+--------------------------------------+ | Variable_name | Value | +------------------+--------------------------------------+ | general_log | ON | | general_log_file | /usr/local/var/mysql/MacBook-Pro.log | +------------------+--------------------------------------+ 2 rows in set (0.01 sec) これによって MySQL に対して発行されたクエリがログとして記録されるようになる。\n直感的に snapshot isolation になっているのであれば MySQL に対する select 文は1回だけ発行されるはずである。\nしかし前述のとおり RDD や DataFrame の処理は途中の状態を通常保存せず、同じ RDD や DataFrame を参照していたとしても再計算される。\n上記コードの例だと dfEmployee が2回参照されている。\nコードを実行すると general query log には次のように、データ取得のための select 文が2つ記録されていた。\nそれぞれ join() の左右の table のデータソースを示している。\n8 Query SELECT `id`,`salary`,`department_id` FROM test_fout_dsp.employees 7 Query SELECT `salary`,`department_id` FROM test_fout_dsp.employees WHERE (`department_id` IS NOT NULL) 2つの select 文はそれぞれ別のクエリ、トランザクションとして発行されている。\nしたがって前者の select 文が実行された後、後者の select 文が実行される前に別のトランザクションにより employees が更新されたり挿入・削除されたりすると non-repeatable read や phantom read が発生してしまうのである。\n今回はデータソースへのアクセスを確認するためにデータソースとして MySQL を使ったが、同じことはファイルや他の DB など別のデータソースで起こりうる。\n回避策 プロダクト運用上、non-repeatable read や phantom read が発生しうる状況というのは多くの場合で厄介である。\n一時的なデータソースの状態に依存して問題が発生するため、バグの原因追求がとても困難だからだ。\n見た目上の分離レベルを強くし、これらを避けるには2つの方法が考えられる。\nimmutable なデータにのみアクセスする 単純な話で non-repeatable read や phantom read が発生するようなデータソースを参照しなければよい。\n例えばユーザの行動ログのような蓄積されていくデータが hour 単位で partitioning されているような場合、基本的に過去の partition に対しては変更や挿入・削除は行われない。\nこのような partition にアクセスする分には前述のような厄介な問題は起こらない。\ncache する データソースから読み取った結果の DataFrame に対して cache() または persist() をするとよい。\n Spark SQL can cache tables using an in-memory columnar format by calling spark.catalog.cacheTable(\u0026quot;tableName\u0026quot;) or dataFrame.cache().\u0026ndash; Caching Data In Memory 前述のコードで dfEmployee に対して .cache() をした場合、MySQL へのデータ取得のための select 文の発行は1回になった。\n大きなデータソースを cache() するときだけメモリや HDD 容量に気をつけておきたい。\nまとめ DataFrame はいわゆる RDBMS を操作しているように見えてしまうところが難しいところだろうか。\n「データ指向アプリケーションデザイン」に至極真っ当なことが書いてあったので、その言葉を借りて締めておく。\n 何も考えずにツールを信じて依存するのではなく、並行性の問題にはどういったものがあるのか、そしてそれらを回避するにはどうしたら良いのかを、しっかり理解しなければなりません。そうすれば、信頼性があり、正しく動作するアプリケーションを手の届くツールを使って構築できるようになります。\u0026ndash; Martin Kleppmann データ指向アプリケーションデザイン ","permalink":"https://soonraah.github.io/posts/weak_isolation_level_of_dataframe/","summary":"Spark バッチ処理の問題を調べていたら分離レベルという概念にたどりついた。\n分離レベルについて調べたので、Spark の問題の内容と絡めて記しておく。\n考えてみれば当たり前でたいした話ではない。\n分離レベルとは トランザクションの挙動についての暗黙の理解 アドホックな分析クエリやプロダクションコード中のクエリを書くとき、その単一のクエリのトランザクションにおいて「同時に実行されている別のクエリの commit 前の状態や commit 結果に影響され、このクエリの結果がおかしくなるかもしれない」ということは通常考えない。\nトランザクションはデータベースのある時点の状態に対して正しく処理される、というほぼ無意識の理解をおそらくほとんどの開発者が持っている。\n多くの場合この理解は間違っていない。\nそれはなぜかというと DB 等のデータ処理フレームワークがある強さの分離レベルを提供しているからである。\nいろいろな分離レベル ACID 特性のうちの1つ、分離性 (Isolation) の程度を表すのが分離レベル。\n トランザクション中に行われる操作の過程が他の操作から隠蔽されることを指し、日本語では分離性、独立性または隔離性ともいう。より形式的には、独立性とはトランザクション履歴が直列化されていることと言える。この性質と性能はトレードオフの関係にあるため、一般的にはこの性質の一部を緩和して実装される場合が多い。 \u0026ndash; Wikipedia ACID (コンピュータ科学) 分離レベルには名前のついたものがいくつかあり、分離性の保証の強さが異なる。\n具体的にはトランザクションの並行性の問題への対応力が異なる。\n名著「データ指向アプリケーションデザイン」の第7章で分離レベルについて詳しく述べられているので、以下ではそちらからの引用。\n分離レベルを弱い順に並べる。\n  read uncommitted\n このレベルではダーティライトは生じませんが、ダーティリードは妨げられません。\n   read committed\n  データベースからの読み取りを行った際に見えるデータは、コミットされたもののみであること（ダーティリードは生じない）。 データベースへの書き込みを行う場合、上書きするのはコミットされたデータのみであること（ダーティライトは生じない）。     snapshot isolation\n スナップショット分離の考え方は、それぞれのトランザクションがデータベースの一貫性のあるスナップショットから読み取りを行うというものです。すなわち、トランザクションが読み取るデータは、すべてそのトランザクションの開始時点のデータベースにコミット済みのものだけということです。\n   serializability\n この分離レベルはトランザクションが並行して実行されていても、最終的な答えはそれぞれが1つずつ順番に、並行ではなく実行された場合と同じになることを保証します。\n   日本語で「分離レベル」を検索すると snapshot isolation の代わりに repeatable read が出てくる事が多い。","title":"Spark DataFrame クエリの弱い分離レベル"},{"content":"東京の IT 企業で働く中年エンジニアが勉強したことや考えていることなどを書きます。\nこのブログは Hugo で作成しました。\nTheme には PaperMod を利用しています。\n","permalink":"https://soonraah.github.io/about/","summary":"東京の IT 企業で働く中年エンジニアが勉強したことや考えていることなどを書きます。\nこのブログは Hugo で作成しました。\nTheme には PaperMod を利用しています。","title":"About"},{"content":"はじめに Apache Spark 3.0.0 がリリースされました。\n Spark Release 3.0.0  release note を見て個人的に気になったところなど簡単に調べました。\n書いてみると Databricks の記事へのリンクばっかになってしまった…\n全体感 こちらの記事を読めば全体感は OK.\n Introducing Apache Spark 3.0  公式の release note には\n Python is now the most widely used language on Spark.\n とあってそうなん？ってなったけど、こちらの記事だと\n Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.\n と書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。\nプロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。\n[Project Hydrogen] Accelerator-aware Scheduler  SPARK-24615  Spark 上で deep learning できるようにすることを目指す Project Hydrogen、その3つの大きな目標のうちの一つ。\n Big Data LDN 2018: PROJECT HYDROGEN: UNIFYING AI WITH APACHE SPARK  YARN や Kubernetes では GPU や FPGA を扱えるようになっているので Spark でも扱えるようにしたいというモチベーション。\nSpark のドキュメント によると\n For example, the user wants to request 2 GPUs for each executor. The user can just specify spark.executor.resource.gpu.amount=2 and Spark will handle requesting yarn.io/gpu resource type from YARN.\n のようにして executor に GPU リソースを要求できるみたいです。\nAdaptive Query Execution  SPARK-31412  平たく言うと実行時に得られる統計情報を使って plan を最適化すると、静的に生成された plan より効率化できるよねという話。\nspark.sql.adaptive.enabled=true にすることで有効になります。\n処理の途中で中間生成物が materialize されるタイミングで、その時点の統計情報を使って残りの処理を最適化する、というのを繰り返します。\nSpark 3.0.0 では以下3つの AQE が実装されました。\n Coalescing Post Shuffle Partitions Converting sort-merge join to broadcast join Optimizing Skew Join  Spark 2 以前だとこのあたりは実行しつつチューニングするような運用になりがちでした。\n特に skew の解消は salt を追加したりなど面倒だったりします。\nこれらが自動で最適化されるというのは運用上うれしいところ。\n急なデータ傾向の変化に対しても自動で最適化して対応できるという面があります。\nAQE に関してもやはり Databricks の解説記事がわかりやすいです。\n図もいい感じ。\n Adaptive Query Execution: Speeding Up Spark SQL at Runtime  Dynamic Partition Pruning  SPARK-11150  こちらも AQE 同様にクエリのパフォーマンスを改善する目的で導入されたもの。\n改善幅は AQE より大きいようです。\nやはり実行時の情報を使って partition pruning を行い、不要な partition の参照を減らすという方法。\n主に star schema における join 時のように、静的には partition pruning が行えない場合を想定しています。\n比較的小さいことが多いと思われる dimension table 側を broadcast する broadcast join において、broadcast された情報を fact table の partition pruning に利用するというやり口。\n Dynamic Partition Pruning in Apache Spark  Structured Streaming UI  SPARK-29543  \u0026ldquo;Structured Streaming\u0026rdquo; というタブが UI に追加された件。\nSpark のドキュメントに例があります。\n  Structured Streaming Tab\n  Spark 2.4 系では Structured Streaming を動かしていてもせいぜい job や stage が増えていくという味気ないものしか見えませんでした。\nSpark 3.0.0 で実際に動かしてみたけど欲しかったやつ！という感じ。\nストリーム処理では入力データ量の変化の可視化がマストだと思ってます。\nCatalog plugin API  SPARK-31121 SPIP: Spark API for Table Metadata  これまでは CTAS (Create Table As Select) の操作はあったが、外部のデータソースに対して DDL 的な操作をする API が足りていませんでした。\nCTAS も挙動に実装依存の曖昧さがありました。\nそこで create, alter, load, drop 等のテーブル操作をできるようにしたという話。\nドキュメントの DDL Statements のあたりを読め何ができるかわかります。\n以前のバージョンでも一部のデータソースについてはできた模様 (ex. Hive)。\n今の自分の業務では Spark から DDL を扱うようなことはしないのでそれほど恩恵は感じられません。\nnotebook からアドホックな Spark のバッチを動かすというような使い方をしていればうれしいかもしれません。\nAdd an API that allows a user to define and observe arbitrary metrics on batch and streaming queries  SPARK-29345  クエリの途中の段階で何らかの metrics を仕込んでおいて callback 的にその metrics にアクセスできる仕組み。\nDataset#observe() の API ドキュメント を読むのが一番早いです。\nこの例ではストリーム処理を扱っているが、バッチ処理の例を自分で書いて試してみました。\n// Register listener spark .listenerManager .register(new QueryExecutionListener { override def onSuccess(funcName: String, qe: QueryExecution, durationNs: Long): Unit = { val num = qe.observedMetrics .get(\u0026#34;my_metrics\u0026#34;) .map(_.getAs[Long](\u0026#34;num\u0026#34;)) .getOrElse(-100.0) println(s\u0026#34;num of data: $num\u0026#34;) } override def onFailure(funcName: String, qe: QueryExecution, exception: Exception): Unit = {} }) // Make DataFrame val df = Seq .range(0, 1000) .map((_, Seq(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;)(Random.nextInt(3)), math.random())) .toDF(\u0026#34;id\u0026#34;, \u0026#34;type\u0026#34;, \u0026#34;value\u0026#34;) // Observe and process val dfResult = df .observe(\u0026#34;my_metrics\u0026#34;, count($\u0026#34;*\u0026#34;).as(\u0026#34;num\u0026#34;)) .groupBy($\u0026#34;type\u0026#34;) .agg(avg($\u0026#34;value\u0026#34;).as(\u0026#34;avg_value\u0026#34;)) // Run dfResult.show これを動かしたときの出力は次のようになりました。\n+----+------------------+ |type| avg_value| +----+------------------+ | c|0.5129435063033314| | b|0.4693004460694317| | a|0.4912087482418599| +----+------------------+ num of data: 1000 observe() はその出力の DataFrame に対して schema やデータの中身を変更することはありません。\nmetrics を仕込むのみ。\nlogical plan を出力してみると observe() を入れることにより途中に CollectMetrics という plan が挿入されていました。\nソースを見ると accumulator を使っている模様。\nなので observe() の集計のみで一度 job が動くわけではなく、クエリが2回走るという感じではありません。\n全体の処理の中でひっそりと accumulator で脇で集計しておくといった趣でしょうか。\nこれは結構有用だと思います。\n例えば何らかの集計をやるにしてもその最初や途中で、例えば入力データは何件あったか？みたいなことをログに出しておきたいことがあります。\nというか accumulator で頑張ってそういうものを作ったことがある…\nこれがフレームワーク側でサポートされるのはうれしいです。\nまとめ 2つのダイナミックな最適化に期待大。\n気が向いたら追加でまた調べるかもしれません。\n","permalink":"https://soonraah.github.io/posts/study-spark-3-0-0/","summary":"はじめに Apache Spark 3.0.0 がリリースされました。\n Spark Release 3.0.0  release note を見て個人的に気になったところなど簡単に調べました。\n書いてみると Databricks の記事へのリンクばっかになってしまった…\n全体感 こちらの記事を読めば全体感は OK.\n Introducing Apache Spark 3.0  公式の release note には\n Python is now the most widely used language on Spark.\n とあってそうなん？ってなったけど、こちらの記事だと\n Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.","title":"Apache Spark 3.0.0 について調べた"}]