<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Apache Spark 3.0.0 について調べた | Froglog</title>
<meta name=keywords content="Apache Spark"><meta name=description content="はじめに
Apache Spark 3.0.0 がリリースされました。

Spark Release 3.0.0

release note を見て個人的に気になったところなど簡単に調べました。
書いてみると Databricks の記事へのリンクばっかになってしまった…
全体感
こちらの記事を読めば全体感は OK.

Introducing Apache Spark 3.0

公式の release note には

Python is now the most widely used language on Spark.
とあってそうなん？ってなったけど、こちらの記事だと

Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.
と書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。
プロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/study-spark-3-0-0/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ja href=https://soonraah.github.io/posts/study-spark-3-0-0/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://soonraah.github.io/posts/study-spark-3-0-0/"><meta property="og:site_name" content="Froglog"><meta property="og:title" content="Apache Spark 3.0.0 について調べた"><meta property="og:description" content="はじめに Apache Spark 3.0.0 がリリースされました。
Spark Release 3.0.0 release note を見て個人的に気になったところなど簡単に調べました。
書いてみると Databricks の記事へのリンクばっかになってしまった…
全体感 こちらの記事を読めば全体感は OK.
Introducing Apache Spark 3.0 公式の release note には
Python is now the most widely used language on Spark.
とあってそうなん？ってなったけど、こちらの記事だと
Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.
と書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。
プロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。"><meta property="og:locale" content="ja"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-07-12T11:30:00+09:00"><meta property="article:modified_time" content="2020-07-12T11:30:00+09:00"><meta property="article:tag" content="Apache Spark"><meta property="og:image" content="https://soonraah.github.io/image/logo/Apache_Spark_logo.svg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/logo/Apache_Spark_logo.svg"><meta name=twitter:title content="Apache Spark 3.0.0 について調べた"><meta name=twitter:description content="はじめに
Apache Spark 3.0.0 がリリースされました。

Spark Release 3.0.0

release note を見て個人的に気になったところなど簡単に調べました。
書いてみると Databricks の記事へのリンクばっかになってしまった…
全体感
こちらの記事を読めば全体感は OK.

Introducing Apache Spark 3.0

公式の release note には

Python is now the most widely used language on Spark.
とあってそうなん？ってなったけど、こちらの記事だと

Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.
と書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。
プロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soonraah.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Apache Spark 3.0.0 について調べた","item":"https://soonraah.github.io/posts/study-spark-3-0-0/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Spark 3.0.0 について調べた","name":"Apache Spark 3.0.0 について調べた","description":"はじめに Apache Spark 3.0.0 がリリースされました。\nSpark Release 3.0.0 release note を見て個人的に気になったところなど簡単に調べました。\n書いてみると Databricks の記事へのリンクばっかになってしまった…\n全体感 こちらの記事を読めば全体感は OK.\nIntroducing Apache Spark 3.0 公式の release note には\nPython is now the most widely used language on Spark.\nとあってそうなん？ってなったけど、こちらの記事だと\nPython is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.\nと書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。\nプロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。\n","keywords":["Apache Spark"],"articleBody":"はじめに Apache Spark 3.0.0 がリリースされました。\nSpark Release 3.0.0 release note を見て個人的に気になったところなど簡単に調べました。\n書いてみると Databricks の記事へのリンクばっかになってしまった…\n全体感 こちらの記事を読めば全体感は OK.\nIntroducing Apache Spark 3.0 公式の release note には\nPython is now the most widely used language on Spark.\nとあってそうなん？ってなったけど、こちらの記事だと\nPython is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.\nと書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。\nプロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。\n[Project Hydrogen] Accelerator-aware Scheduler SPARK-24615 Spark 上で deep learning できるようにすることを目指す Project Hydrogen、その3つの大きな目標のうちの一つ。\nBig Data LDN 2018: PROJECT HYDROGEN: UNIFYING AI WITH APACHE SPARK YARN や Kubernetes では GPU や FPGA を扱えるようになっているので Spark でも扱えるようにしたいというモチベーション。\nSpark のドキュメント によると\nFor example, the user wants to request 2 GPUs for each executor. The user can just specify spark.executor.resource.gpu.amount=2 and Spark will handle requesting yarn.io/gpu resource type from YARN.\nのようにして executor に GPU リソースを要求できるみたいです。\nAdaptive Query Execution SPARK-31412 平たく言うと実行時に得られる統計情報を使って plan を最適化すると、静的に生成された plan より効率化できるよねという話。\nspark.sql.adaptive.enabled=true にすることで有効になります。\n処理の途中で中間生成物が materialize されるタイミングで、その時点の統計情報を使って残りの処理を最適化する、というのを繰り返します。\nSpark 3.0.0 では以下3つの AQE が実装されました。\nCoalescing Post Shuffle Partitions Converting sort-merge join to broadcast join Optimizing Skew Join Spark 2 以前だとこのあたりは実行しつつチューニングするような運用になりがちでした。\n特に skew の解消は salt を追加したりなど面倒だったりします。\nこれらが自動で最適化されるというのは運用上うれしいところ。\n急なデータ傾向の変化に対しても自動で最適化して対応できるという面があります。\nAQE に関してもやはり Databricks の解説記事がわかりやすいです。\n図もいい感じ。\nAdaptive Query Execution: Speeding Up Spark SQL at Runtime Dynamic Partition Pruning SPARK-11150 こちらも AQE 同様にクエリのパフォーマンスを改善する目的で導入されたもの。\n改善幅は AQE より大きいようです。\nやはり実行時の情報を使って partition pruning を行い、不要な partition の参照を減らすという方法。\n主に star schema における join 時のように、静的には partition pruning が行えない場合を想定しています。\n比較的小さいことが多いと思われる dimension table 側を broadcast する broadcast join において、broadcast された情報を fact table の partition pruning に利用するというやり口。\nDynamic Partition Pruning in Apache Spark Structured Streaming UI SPARK-29543 “Structured Streaming” というタブが UI に追加された件。\nSpark のドキュメントに例があります。\nStructured Streaming Tab\nSpark 2.4 系では Structured Streaming を動かしていてもせいぜい job や stage が増えていくという味気ないものしか見えませんでした。\nSpark 3.0.0 で実際に動かしてみたけど欲しかったやつ！という感じ。\nストリーム処理では入力データ量の変化の可視化がマストだと思ってます。\nCatalog plugin API SPARK-31121 SPIP: Spark API for Table Metadata これまでは CTAS (Create Table As Select) の操作はあったが、外部のデータソースに対して DDL 的な操作をする API が足りていませんでした。\nCTAS も挙動に実装依存の曖昧さがありました。\nそこで create, alter, load, drop 等のテーブル操作をできるようにしたという話。\nドキュメントの DDL Statements のあたりを読め何ができるかわかります。\n以前のバージョンでも一部のデータソースについてはできた模様 (ex. Hive)。\n今の自分の業務では Spark から DDL を扱うようなことはしないのでそれほど恩恵は感じられません。\nnotebook からアドホックな Spark のバッチを動かすというような使い方をしていればうれしいかもしれません。\nAdd an API that allows a user to define and observe arbitrary metrics on batch and streaming queries SPARK-29345 クエリの途中の段階で何らかの metrics を仕込んでおいて callback 的にその metrics にアクセスできる仕組み。\nDataset#observe() の API ドキュメント を読むのが一番早いです。\nこの例ではストリーム処理を扱っているが、バッチ処理の例を自分で書いて試してみました。\n// Register listener spark .listenerManager .register(new QueryExecutionListener { override def onSuccess(funcName: String, qe: QueryExecution, durationNs: Long): Unit = { val num = qe.observedMetrics .get(\"my_metrics\") .map(_.getAs[Long](\"num\")) .getOrElse(-100.0) println(s\"num of data: $num\") } override def onFailure(funcName: String, qe: QueryExecution, exception: Exception): Unit = {} }) // Make DataFrame val df = Seq .range(0, 1000) .map((_, Seq(\"a\", \"b\", \"c\")(Random.nextInt(3)), math.random())) .toDF(\"id\", \"type\", \"value\") // Observe and process val dfResult = df .observe(\"my_metrics\", count($\"*\").as(\"num\")) .groupBy($\"type\") .agg(avg($\"value\").as(\"avg_value\")) // Run dfResult.show これを動かしたときの出力は次のようになりました。\n+----+------------------+ |type| avg_value| +----+------------------+ | c|0.5129435063033314| | b|0.4693004460694317| | a|0.4912087482418599| +----+------------------+ num of data: 1000 observe() はその出力の DataFrame に対して schema やデータの中身を変更することはありません。\nmetrics を仕込むのみ。\nlogical plan を出力してみると observe() を入れることにより途中に CollectMetrics という plan が挿入されていました。\nソースを見ると accumulator を使っている模様。\nなので observe() の集計のみで一度 job が動くわけではなく、クエリが2回走るという感じではありません。\n全体の処理の中でひっそりと accumulator で脇で集計しておくといった趣でしょうか。\nこれは結構有用だと思います。\n例えば何らかの集計をやるにしてもその最初や途中で、例えば入力データは何件あったか？みたいなことをログに出しておきたいことがあります。\nというか accumulator で頑張ってそういうものを作ったことがある…\nこれがフレームワーク側でサポートされるのはうれしいです。\nまとめ 2つのダイナミックな最適化に期待大。\n気が向いたら追加でまた調べるかもしれません。\n","wordCount":"477","inLanguage":"ja","image":"https://soonraah.github.io/image/logo/Apache_Spark_logo.svg","datePublished":"2020-07-12T11:30:00+09:00","dateModified":"2020-07-12T11:30:00+09:00","author":{"@type":"Person","name":"soonraah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soonraah.github.io/posts/study-spark-3-0-0/"},"publisher":{"@type":"Organization","name":"Froglog","logo":{"@type":"ImageObject","url":"https://soonraah.github.io/favicon2.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soonraah.github.io/>ホーム</a>&nbsp;»&nbsp;<a href=https://soonraah.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Apache Spark 3.0.0 について調べた</h1><div class=post-meta><span title='2020-07-12 11:30:00 +0900 JST'>7月 12, 2020</span>&nbsp;·&nbsp;soonraah</div></header><figure class=entry-cover><img loading=eager src=https://soonraah.github.io/image/logo/Apache_Spark_logo.svg alt="Apache Spark"><figcaption><a href=https://spark.apache.org/>Apache Spark</a></figcaption></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目次</span></summary><div class=inner><ul><li><a href=#%e3%81%af%e3%81%98%e3%82%81%e3%81%ab aria-label=はじめに>はじめに</a></li><li><a href=#%e5%85%a8%e4%bd%93%e6%84%9f aria-label=全体感>全体感</a></li><li><a href=#project-hydrogen-accelerator-aware-scheduler aria-label="[Project Hydrogen] Accelerator-aware Scheduler">[Project Hydrogen] Accelerator-aware Scheduler</a></li><li><a href=#adaptive-query-execution aria-label="Adaptive Query Execution">Adaptive Query Execution</a></li><li><a href=#dynamic-partition-pruning aria-label="Dynamic Partition Pruning">Dynamic Partition Pruning</a></li><li><a href=#structured-streaming-ui aria-label="Structured Streaming UI">Structured Streaming UI</a></li><li><a href=#catalog-plugin-api aria-label="Catalog plugin API">Catalog plugin API</a></li><li><a href=#add-an-api-that-allows-a-user-to-define-and-observe-arbitrary-metrics-on-batch-and-streaming-queries aria-label="Add an API that allows a user to define and observe arbitrary metrics on batch and streaming queries">Add an API that allows a user to define and observe arbitrary metrics on batch and streaming queries</a></li><li><a href=#%e3%81%be%e3%81%a8%e3%82%81 aria-label=まとめ>まとめ</a></li></ul></div></details></div><div class=post-content><h2 id=はじめに>はじめに<a hidden class=anchor aria-hidden=true href=#はじめに>#</a></h2><p>Apache Spark 3.0.0 がリリースされました。</p><ul><li><a href=https://spark.apache.org/releases/spark-release-3-0-0.html>Spark Release 3.0.0</a></li></ul><p>release note を見て個人的に気になったところなど簡単に調べました。<br>書いてみると Databricks の記事へのリンクばっかになってしまった…</p><h2 id=全体感>全体感<a hidden class=anchor aria-hidden=true href=#全体感>#</a></h2><p>こちらの記事を読めば全体感は OK.</p><ul><li><a href=https://databricks.com/jp/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html>Introducing Apache Spark 3.0</a></li></ul><p>公式の release note には</p><blockquote><p>Python is now the most widely used language on Spark.</p></blockquote><p>とあってそうなん？ってなったけど、こちらの記事だと</p><blockquote><p>Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.</p></blockquote><p>と書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。<br>プロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。</p><h2 id=project-hydrogen-accelerator-aware-scheduler>[Project Hydrogen] Accelerator-aware Scheduler<a hidden class=anchor aria-hidden=true href=#project-hydrogen-accelerator-aware-scheduler>#</a></h2><ul><li><a href=https://issues.apache.org/jira/browse/SPARK-24615>SPARK-24615</a></li></ul><p>Spark 上で deep learning できるようにすることを目指す Project Hydrogen、その3つの大きな目標のうちの一つ。</p><ul><li><a href=https://www.slideshare.net/MatthewStubbs6/big-data-ldn-2018-project-hydrogen-unifying-ai-with-apache-spark/26>Big Data LDN 2018: PROJECT HYDROGEN: UNIFYING AI WITH APACHE SPARK</a></li></ul><p>YARN や Kubernetes では GPU や FPGA を扱えるようになっているので Spark でも扱えるようにしたいというモチベーション。<br><a href=https://spark.apache.org/docs/3.0.0/running-on-yarn.html#resource-allocation-and-configuration-overview>Spark のドキュメント</a> によると</p><blockquote><p>For example, the user wants to request 2 GPUs for each executor. The user can just specify <code>spark.executor.resource.gpu.amount=2</code> and Spark will handle requesting <code>yarn.io/gpu</code> resource type from YARN.</p></blockquote><p>のようにして executor に GPU リソースを要求できるみたいです。</p><h2 id=adaptive-query-execution>Adaptive Query Execution<a hidden class=anchor aria-hidden=true href=#adaptive-query-execution>#</a></h2><ul><li><a href=https://issues.apache.org/jira/browse/SPARK-31412>SPARK-31412</a></li></ul><p>平たく言うと実行時に得られる統計情報を使って plan を最適化すると、静的に生成された plan より効率化できるよねという話。<br><code>spark.sql.adaptive.enabled=true</code> にすることで有効になります。</p><p>処理の途中で中間生成物が materialize されるタイミングで、その時点の統計情報を使って残りの処理を最適化する、というのを繰り返します。</p><p>Spark 3.0.0 では以下3つの AQE が実装されました。</p><ul><li>Coalescing Post Shuffle Partitions</li><li>Converting sort-merge join to broadcast join</li><li>Optimizing Skew Join</li></ul><p>Spark 2 以前だとこのあたりは実行しつつチューニングするような運用になりがちでした。<br>特に skew の解消は salt を追加したりなど面倒だったりします。<br>これらが自動で最適化されるというのは運用上うれしいところ。<br>急なデータ傾向の変化に対しても自動で最適化して対応できるという面があります。</p><p>AQE に関してもやはり Databricks の解説記事がわかりやすいです。<br>図もいい感じ。</p><ul><li><a href=https://databricks.com/blog/2020/05/29/adaptive-query-execution-speeding-up-spark-sql-at-runtime.html>Adaptive Query Execution: Speeding Up Spark SQL at Runtime</a></li></ul><h2 id=dynamic-partition-pruning>Dynamic Partition Pruning<a hidden class=anchor aria-hidden=true href=#dynamic-partition-pruning>#</a></h2><ul><li><a href=https://issues.apache.org/jira/browse/SPARK-11150>SPARK-11150</a></li></ul><p>こちらも AQE 同様にクエリのパフォーマンスを改善する目的で導入されたもの。<br>改善幅は AQE より大きいようです。<br>やはり実行時の情報を使って partition pruning を行い、不要な partition の参照を減らすという方法。</p><p>主に <a href=https://ja.wikipedia.org/wiki/%E3%82%B9%E3%82%BF%E3%83%BC%E3%82%B9%E3%82%AD%E3%83%BC%E3%83%9E>star schema</a> における join 時のように、静的には partition pruning が行えない場合を想定しています。<br>比較的小さいことが多いと思われる dimension table 側を broadcast する broadcast join において、broadcast された情報を fact table の partition pruning に利用するというやり口。</p><ul><li><a href=https://www.slideshare.net/databricks/dynamic-partition-pruning-in-apache-spark>Dynamic Partition Pruning in Apache Spark</a></li></ul><h2 id=structured-streaming-ui>Structured Streaming UI<a hidden class=anchor aria-hidden=true href=#structured-streaming-ui>#</a></h2><ul><li><a href=https://issues.apache.org/jira/browse/SPARK-29543>SPARK-29543</a></li></ul><p>&ldquo;Structured Streaming&rdquo; というタブが UI に追加された件。<br>Spark のドキュメントに例があります。</p><figure><img loading=lazy src=https://spark.apache.org/docs/3.0.0/img/webui-structured-streaming-detail.png alt="Structured Streaming Tab"><figcaption><p><a href=https://spark.apache.org/docs/3.0.0/web-ui.html#structured-streaming-tab>Structured Streaming Tab</a></p></figcaption></figure><p>Spark 2.4 系では Structured Streaming を動かしていてもせいぜい job や stage が増えていくという味気ないものしか見えませんでした。<br>Spark 3.0.0 で実際に動かしてみたけど欲しかったやつ！という感じ。<br>ストリーム処理では入力データ量の変化の可視化がマストだと思ってます。</p><h2 id=catalog-plugin-api>Catalog plugin API<a hidden class=anchor aria-hidden=true href=#catalog-plugin-api>#</a></h2><ul><li><a href=https://issues.apache.org/jira/browse/SPARK-31121>SPARK-31121</a></li><li><a href=https://docs.google.com/document/d/1zLFiA1VuaWeVxeTDXNg8bL6GP3BVoOZBkewFtEnjEoo/edit>SPIP: Spark API for Table Metadata</a></li></ul><p>これまでは CTAS (Create Table As Select) の操作はあったが、外部のデータソースに対して DDL 的な操作をする API が足りていませんでした。<br>CTAS も挙動に実装依存の曖昧さがありました。<br>そこで <code>create</code>, <code>alter</code>, <code>load</code>, <code>drop</code> 等のテーブル操作をできるようにしたという話。</p><p>ドキュメントの <a href=https://spark.apache.org/docs/3.0.0/sql-ref-syntax.html#ddl-statements>DDL Statements</a> のあたりを読め何ができるかわかります。<br>以前のバージョンでも一部のデータソースについてはできた模様 (ex. <a href=https://spark.apache.org/docs/2.4.6/sql-migration-guide-hive-compatibility.html#supported-hive-features>Hive</a>)。</p><p>今の自分の業務では Spark から DDL を扱うようなことはしないのでそれほど恩恵は感じられません。<br>notebook からアドホックな Spark のバッチを動かすというような使い方をしていればうれしいかもしれません。</p><h2 id=add-an-api-that-allows-a-user-to-define-and-observe-arbitrary-metrics-on-batch-and-streaming-queries>Add an API that allows a user to define and observe arbitrary metrics on batch and streaming queries<a hidden class=anchor aria-hidden=true href=#add-an-api-that-allows-a-user-to-define-and-observe-arbitrary-metrics-on-batch-and-streaming-queries>#</a></h2><ul><li><a href=https://issues.apache.org/jira/browse/SPARK-29345>SPARK-29345</a></li></ul><p>クエリの途中の段階で何らかの metrics を仕込んでおいて callback 的にその metrics にアクセスできる仕組み。<br><a href=https://spark.apache.org/docs/3.0.0/api/scala/org/apache/spark/sql/Dataset.html#observe%28name:String,expr:org.apache.spark.sql.Column,exprs:org.apache.spark.sql.Column*%29:org.apache.spark.sql.Dataset[T]>Dataset#observe() の API ドキュメント</a> を読むのが一番早いです。<br>この例ではストリーム処理を扱っているが、バッチ処理の例を自分で書いて試してみました。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#75715e>// Register listener
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>spark
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>listenerManager
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>register<span style=color:#f92672>(</span><span style=color:#66d9ef>new</span> <span style=color:#a6e22e>QueryExecutionListener</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>override</span> <span style=color:#66d9ef>def</span> onSuccess<span style=color:#f92672>(</span>funcName<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>String</span><span style=color:#f92672>,</span> qe<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>QueryExecution</span><span style=color:#f92672>,</span> durationNs<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>)</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Unit</span> <span style=color:#f92672>=</span> <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>      <span style=color:#66d9ef>val</span> num <span style=color:#66d9ef>=</span> qe<span style=color:#f92672>.</span>observedMetrics
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>get<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;my_metrics&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>map<span style=color:#f92672>(</span><span style=color:#66d9ef>_</span><span style=color:#f92672>.</span>getAs<span style=color:#f92672>[</span><span style=color:#66d9ef>Long</span><span style=color:#f92672>](</span><span style=color:#e6db74>&#34;num&#34;</span><span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>getOrElse<span style=color:#f92672>(-</span><span style=color:#ae81ff>100.0</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      println<span style=color:#f92672>(</span><span style=color:#e6db74>s&#34;num of data: </span><span style=color:#e6db74>$num</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>override</span> <span style=color:#66d9ef>def</span> onFailure<span style=color:#f92672>(</span>funcName<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>String</span><span style=color:#f92672>,</span> qe<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>QueryExecution</span><span style=color:#f92672>,</span> exception<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Exception</span><span style=color:#f92672>)</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Unit</span> <span style=color:#f92672>=</span> <span style=color:#f92672>{}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>})</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Make DataFrame
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>val</span> df <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>Seq</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>range<span style=color:#f92672>(</span><span style=color:#ae81ff>0</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>1000</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>map<span style=color:#f92672>((</span><span style=color:#66d9ef>_</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>Seq</span><span style=color:#f92672>(</span><span style=color:#e6db74>&#34;a&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;b&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;c&#34;</span><span style=color:#f92672>)(</span><span style=color:#a6e22e>Random</span><span style=color:#f92672>.</span>nextInt<span style=color:#f92672>(</span><span style=color:#ae81ff>3</span><span style=color:#f92672>)),</span> math<span style=color:#f92672>.</span>random<span style=color:#f92672>()))</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>toDF<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;id&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;type&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;value&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Observe and process
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>val</span> dfResult <span style=color:#66d9ef>=</span> df
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>observe<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;my_metrics&#34;</span><span style=color:#f92672>,</span> count<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;*&#34;</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;num&#34;</span><span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>groupBy<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;type&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>agg<span style=color:#f92672>(</span>avg<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;value&#34;</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;avg_value&#34;</span><span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Run
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>dfResult<span style=color:#f92672>.</span>show
</span></span></code></pre></div><p>これを動かしたときの出力は次のようになりました。</p><pre tabindex=0><code>+----+------------------+
|type|         avg_value|
+----+------------------+
|   c|0.5129435063033314|
|   b|0.4693004460694317|
|   a|0.4912087482418599|
+----+------------------+

num of data: 1000
</code></pre><p><code>observe()</code> はその出力の DataFrame に対して schema やデータの中身を変更することはありません。<br>metrics を仕込むのみ。<br>logical plan を出力してみると <code>observe()</code> を入れることにより途中に <code>CollectMetrics</code> という plan が挿入されていました。<br>ソースを見ると accumulator を使っている模様。<br>なので <code>observe()</code> の集計のみで一度 job が動くわけではなく、クエリが2回走るという感じではありません。<br>全体の処理の中でひっそりと accumulator で脇で集計しておくといった趣でしょうか。</p><p>これは結構有用だと思います。<br>例えば何らかの集計をやるにしてもその最初や途中で、例えば入力データは何件あったか？みたいなことをログに出しておきたいことがあります。<br>というか accumulator で頑張ってそういうものを作ったことがある…<br>これがフレームワーク側でサポートされるのはうれしいです。</p><h2 id=まとめ>まとめ<a hidden class=anchor aria-hidden=true href=#まとめ>#</a></h2><p>2つのダイナミックな最適化に期待大。<br>気が向いたら追加でまた調べるかもしれません。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://soonraah.github.io/tags/apache-spark/>Apache Spark</a></li></ul><nav class=paginav><a class=prev href=https://soonraah.github.io/posts/weak_isolation_level_of_dataframe/><span class=title>« 前へ</span><br><span>Spark DataFrame クエリの弱い分離レベル</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Spark 3.0.0 について調べた on x" href="https://x.com/intent/tweet/?text=Apache%20Spark%203.0.0%20%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-spark-3-0-0%2f&amp;hashtags=ApacheSpark"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Spark 3.0.0 について調べた on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-spark-3-0-0%2f&amp;title=Apache%20Spark%203.0.0%20%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f&amp;summary=Apache%20Spark%203.0.0%20%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f&amp;source=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-spark-3-0-0%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Spark 3.0.0 について調べた on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-spark-3-0-0%2f&title=Apache%20Spark%203.0.0%20%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Spark 3.0.0 について調べた on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-spark-3-0-0%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Spark 3.0.0 について調べた on whatsapp" href="https://api.whatsapp.com/send?text=Apache%20Spark%203.0.0%20%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%20-%20https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-spark-3-0-0%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Spark 3.0.0 について調べた on telegram" href="https://telegram.me/share/url?text=Apache%20Spark%203.0.0%20%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-spark-3-0-0%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Apache Spark 3.0.0 について調べた on ycombinator" href="https://news.ycombinator.com/submitlink?t=Apache%20Spark%203.0.0%20%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f&u=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-spark-3-0-0%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://soonraah.github.io/>Froglog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="コピー";function s(){t.innerHTML="コピーされました!",setTimeout(()=>{t.innerHTML="コピー"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>