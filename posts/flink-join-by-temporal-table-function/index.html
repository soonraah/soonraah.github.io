<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Apache Flink の Temporary Table Function を用いた stream data と static data の join - Froglog</title><meta name=keywords content="Apache Flink,stream processing"><meta name=description content="前回の記事 では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。 今回の記事では Table API の temporal table function を用いた実験を行う。
Table API Table API は名前のとおりで class Table を中心として SQL-like な DSL により処理を記述するという、DataStream API より high-level な API となっている。 これらの関係は Apaceh Spark の RDD と DataFrame (DataSet) の関係に似ている。 SQL-like な API で記述された処理が実行時に最適化されて low-level API の処理に翻訳されるところも同じだ。
RDB の table の概念を元にしているものと考えられるが、本質的に table の概念とストリーム処理はあまりマッチしないと思う。 table はある時点のデータセット全体を表すのに対し、ストリーム処理ではやってくるレコードを逐次的に処理したい。 ここを合わせているため、ストリーム処理における Table API による処理の挙動の理解には注意が必要だ。 Streaming Concepts 以下のドキュメントを確認しておきたい。"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/flink-join-by-temporal-table-function/><meta name=google-site-verification content="XYZabc"><link href=https://soonraah.github.io/assets/css/stylesheet.min.595f5ecef354f9eb94e43d831cd360dcf8b7727542e731c55a7875c9e94a9577.css integrity="sha256-WV9ezvNU+euU5D2DHNNg3Pi3cnVC5zHFWnh1yelKlXc=" rel="preload stylesheet" as=style><link rel=manifest href=https://soonraah.github.io/site.webmanifest><link rel=icon href=https://soonraah.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.78.1"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-73329599-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="Apache Flink の Temporary Table Function を用いた stream data と static data の join"><meta property="og:description" content="前回の記事 では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。 今回の記事では Table API の temporal table function を用いた実験を行う。
Table API Table API は名前のとおりで class Table を中心として SQL-like な DSL により処理を記述するという、DataStream API より high-level な API となっている。 これらの関係は Apaceh Spark の RDD と DataFrame (DataSet) の関係に似ている。 SQL-like な API で記述された処理が実行時に最適化されて low-level API の処理に翻訳されるところも同じだ。
RDB の table の概念を元にしているものと考えられるが、本質的に table の概念とストリーム処理はあまりマッチしないと思う。 table はある時点のデータセット全体を表すのに対し、ストリーム処理ではやってくるレコードを逐次的に処理したい。 ここを合わせているため、ストリーム処理における Table API による処理の挙動の理解には注意が必要だ。 Streaming Concepts 以下のドキュメントを確認しておきたい。"><meta property="og:type" content="article"><meta property="og:url" content="https://soonraah.github.io/posts/flink-join-by-temporal-table-function/"><meta property="og:image" content="https://soonraah.github.io/image/logo/flink_squirrel_color_logo.png"><meta property="article:published_time" content="2020-08-16T00:30:00+09:00"><meta property="article:modified_time" content="2020-08-16T00:30:00+09:00"><meta property="og:site_name" content="Froglog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/logo/flink_squirrel_color_logo.png"><meta name=twitter:title content="Apache Flink の Temporary Table Function を用いた stream data と static data の join"><meta name=twitter:description content="前回の記事 では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。 今回の記事では Table API の temporal table function を用いた実験を行う。
Table API Table API は名前のとおりで class Table を中心として SQL-like な DSL により処理を記述するという、DataStream API より high-level な API となっている。 これらの関係は Apaceh Spark の RDD と DataFrame (DataSet) の関係に似ている。 SQL-like な API で記述された処理が実行時に最適化されて low-level API の処理に翻訳されるところも同じだ。
RDB の table の概念を元にしているものと考えられるが、本質的に table の概念とストリーム処理はあまりマッチしないと思う。 table はある時点のデータセット全体を表すのに対し、ストリーム処理ではやってくるレコードを逐次的に処理したい。 ここを合わせているため、ストリーム処理における Table API による処理の挙動の理解には注意が必要だ。 Streaming Concepts 以下のドキュメントを確認しておきたい。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Flink の Temporary Table Function を用いた stream data と static data の join","name":"Apache Flink の Temporary Table Function を用いた stream data と static data の join","description":"前回の記事 では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。 今回の記事では Table API の temporal table function を用いた実験を行う。\nTable …","keywords":["Apache Flink","stream processing"],"articleBody":"前回の記事 では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。 今回の記事では Table API の temporal table function を用いた実験を行う。\nTable API Table API は名前のとおりで class Table を中心として SQL-like な DSL により処理を記述するという、DataStream API より high-level な API となっている。 これらの関係は Apaceh Spark の RDD と DataFrame (DataSet) の関係に似ている。 SQL-like な API で記述された処理が実行時に最適化されて low-level API の処理に翻訳されるところも同じだ。\nRDB の table の概念を元にしているものと考えられるが、本質的に table の概念とストリーム処理はあまりマッチしないと思う。 table はある時点のデータセット全体を表すのに対し、ストリーム処理ではやってくるレコードを逐次的に処理したい。 ここを合わせているため、ストリーム処理における Table API による処理の挙動の理解には注意が必要だ。 Streaming Concepts 以下のドキュメントを確認しておきたい。\nTemporal Table Function star schema における、変更されうる dimension table を stream data と結合する方法として、temporal table という仕組みが提供されている。 ドキュメントでは為替レートの例が示されている。 stream でやってくる fact table 的なレコードに対して、為替のように時々刻々と変化する dimension table をそのレコードの時刻における snap shot としてぶつけるような形となる。\nレコードの時刻としては processing time または event time を扱うことができる。 event time の場合であっても watermark で遅延の許容を定義できるため dimension table のすべての履歴を状態として保持する必要はなく、processing time または event time の watermark に応じて過去の履歴は捨てることが可能となっている。\nTable API において temporal table を使うには temporal table function という形を取ることになる。\n実験 実験概要 やることは 前回の記事 とまったく同じで乱数で作った株価のデータを扱う。 前回と違うのは DataStream API ではなく Table API で処理を記述したところである。\nコード 上記を実行するためのコードを以下に示す。 実行可能なプロジェクトは GitHub に置いておいた。\nEntry Point toTable() により入力データの DataStream を Table に変換した後、処理を記述した。 func が temporal table function に当たる。 今回は processing time を基準として join しているが、実際のシステムでは event time を基準としたいことが多いのではないだろうか。\npackage example import org.apache.flink.api.java.io.TextInputFormat import org.apache.flink.api.scala._ import org.apache.flink.core.fs.Path import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration import org.apache.flink.streaming.api.TimeCharacteristic import org.apache.flink.streaming.api.functions.source.FileProcessingMode import org.apache.flink.streaming.api.scala.{DataStream, StreamExecutionEnvironment} import org.apache.flink.table.api.bridge.scala.{StreamTableEnvironment, _} import org.apache.flink.table.api.{AnyWithOperations, EnvironmentSettings, FieldExpression, call} import org.apache.flink.test.util.MiniClusterWithClientResource object FlinkTableJoinTest { // See https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/testing.html#testing-flink-jobs  private val FlinkCluster = new MiniClusterWithClientResource( new MiniClusterResourceConfiguration .Builder() .setNumberSlotsPerTaskManager(2) .setNumberTaskManagers(1) .build ) def main(args: Array[String]): Unit = { FlinkCluster.before() // for batch programs use ExecutionEnvironment instead of StreamExecutionEnvironment  val env = StreamExecutionEnvironment.getExecutionEnvironment env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime) env.setParallelism(2) // create settings  val setting = EnvironmentSettings .newInstance() .useBlinkPlanner() .inStreamingMode() .build() // create a TableEnvironment  val tableEnv = StreamTableEnvironment.create(env, setting) // create a Table instance for Company  val companiesMasterFilePath = \"data/companies.csv\" val companies = readCompaniesMaster(companiesMasterFilePath, env) .toTable(tableEnv, $\"ticker\".as(\"c_ticker\"), $\"name\", $\"c_proc_time\".proctime) // temporal table function  val func = companies.createTemporalTableFunction($\"c_proc_time\", $\"c_ticker\") // create a Table instance for Stock  val stocks = env .fromCollection(new UnboundedStocks) .toTable(tableEnv, $\"ticker\".as(\"s_ticker\"), $\"price\", $\"s_proc_time\".proctime) // join with a temporal table function  val results = stocks .joinLateral(call(func, $\"s_proc_time\"), $\"s_ticker\" === $\"c_ticker\") .select($\"s_ticker\", $\"name\", $\"price\") .toAppendStream[(String, String, Double)] .print env.execute() FlinkCluster.after() } private def readCompaniesMaster(companiesMasterFilePath: String, env: StreamExecutionEnvironment): DataStream[Company] = { env .readFile( new TextInputFormat(new Path(companiesMasterFilePath)), companiesMasterFilePath, FileProcessingMode.PROCESS_CONTINUOUSLY, 10 * 1000 ) .map { line = val items = line.split(\",\") Company(items(0), items(1)) } } } 実行結果 上記を実行すると以下のような stream と static が結合された結果レコードが流れ続ける。\n2 (AMZN,Amazon,110.05826176785374) 2 (AMZN,Amazon,237.82717323588966) 1 (FB,Facebook,147.96046700184428) 1 (GOOGL,Google,393.58555322242086) 2 (AMZN,Amazon,104.18843434881401) 前回と同様に data/companies.csv の中身を更新するとその結果が反映される。 削除が反映されないのも同じだった。 おそらく physical な処理としてはほぼ同じようになっていると思われる。\nまとめ 前回と同様の stream data と static data の join を、Table API + temporal table function で行えることを確認した。 temporal table function の概念さえ把握できれば Straem API のときに比べて簡潔に処理を記述できた。\n","wordCount":"413","inLanguage":"ja","image":"https://soonraah.github.io/image/logo/flink_squirrel_color_logo.png","datePublished":"2020-08-16T00:30:00+09:00","dateModified":"2020-08-16T00:30:00+09:00","author":{"@type":"Person","name":"soonraah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soonraah.github.io/posts/flink-join-by-temporal-table-function/"},"publisher":{"@type":"Organization","name":"Froglog","logo":{"@type":"ImageObject","url":"https://soonraah.github.io/favicon.ico"}}}</script></head><body class="single dark" id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else{document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io accesskey=h><img src=/image/brand/favicon.png alt=logo aria-label=logo height=35>Home</a>
<span class=logo-switches><span class=theme-toggle><a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span></span></div><ul class=menu id=menu onscroll=menu_on_scroll()><li><a href=https://soonraah.github.io/about/><span>About</span></a></li><li><a href=https://soonraah.github.io/archives/><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Apache Flink の Temporary Table Function を用いた stream data と static data の join</h1><div class=post-meta>August 16, 2020&nbsp;·&nbsp;soonraah</div></header><figure class=entry-cover><img src=https://soonraah.github.io/image/logo/flink_squirrel_color_logo.png alt="Apache Flink"><p><a href=https://flink.apache.org/>Apache Flink</a></p></figure><div class=toc><details><summary><div class=details accesskey=c>Table of Contents</div></summary><blockquote><ul><li><a href=#table-api aria-label="Table API">Table API</a></li><li><a href=#temporal-table-function aria-label="Temporal Table Function">Temporal Table Function</a></li><li><a href=#%e5%ae%9f%e9%a8%93 aria-label=実験>実験</a><ul><li><a href=#%e5%ae%9f%e9%a8%93%e6%a6%82%e8%a6%81 aria-label=実験概要>実験概要</a></li><li><a href=#%e3%82%b3%e3%83%bc%e3%83%89 aria-label=コード>コード</a><ul><li><a href=#entry-point aria-label="Entry Point">Entry Point</a></li></ul></li><li><a href=#%e5%ae%9f%e8%a1%8c%e7%b5%90%e6%9e%9c aria-label=実行結果>実行結果</a></li></ul></li><li><a href=#%e3%81%be%e3%81%a8%e3%82%81 aria-label=まとめ>まとめ</a></li></ul></blockquote></details></div><div class=post-content><p><a href=https://soonraah.github.io/posts/flink-join-by-broadcast-state-pattern/>前回の記事</a> では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。
今回の記事では Table API の temporal table function を用いた実験を行う。</p><h2 id=table-api>Table API</h2><p><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/>Table API</a> は名前のとおりで class <code>Table</code> を中心として SQL-like な DSL により処理を記述するという、DataStream API より high-level な API となっている。
これらの関係は Apaceh Spark の <code>RDD</code> と <code>DataFrame</code> (<code>DataSet</code>) の関係に似ている。
SQL-like な API で記述された処理が実行時に最適化されて low-level API の処理に翻訳されるところも同じだ。</p><p>RDB の table の概念を元にしているものと考えられるが、本質的に table の概念とストリーム処理はあまりマッチしないと思う。
table はある時点のデータセット全体を表すのに対し、ストリーム処理ではやってくるレコードを逐次的に処理したい。
ここを合わせているため、ストリーム処理における Table API による処理の挙動の理解には注意が必要だ。
<a href=https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/>Streaming Concepts</a> 以下のドキュメントを確認しておきたい。</p><h2 id=temporal-table-function>Temporal Table Function</h2><p>star schema における、変更されうる dimension table を stream data と結合する方法として、<a href=https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/table/streaming/temporal_tables.html>temporal table</a> という仕組みが提供されている。
ドキュメントでは為替レートの例が示されている。
stream でやってくる fact table 的なレコードに対して、為替のように時々刻々と変化する dimension table をそのレコードの時刻における snap shot としてぶつけるような形となる。</p><p>レコードの時刻としては processing time または event time を扱うことができる。
event time の場合であっても watermark で遅延の許容を定義できるため dimension table のすべての履歴を状態として保持する必要はなく、processing time または event time の watermark に応じて過去の履歴は捨てることが可能となっている。</p><p>Table API において temporal table を使うには temporal table function という形を取ることになる。</p><h2 id=実験>実験</h2><h3 id=実験概要>実験概要</h3><p>やることは <a href=https://soonraah.github.io/posts/flink-join-by-broadcast-state-pattern/>前回の記事</a> とまったく同じで乱数で作った株価のデータを扱う。
前回と違うのは DataStream API ではなく Table API で処理を記述したところである。</p><h3 id=コード>コード</h3><p>上記を実行するためのコードを以下に示す。
実行可能なプロジェクトは <a href=https://github.com/soonraah/flink_join_test>GitHub</a> に置いておいた。</p><h4 id=entry-point>Entry Point</h4><p><code>toTable()</code> により入力データの <code>DataStream</code> を <code>Table</code> に変換した後、処理を記述した。
<code>func</code> が temporal table function に当たる。
今回は processing time を基準として join しているが、実際のシステムでは event time を基準としたいことが多いのではないだろうか。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=color:#66d9ef>package</span> example

<span style=color:#66d9ef>import</span> org.apache.flink.api.java.io.TextInputFormat
<span style=color:#66d9ef>import</span> org.apache.flink.api.scala._
<span style=color:#66d9ef>import</span> org.apache.flink.core.fs.Path
<span style=color:#66d9ef>import</span> org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration
<span style=color:#66d9ef>import</span> org.apache.flink.streaming.api.TimeCharacteristic
<span style=color:#66d9ef>import</span> org.apache.flink.streaming.api.functions.source.FileProcessingMode
<span style=color:#66d9ef>import</span> org.apache.flink.streaming.api.scala.<span style=color:#f92672>{</span><span style=color:#a6e22e>DataStream</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>StreamExecutionEnvironment</span><span style=color:#f92672>}</span>
<span style=color:#66d9ef>import</span> org.apache.flink.table.api.bridge.scala.<span style=color:#f92672>{</span><span style=color:#a6e22e>StreamTableEnvironment</span><span style=color:#f92672>,</span> <span style=color:#66d9ef>_</span><span style=color:#f92672>}</span>
<span style=color:#66d9ef>import</span> org.apache.flink.table.api.<span style=color:#f92672>{</span><span style=color:#a6e22e>AnyWithOperations</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>EnvironmentSettings</span><span style=color:#f92672>,</span> <span style=color:#a6e22e>FieldExpression</span><span style=color:#f92672>,</span> call<span style=color:#f92672>}</span>
<span style=color:#66d9ef>import</span> org.apache.flink.test.util.MiniClusterWithClientResource

<span style=color:#66d9ef>object</span> <span style=color:#a6e22e>FlinkTableJoinTest</span> <span style=color:#f92672>{</span>
  <span style=color:#75715e>// See https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/testing.html#testing-flink-jobs
</span><span style=color:#75715e></span>  <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>val</span> <span style=color:#a6e22e>FlinkCluster</span> <span style=color:#66d9ef>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>MiniClusterWithClientResource</span><span style=color:#f92672>(</span>
    <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>MiniClusterResourceConfiguration</span>
    <span style=color:#f92672>.</span><span style=color:#a6e22e>Builder</span><span style=color:#f92672>()</span>
      <span style=color:#f92672>.</span>setNumberSlotsPerTaskManager<span style=color:#f92672>(</span><span style=color:#ae81ff>2</span><span style=color:#f92672>)</span>
      <span style=color:#f92672>.</span>setNumberTaskManagers<span style=color:#f92672>(</span><span style=color:#ae81ff>1</span><span style=color:#f92672>)</span>
      <span style=color:#f92672>.</span>build
  <span style=color:#f92672>)</span>

  <span style=color:#66d9ef>def</span> main<span style=color:#f92672>(</span>args<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Array</span><span style=color:#f92672>[</span><span style=color:#66d9ef>String</span><span style=color:#f92672>])</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Unit</span> <span style=color:#f92672>=</span> <span style=color:#f92672>{</span>
    <span style=color:#a6e22e>FlinkCluster</span><span style=color:#f92672>.</span>before<span style=color:#f92672>()</span>

    <span style=color:#75715e>// for batch programs use ExecutionEnvironment instead of StreamExecutionEnvironment
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>val</span> env <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>StreamExecutionEnvironment</span><span style=color:#f92672>.</span>getExecutionEnvironment
    env<span style=color:#f92672>.</span>setStreamTimeCharacteristic<span style=color:#f92672>(</span><span style=color:#a6e22e>TimeCharacteristic</span><span style=color:#f92672>.</span><span style=color:#a6e22e>ProcessingTime</span><span style=color:#f92672>)</span>
    env<span style=color:#f92672>.</span>setParallelism<span style=color:#f92672>(</span><span style=color:#ae81ff>2</span><span style=color:#f92672>)</span>

    <span style=color:#75715e>// create settings
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>val</span> setting <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>EnvironmentSettings</span>
      <span style=color:#f92672>.</span>newInstance<span style=color:#f92672>()</span>
      <span style=color:#f92672>.</span>useBlinkPlanner<span style=color:#f92672>()</span>
      <span style=color:#f92672>.</span>inStreamingMode<span style=color:#f92672>()</span>
      <span style=color:#f92672>.</span>build<span style=color:#f92672>()</span>

    <span style=color:#75715e>// create a TableEnvironment
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>val</span> tableEnv <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>StreamTableEnvironment</span><span style=color:#f92672>.</span>create<span style=color:#f92672>(</span>env<span style=color:#f92672>,</span> setting<span style=color:#f92672>)</span>

    <span style=color:#75715e>// create a Table instance for Company
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>val</span> companiesMasterFilePath <span style=color:#66d9ef>=</span> <span style=color:#e6db74>&#34;data/companies.csv&#34;</span>
    <span style=color:#66d9ef>val</span> companies <span style=color:#66d9ef>=</span> readCompaniesMaster<span style=color:#f92672>(</span>companiesMasterFilePath<span style=color:#f92672>,</span> env<span style=color:#f92672>)</span>
      <span style=color:#f92672>.</span>toTable<span style=color:#f92672>(</span>tableEnv<span style=color:#f92672>,</span> $<span style=color:#e6db74>&#34;ticker&#34;</span><span style=color:#f92672>.</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;c_ticker&#34;</span><span style=color:#f92672>),</span> $<span style=color:#e6db74>&#34;name&#34;</span><span style=color:#f92672>,</span> $<span style=color:#e6db74>&#34;c_proc_time&#34;</span><span style=color:#f92672>.</span>proctime<span style=color:#f92672>)</span>

    <span style=color:#75715e>// temporal table function
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>val</span> func <span style=color:#66d9ef>=</span> companies<span style=color:#f92672>.</span>createTemporalTableFunction<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;c_proc_time&#34;</span><span style=color:#f92672>,</span> $<span style=color:#e6db74>&#34;c_ticker&#34;</span><span style=color:#f92672>)</span>

    <span style=color:#75715e>// create a Table instance for Stock
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>val</span> stocks <span style=color:#66d9ef>=</span> env
      <span style=color:#f92672>.</span>fromCollection<span style=color:#f92672>(</span><span style=color:#66d9ef>new</span> <span style=color:#a6e22e>UnboundedStocks</span><span style=color:#f92672>)</span>
      <span style=color:#f92672>.</span>toTable<span style=color:#f92672>(</span>tableEnv<span style=color:#f92672>,</span> $<span style=color:#e6db74>&#34;ticker&#34;</span><span style=color:#f92672>.</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;s_ticker&#34;</span><span style=color:#f92672>),</span> $<span style=color:#e6db74>&#34;price&#34;</span><span style=color:#f92672>,</span> $<span style=color:#e6db74>&#34;s_proc_time&#34;</span><span style=color:#f92672>.</span>proctime<span style=color:#f92672>)</span>

    <span style=color:#75715e>// join with a temporal table function
</span><span style=color:#75715e></span>    <span style=color:#66d9ef>val</span> results <span style=color:#66d9ef>=</span> stocks
      <span style=color:#f92672>.</span>joinLateral<span style=color:#f92672>(</span>call<span style=color:#f92672>(</span>func<span style=color:#f92672>,</span> $<span style=color:#e6db74>&#34;s_proc_time&#34;</span><span style=color:#f92672>),</span> $<span style=color:#e6db74>&#34;s_ticker&#34;</span> <span style=color:#f92672>===</span> $<span style=color:#e6db74>&#34;c_ticker&#34;</span><span style=color:#f92672>)</span>
      <span style=color:#f92672>.</span>select<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;s_ticker&#34;</span><span style=color:#f92672>,</span> $<span style=color:#e6db74>&#34;name&#34;</span><span style=color:#f92672>,</span> $<span style=color:#e6db74>&#34;price&#34;</span><span style=color:#f92672>)</span>
      <span style=color:#f92672>.</span>toAppendStream<span style=color:#f92672>[(</span><span style=color:#66d9ef>String</span>, <span style=color:#66d9ef>String</span>, <span style=color:#66d9ef>Double</span><span style=color:#f92672>)]</span>
      <span style=color:#f92672>.</span>print

    env<span style=color:#f92672>.</span>execute<span style=color:#f92672>()</span>

    <span style=color:#a6e22e>FlinkCluster</span><span style=color:#f92672>.</span>after<span style=color:#f92672>()</span>
  <span style=color:#f92672>}</span>

  <span style=color:#66d9ef>private</span> <span style=color:#66d9ef>def</span> readCompaniesMaster<span style=color:#f92672>(</span>companiesMasterFilePath<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>String</span><span style=color:#f92672>,</span>
                                  env<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>StreamExecutionEnvironment</span><span style=color:#f92672>)</span><span style=color:#66d9ef>:</span> <span style=color:#66d9ef>DataStream</span><span style=color:#f92672>[</span><span style=color:#66d9ef>Company</span><span style=color:#f92672>]</span> <span style=color:#66d9ef>=</span> <span style=color:#f92672>{</span>
    env
      <span style=color:#f92672>.</span>readFile<span style=color:#f92672>(</span>
        <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>TextInputFormat</span><span style=color:#f92672>(</span><span style=color:#66d9ef>new</span> <span style=color:#a6e22e>Path</span><span style=color:#f92672>(</span>companiesMasterFilePath<span style=color:#f92672>)),</span>
        companiesMasterFilePath<span style=color:#f92672>,</span>
        <span style=color:#a6e22e>FileProcessingMode</span><span style=color:#f92672>.</span><span style=color:#a6e22e>PROCESS_CONTINUOUSLY</span><span style=color:#f92672>,</span>
        <span style=color:#ae81ff>10</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>1000</span>
      <span style=color:#f92672>)</span>
      <span style=color:#f92672>.</span>map <span style=color:#f92672>{</span> line <span style=color:#66d9ef>=&gt;</span>
        <span style=color:#66d9ef>val</span> items <span style=color:#66d9ef>=</span> line<span style=color:#f92672>.</span>split<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;,&#34;</span><span style=color:#f92672>)</span>
        <span style=color:#a6e22e>Company</span><span style=color:#f92672>(</span>items<span style=color:#f92672>(</span><span style=color:#ae81ff>0</span><span style=color:#f92672>),</span> items<span style=color:#f92672>(</span><span style=color:#ae81ff>1</span><span style=color:#f92672>))</span>
      <span style=color:#f92672>}</span>
  <span style=color:#f92672>}</span>
<span style=color:#f92672>}</span>
</code></pre></div><h3 id=実行結果>実行結果</h3><p>上記を実行すると以下のような stream と static が結合された結果レコードが流れ続ける。</p><pre><code>2&gt; (AMZN,Amazon,110.05826176785374)
2&gt; (AMZN,Amazon,237.82717323588966)
1&gt; (FB,Facebook,147.96046700184428)
1&gt; (GOOGL,Google,393.58555322242086)
2&gt; (AMZN,Amazon,104.18843434881401)
</code></pre><p>前回と同様に <code>data/companies.csv</code> の中身を更新するとその結果が反映される。
削除が反映されないのも同じだった。
おそらく physical な処理としてはほぼ同じようになっていると思われる。</p><h2 id=まとめ>まとめ</h2><p>前回と同様の stream data と static data の join を、Table API + temporal table function で行えることを確認した。
temporal table function の概念さえ把握できれば Straem API のときに比べて簡潔に処理を記述できた。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://soonraah.github.io/tags/apache-flink>Apache Flink</a></li><li><a href=https://soonraah.github.io/tags/stream-processing>stream processing</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Apache Flink の Temporary Table Function を用いた stream data と static data の join on twitter" href="https://twitter.com/intent/tweet/?text=Apache%20Flink%20%e3%81%ae%20Temporary%20Table%20Function%20%e3%82%92%e7%94%a8%e3%81%84%e3%81%9f%20stream%20data%20%e3%81%a8%20static%20data%20%e3%81%ae%20join&url=https%3a%2f%2fsoonraah.github.io%2fposts%2fflink-join-by-temporal-table-function%2f&hashtags=ApacheFlink%2cstreamprocessing"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Flink の Temporary Table Function を用いた stream data と static data の join on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fsoonraah.github.io%2fposts%2fflink-join-by-temporal-table-function%2f&title=Apache%20Flink%20%e3%81%ae%20Temporary%20Table%20Function%20%e3%82%92%e7%94%a8%e3%81%84%e3%81%9f%20stream%20data%20%e3%81%a8%20static%20data%20%e3%81%ae%20join&summary=Apache%20Flink%20%e3%81%ae%20Temporary%20Table%20Function%20%e3%82%92%e7%94%a8%e3%81%84%e3%81%9f%20stream%20data%20%e3%81%a8%20static%20data%20%e3%81%ae%20join&source=https%3a%2f%2fsoonraah.github.io%2fposts%2fflink-join-by-temporal-table-function%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Flink の Temporary Table Function を用いた stream data と static data の join on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoonraah.github.io%2fposts%2fflink-join-by-temporal-table-function%2f&title=Apache%20Flink%20%e3%81%ae%20Temporary%20Table%20Function%20%e3%82%92%e7%94%a8%e3%81%84%e3%81%9f%20stream%20data%20%e3%81%a8%20static%20data%20%e3%81%ae%20join"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zm-119.474 108.193c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zm-160.386-29.702c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Flink の Temporary Table Function を用いた stream data と static data の join on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoonraah.github.io%2fposts%2fflink-join-by-temporal-table-function%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978v-192.915h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Flink の Temporary Table Function を用いた stream data と static data の join on whatsapp" href="https://api.whatsapp.com/send?text=Apache%20Flink%20%e3%81%ae%20Temporary%20Table%20Function%20%e3%82%92%e7%94%a8%e3%81%84%e3%81%9f%20stream%20data%20%e3%81%a8%20static%20data%20%e3%81%ae%20join%20-%20https%3a%2f%2fsoonraah.github.io%2fposts%2fflink-join-by-temporal-table-function%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23-13.314-11.876-22.304-26.542-24.916-31.026s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Flink の Temporary Table Function を用いた stream data と static data の join on telegram" href="https://telegram.me/share/url?text=Apache%20Flink%20%e3%81%ae%20Temporary%20Table%20Function%20%e3%82%92%e7%94%a8%e3%81%84%e3%81%9f%20stream%20data%20%e3%81%a8%20static%20data%20%e3%81%ae%20join&url=https%3a%2f%2fsoonraah.github.io%2fposts%2fflink-join-by-temporal-table-function%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47A3.38 3.38.0 0126.49 29.86zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2020 <a href=https://soonraah.github.io>Froglog</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top" accesskey=g><button class=top-link id=top-link type=button><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg></button></a>
<script src=https://soonraah.github.io/assets/js/highlight.min.e7afc2928c0925d65c4732dfebe147014d91299a98e819e4b42f25c4fa68e91c.js integrity="sha256-56/CkowJJdZcRzLf6+FHAU2RKZqY6BnktC8lxPpo6Rw="></script><script>hljs.initHighlightingOnLoad();</script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);document.querySelector(`[id='${id}']`).scrollIntoView({behavior:"smooth"});});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>