<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Apache Iceberg の table を near real time で更新する | Froglog</title><meta name=keywords content="Data Lake,Lakehouse,Apache Iceberg"><meta name=description content="Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。
Apache Iceberg とは Apache Iceberg (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。
特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。
これにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。
Apache Iceberg Iceberg Table Spec
詳しくは公式ドキュメントを参照のこと。
最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。
Flink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/update-iceberg-table-in-near-real-time/><link crossorigin=anonymous href=/assets/css/stylesheet.min.ec8da366ca2fb647537ccb7a8f6fa5b4e9cd3c7a0d3171dd2d3baad1e49c8bfc.css integrity="sha256-7I2jZsovtkdTfMt6j2+ltOnNPHoNMXHdLTuq0eSci/w=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.b95bacdc39e37a332a9f883b1e78be4abc1fdca2bc1f2641f55e3cd3dabd4d61.js integrity="sha256-uVus3DnjejMqn4g7Hni+Srwf3KK8HyZB9V4809q9TWE=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://soonraah.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-73329599-2","auto"),ga("send","pageview"))</script><meta property="og:title" content="Apache Iceberg の table を near real time で更新する"><meta property="og:description" content="Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。
Apache Iceberg とは Apache Iceberg (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。
特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。
これにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。
Apache Iceberg Iceberg Table Spec
詳しくは公式ドキュメントを参照のこと。
最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。
Flink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。"><meta property="og:type" content="article"><meta property="og:url" content="https://soonraah.github.io/posts/update-iceberg-table-in-near-real-time/"><meta property="og:image" content="https://soonraah.github.io/image/photo/danting-zhu-kWsT6p_S3cY-unsplash.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-05-11T01:30:00+09:00"><meta property="article:modified_time" content="2023-05-11T01:30:00+09:00"><meta property="og:site_name" content="Froglog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/photo/danting-zhu-kWsT6p_S3cY-unsplash.jpg"><meta name=twitter:title content="Apache Iceberg の table を near real time で更新する"><meta name=twitter:description content="Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。
Apache Iceberg とは Apache Iceberg (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。
特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。
これにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。
Apache Iceberg Iceberg Table Spec
詳しくは公式ドキュメントを参照のこと。
最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。
Flink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://soonraah.github.io/posts/"},{"@type":"ListItem","position":3,"name":"Apache Iceberg の table を near real time で更新する","item":"https://soonraah.github.io/posts/update-iceberg-table-in-near-real-time/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Apache Iceberg の table を near real time で更新する","name":"Apache Iceberg の table を near real time で更新する","description":"Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。\nApache Iceberg とは Apache Iceberg (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。\n特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。\nこれにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。\nApache Iceberg Iceberg Table Spec\n詳しくは公式ドキュメントを参照のこと。\n最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。\nFlink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。","keywords":["Data Lake","Lakehouse","Apache Iceberg"],"articleBody":"Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。\nApache Iceberg とは Apache Iceberg (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。\n特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。\nこれにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。\nApache Iceberg Iceberg Table Spec\n詳しくは公式ドキュメントを参照のこと。\n最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。\nFlink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。\nこのポストでやりたいこと このポストでは Iceberg の table を near real time 更新することを想定して実験を行う。\n多数の IoT デバイスで測定された温度情報が逐次的に送られていることを想定し、定期的にそれをデバイス ID ごとの最新の温度情報を持つ table へと書き出すものとする。\n次のような要件を仮定する。\n低レイテンシが要求されており、near real time での table 更新を行う 次のような schema のレコードが IoT デバイスから送信され得られる状態になっているものとする device_id: デバイスに対して一意に振られている ID operation: upsert or delete (後述) temperature: 測定された温度の値 ts: 測定時の timestamp IoT デバイスは登録削除されることがあり、その場合は table 上の当該デバイス ID のレコードを削除する 削除の場合は operation = 'delete' となっている。それ以外は 'upsert' 送られてくるレコードは timestamp (ts) の順になっているとは限らない (out of order) リアルタイム処理のフレームワークとしては Spark Structured Streaming を使用するものとする。\ntable 更新の実装 上記実験のための実装を行った。\n各言語・フレームワーク等は以下のバージョンを使っている。\nScala 2.13.10 Java 11 Spark 3.3.2 Iceberg 1.2.1 実行可能な sbt project の全体を GitHub repository soonraah/streaming_iceberg に置いているのでご参考まで。\n実装の主要な部分を次に示す。\n// Create SparkSession instance val spark = SparkSession .builder() .appName(\"StreamingIcebergExperiment\") .master(\"local[2]\") .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") .config(\"spark.sql.catalog.my_catalog\", \"org.apache.iceberg.spark.SparkCatalog\") .config(\"spark.sql.catalog.my_catalog.type\", \"hadoop\") .config(\"spark.sql.catalog.my_catalog.warehouse\", \"data/warehouse\") .getOrCreate() spark.sparkContext.setLogLevel(\"WARN\") import spark.implicits._ // Drop table spark .sql( \"\"\"drop table if exists | my_catalog.my_db.device_temperature |\"\"\".stripMargin ) // Create table spark .sql( \"\"\"create table | my_catalog.my_db.device_temperature |( | device_id int, | operation string, | temperature double, | ts timestamp |) |using iceberg |tblproperties ( | 'format-version' = '2', | 'write.delete.mode' = 'merge-on-read', | 'write.update.mode' = 'merge-on-read', | 'write.merge.mode' = 'merge-on-read' |) |\"\"\".stripMargin ) val random = new Random() val addOutOfOrderness = udf { (timestamp: Timestamp) =\u003e // add time randomly in [-5, +5) sec val ms = timestamp.getTime + random.nextInt(10000) - 5000 new Timestamp(ms) } // Prepare input data val dfInput = spark .readStream .format(\"rate\") .option(\"rowsPerSecond\", 1) .load() .select( // Generate device_id in 0~127 randomly (rand() * 128).cast(IntegerType).as(\"device_id\"), // 90% of operation is upsert and 10% is delete when(rand() \u003e 0.1, \"upsert\").otherwise(\"delete\").as(\"operation\"), // Generate temperature randomly based on standard normal distribution (randn() * 5.0 + 20.0).as(\"temperature\"), // timestamp is out of order addOutOfOrderness($\"timestamp\").as(\"ts\") ) // Update table for each mini batch dfInput .writeStream .trigger(Trigger.ProcessingTime(30.seconds)) .foreachBatch { (dfBatch: DataFrame, batchId: Long) =\u003e println(s\"Processing batchId=$batchId\") // Eliminate duplicated device_id val dfDedup = dfBatch .withColumn( \"row_num\", row_number() .over(Window.partitionBy($\"device_id\").orderBy($\"ts\".desc)) ) .where($\"row_num\" === 1) .drop($\"row_num\") // createOrReplaceTempView() doesn't work dfDedup.createOrReplaceGlobalTempView(\"input\") // Insert, update and delete records by 'merge into' spark .sql( \"\"\"merge into | my_catalog.my_db.device_temperature |using( | select | * | from | global_temp.input |) as input |on | device_temperature.device_id = input.device_id | and device_temperature.ts \u003c input.ts |when matched and input.operation = 'upsert' then update set * |when matched and input.operation = 'delete' then delete |when not matched then insert * |\"\"\".stripMargin ) () } .start .awaitTermination() spark.stop() この中の各処理を以下で説明していく。\n// Create SparkSession instance val spark = SparkSession .builder() .appName(\"StreamingIcebergExperiment\") .master(\"local[2]\") .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") .config(\"spark.sql.catalog.my_catalog\", \"org.apache.iceberg.spark.SparkCatalog\") .config(\"spark.sql.catalog.my_catalog.type\", \"hadoop\") .config(\"spark.sql.catalog.my_catalog.warehouse\", \"data/warehouse\") .getOrCreate() Spark から Iceberg を使うためには extensions の設定、および catalog の設定が必要となる。\nこれらは設定ファイルやコマンドラインからも指定できるが、今回は実験のためソースコード上で簡易に設定した。\n// Create table spark .sql( \"\"\"create table | my_catalog.my_db.device_temperature |( | device_id int, | operation string, | temperature double, | ts timestamp |) |using iceberg |tblproperties ( | 'format-version' = '2', | 'write.delete.mode' = 'merge-on-read', | 'write.update.mode' = 'merge-on-read', | 'write.merge.mode' = 'merge-on-read' |) |\"\"\".stripMargin ) table 作成のクエリを実行している。\n頻度の高い更新・削除を想定しているため、ここでは各操作に対して copy-on-write ではなく merge-on-read を指定している。\nこれにより書き込み時にデータファイル全体をコピーするのではなく、差分のみ追加するという形となり書き込みのコストが小さくなる。\nmerge-on-read は format version 2 でしか指定できないため、その設定もしている。\n// Prepare input data val dfInput = spark .readStream .format(\"rate\") .option(\"rowsPerSecond\", 1) .load() .select( // Generate device_id in 0~127 randomly (rand() * 128).cast(IntegerType).as(\"device_id\"), // 90% of operation is upsert and 10% is delete when(rand() \u003e 0.1, \"upsert\").otherwise(\"delete\").as(\"operation\"), // Generate temperature randomly based on standard normal distribution (randn() * 5.0 + 20.0).as(\"temperature\"), // timestamp is out of order addOutOfOrderness($\"timestamp\").as(\"ts\") ) ここでは IoT デバイスから送信されたとするストリームデータを作成している。\nまずは .readStream.foramt(\"rate\") によりストリームを発生させ、select() の部分で想定する schema にして値を入れている。\n詳細はコメントを参照。\n1点だけ補足すると、addOutOfOrderness() の部分では timestamp に対してわざと±5秒以内のランダムなゆらぎを与えおり、レコードが timestamp どおりに流れてこない状況を作っている。\ndfInput .writeStream .trigger(Trigger.ProcessingTime(30.seconds)) .foreachBatch { ... } .start .awaitTermination() ストリームデータは foreachBatch により、30秒ごとの mini batch の単位で処理される。\nこの mini batch の中で table 更新を行う。\n// Eliminate duplicated device_id val dfDedup = dfBatch .withColumn( \"row_num\", row_number() .over(Window.partitionBy($\"device_id\").orderBy($\"ts\".desc)) ) .where($\"row_num\" === 1) .drop($\"row_num\") Iceberg の merge into (後述) では更新をかける側の table において結合のキーとなる column の重複は許されず、重複があった場合は次のようなエラーになってしまう。\norg.apache.spark.SparkException: The ON search condition of the MERGE statement matched a single row from the target table with multiple rows of the source table. This could result in the target row being operated on more than once with an update or delete operation and is not allowed. これを避けるため結合のキーとなる device_id ごとに一意となるよう、最新の行だけ残して重複を排除している。\n// Insert, update and delete records by 'merge into' spark .sql( \"\"\"merge into | my_catalog.my_db.device_temperature |using( | select | * | from | global_temp.input |) as input |on | device_temperature.device_id = input.device_id | and device_temperature.ts \u003c input.ts |when matched and input.operation = 'upsert' then update set * |when matched and input.operation = 'delete' then delete |when not matched then insert * |\"\"\".stripMargin ) はい、ここが update, insert, delete の最もキモとなるところ。\n個人的には merge into という SQL 構文は知らなかったのだが、どうやら Iceberg 特有のものでもないらしい。\ntable device_temperature に対して update, delete, insert を行う SQL となっている。\nこのクエリが実行されると Iceberg の table が更新され、snapshot が1つ前に進むことになる。\nDDL のところで merge-on-read を指定したため、差分のみのファイルが作成される。\ntable 更新の確認 上記のコードを実行すると、table の更新処理が始まる。\nしばらく流した後、SparkSQL で\nspark .sql( \"\"\"select | * |from | my_catalog.my_db.device_temperature |order by | device_id |\"\"\".stripMargin ) .show(128, truncate = false) のようなクエリを実行すると、\n+---------+---------+------------------+-----------------------+ |device_id|operation|temperature |ts | +---------+---------+------------------+-----------------------+ |0 |upsert |15.879340359832794|2023-05-08 07:39:56.637| |1 |upsert |20.303530210621492|2023-05-08 07:40:26.157| |2 |upsert |21.07822922592327 |2023-05-08 07:41:10.937| |3 |upsert |20.81228214216027 |2023-05-08 07:37:09.756| |6 |upsert |20.571664434275807|2023-05-08 07:38:43.124| |7 |upsert |19.44731196983606 |2023-05-08 07:39:56.1 | |8 |upsert |27.964942467735458|2023-05-08 07:39:39.623| |9 |upsert |23.319385015293673|2023-05-08 07:40:59.377| |10 |upsert |22.392313247902365|2023-05-08 07:40:40.946| ... のような結果が得られる。\n少し間をおいて実行すると中身が変わっており、更新されていることがわかる。\nまた、ある程度時間を経た後においても欠番があり (ex. 上記の device_id = 4, 5)、削除も行われていることが確認できる。\n雑感 Apache Hudi に比べて動作が素直でわかりやすいように感じた。\n一方で Hudi で言うところの PRECOMBINE_FIELD のようなものがなく、自分で重複排除する必要がありちょっと面倒。\n必然的にタイムトラベルできる粒度は mini batch の粒度となる。\nmerge-on-read の table では差分ファイルが大きくなるにつれ、読み取りのコストも大きくなっていく。\n上記の更新コードを一晩実行した後だと、単純な select に6分程度かかってしまった。\n最新 snapshot としてはレコード数はたかだか128程度なのでこれはかなり遅い。\nというところで compaction などの table のメンテナンス操作が必要となってくる。\nこれについては次のポストで扱いたい。\n","wordCount":"933","inLanguage":"ja","image":"https://soonraah.github.io/image/photo/danting-zhu-kWsT6p_S3cY-unsplash.jpg","datePublished":"2023-05-11T01:30:00+09:00","dateModified":"2023-05-11T01:30:00+09:00","author":{"@type":"Person","name":"soonraah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soonraah.github.io/posts/update-iceberg-table-in-near-real-time/"},"publisher":{"@type":"Organization","name":"Froglog","logo":{"@type":"ImageObject","url":"https://soonraah.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt=logo aria-label=logo height=35>Home</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soonraah.github.io>Home</a>&nbsp;»&nbsp;<a href=https://soonraah.github.io/posts/>Posts</a></div><h1 class=post-title>Apache Iceberg の table を near real time で更新する</h1><div class=post-meta><span title='2023-05-11 01:30:00 +0900 JST'>5月 11, 2023</span>&nbsp;·&nbsp;soonraah</div></header><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/danting-zhu-kWsT6p_S3cY-unsplash.jpg alt=iceberg><p><a href=https://unsplash.com/photos/kWsT6p_S3cY>Photo by Danting Zhu on Unsplash</a></p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目次</span></summary><div class=inner><ul><li><a href=#apache-iceberg-%e3%81%a8%e3%81%af aria-label="Apache Iceberg とは">Apache Iceberg とは</a></li><li><a href=#%e3%81%93%e3%81%ae%e3%83%9d%e3%82%b9%e3%83%88%e3%81%a7%e3%82%84%e3%82%8a%e3%81%9f%e3%81%84%e3%81%93%e3%81%a8 aria-label=このポストでやりたいこと>このポストでやりたいこと</a></li><li><a href=#table-%e6%9b%b4%e6%96%b0%e3%81%ae%e5%ae%9f%e8%a3%85 aria-label="table 更新の実装">table 更新の実装</a></li><li><a href=#table-%e6%9b%b4%e6%96%b0%e3%81%ae%e7%a2%ba%e8%aa%8d aria-label="table 更新の確認">table 更新の確認</a></li><li><a href=#%e9%9b%91%e6%84%9f aria-label=雑感>雑感</a></li></ul></div></details></div><div class=post-content><p>Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。</p><h2 id=apache-iceberg-とは>Apache Iceberg とは<a hidden class=anchor aria-hidden=true href=#apache-iceberg-とは>#</a></h2><p><a href=https://iceberg.apache.org/>Apache Iceberg</a> (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。<br>特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。<br>これにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。</p><figure class=center><img loading=lazy src=/image/iceberg/iceberg_metadata.png alt="Apache Iceberg"><figcaption><p>Apache Iceberg
<a href=https://iceberg.apache.org/spec/>Iceberg Table Spec</a></p></figcaption></figure><p>詳しくは公式ドキュメントを参照のこと。<br>最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。</p><ul><li><a href=https://medium.com/smartnews-inc/flink-based-iceberg-real-time-data-lake-in-smartnews-part-i-19a7628ce110>Flink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium</a></li></ul><p>ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。</p><h2 id=このポストでやりたいこと>このポストでやりたいこと<a hidden class=anchor aria-hidden=true href=#このポストでやりたいこと>#</a></h2><p>このポストでは Iceberg の table を near real time 更新することを想定して実験を行う。<br>多数の IoT デバイスで測定された温度情報が逐次的に送られていることを想定し、定期的にそれをデバイス ID ごとの最新の温度情報を持つ table へと書き出すものとする。<br>次のような要件を仮定する。</p><ul><li>低レイテンシが要求されており、near real time での table 更新を行う</li><li>次のような schema のレコードが IoT デバイスから送信され得られる状態になっているものとする<ul><li><code>device_id</code>: デバイスに対して一意に振られている ID</li><li><code>operation</code>: upsert or delete (後述)</li><li><code>temperature</code>: 測定された温度の値</li><li><code>ts</code>: 測定時の timestamp</li></ul></li><li>IoT デバイスは登録削除されることがあり、その場合は table 上の当該デバイス ID のレコードを削除する<ul><li>削除の場合は <code>operation = 'delete'</code> となっている。それ以外は <code>'upsert'</code></li></ul></li><li>送られてくるレコードは timestamp (<code>ts</code>) の順になっているとは限らない (<a href=../functionality-of-streaming-system/#out-of-order-data-management>out of order</a>)</li></ul><p>リアルタイム処理のフレームワークとしては <a href=https://spark.apache.org/docs/3.3.2/structured-streaming-programming-guide.html>Spark Structured Streaming</a> を使用するものとする。</p><h2 id=table-更新の実装>table 更新の実装<a hidden class=anchor aria-hidden=true href=#table-更新の実装>#</a></h2><p>上記実験のための実装を行った。<br>各言語・フレームワーク等は以下のバージョンを使っている。</p><ul><li>Scala 2.13.10</li><li>Java 11</li><li>Spark 3.3.2</li><li>Iceberg 1.2.1</li></ul><p>実行可能な sbt project の全体を GitHub repository <a href=https://github.com/soonraah/streaming_iceberg>soonraah/streaming_iceberg</a> に置いているのでご参考まで。<br>実装の主要な部分を次に示す。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#75715e>// Create SparkSession instance
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>val</span> spark <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>SparkSession</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>builder<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>appName<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;StreamingIcebergExperiment&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>master<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;local[2]&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>config<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;spark.sql.extensions&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>config<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;spark.sql.catalog.my_catalog&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;org.apache.iceberg.spark.SparkCatalog&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>config<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;spark.sql.catalog.my_catalog.type&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;hadoop&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>config<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;spark.sql.catalog.my_catalog.warehouse&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;data/warehouse&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>getOrCreate<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spark<span style=color:#f92672>.</span>sparkContext<span style=color:#f92672>.</span>setLogLevel<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;WARN&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>import</span> spark.implicits._
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Drop table
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>spark
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>sql<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;drop table if exists
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    my_catalog.my_db.device_temperature
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |&#34;&#34;&#34;</span><span style=color:#f92672>.</span>stripMargin
</span></span><span style=display:flex><span>  <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Create table
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>spark
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>sql<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;create table
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    my_catalog.my_db.device_temperature
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |(
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    device_id int,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    operation string,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    temperature double,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    ts timestamp
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |using iceberg
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |tblproperties (
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    &#39;format-version&#39; = &#39;2&#39;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    &#39;write.delete.mode&#39; = &#39;merge-on-read&#39;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    &#39;write.update.mode&#39; = &#39;merge-on-read&#39;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    &#39;write.merge.mode&#39; = &#39;merge-on-read&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |&#34;&#34;&#34;</span><span style=color:#f92672>.</span>stripMargin
</span></span><span style=display:flex><span>  <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>val</span> random <span style=color:#66d9ef>=</span> <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>Random</span><span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>val</span> addOutOfOrderness <span style=color:#66d9ef>=</span> udf <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>(</span>timestamp<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Timestamp</span><span style=color:#f92672>)</span> <span style=color:#66d9ef>=&gt;</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// add time randomly in [-5, +5) sec
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#66d9ef>val</span> ms <span style=color:#66d9ef>=</span> timestamp<span style=color:#f92672>.</span>getTime <span style=color:#f92672>+</span> random<span style=color:#f92672>.</span>nextInt<span style=color:#f92672>(</span><span style=color:#ae81ff>10000</span><span style=color:#f92672>)</span> <span style=color:#f92672>-</span> <span style=color:#ae81ff>5000</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>new</span> <span style=color:#a6e22e>Timestamp</span><span style=color:#f92672>(</span>ms<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Prepare input data
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>val</span> dfInput <span style=color:#66d9ef>=</span> spark
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>readStream
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>format<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;rate&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>option<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;rowsPerSecond&#34;</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>load<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>select<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Generate device_id in 0~127 randomly
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>(</span>rand<span style=color:#f92672>()</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>128</span><span style=color:#f92672>).</span>cast<span style=color:#f92672>(</span><span style=color:#a6e22e>IntegerType</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;device_id&#34;</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// 90% of operation is upsert and 10% is delete
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    when<span style=color:#f92672>(</span>rand<span style=color:#f92672>()</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.1</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;upsert&#34;</span><span style=color:#f92672>).</span>otherwise<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;delete&#34;</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;operation&#34;</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Generate temperature randomly based on standard normal distribution
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>(</span>randn<span style=color:#f92672>()</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>5.0</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>20.0</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;temperature&#34;</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// timestamp is out of order
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    addOutOfOrderness<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;timestamp&#34;</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;ts&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Update table for each mini batch
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>dfInput
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>writeStream
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>trigger<span style=color:#f92672>(</span><span style=color:#a6e22e>Trigger</span><span style=color:#f92672>.</span><span style=color:#a6e22e>ProcessingTime</span><span style=color:#f92672>(</span><span style=color:#ae81ff>30.</span>seconds<span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>foreachBatch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>(</span>dfBatch<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>DataFrame</span><span style=color:#f92672>,</span> batchId<span style=color:#66d9ef>:</span> <span style=color:#66d9ef>Long</span><span style=color:#f92672>)</span> <span style=color:#66d9ef>=&gt;</span>
</span></span><span style=display:flex><span>      println<span style=color:#f92672>(</span><span style=color:#e6db74>s&#34;Processing batchId=</span><span style=color:#e6db74>$batchId</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#75715e>// Eliminate duplicated device_id
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>      <span style=color:#66d9ef>val</span> dfDedup <span style=color:#66d9ef>=</span> dfBatch
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>withColumn<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>          <span style=color:#e6db74>&#34;row_num&#34;</span><span style=color:#f92672>,</span>
</span></span><span style=display:flex><span>          row_number<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>.</span>over<span style=color:#f92672>(</span><span style=color:#a6e22e>Window</span><span style=color:#f92672>.</span>partitionBy<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;device_id&#34;</span><span style=color:#f92672>).</span>orderBy<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;ts&#34;</span><span style=color:#f92672>.</span>desc<span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>where<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;row_num&#34;</span> <span style=color:#f92672>===</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>drop<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;row_num&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>      <span style=color:#75715e>// createOrReplaceTempView() doesn&#39;t work
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>      dfDedup<span style=color:#f92672>.</span>createOrReplaceGlobalTempView<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;input&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#75715e>// Insert, update and delete records by &#39;merge into&#39;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>      spark
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>sql<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>          <span style=color:#e6db74>&#34;&#34;&#34;merge into
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    my_catalog.my_db.device_temperature
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |using(
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    select
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |        *
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    from
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |        global_temp.input
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |) as input
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |on
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    device_temperature.device_id = input.device_id
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    and device_temperature.ts &lt; input.ts
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |when matched and input.operation = &#39;upsert&#39; then update set *
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |when matched and input.operation = &#39;delete&#39; then delete
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |when not matched then insert *
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |&#34;&#34;&#34;</span><span style=color:#f92672>.</span>stripMargin
</span></span><span style=display:flex><span>        <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>start
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>awaitTermination<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>spark<span style=color:#f92672>.</span>stop<span style=color:#f92672>()</span>
</span></span></code></pre></div><p>この中の各処理を以下で説明していく。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#75715e>// Create SparkSession instance
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>val</span> spark <span style=color:#66d9ef>=</span> <span style=color:#a6e22e>SparkSession</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>builder<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>appName<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;StreamingIcebergExperiment&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>master<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;local[2]&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>config<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;spark.sql.extensions&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>config<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;spark.sql.catalog.my_catalog&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;org.apache.iceberg.spark.SparkCatalog&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>config<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;spark.sql.catalog.my_catalog.type&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;hadoop&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>config<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;spark.sql.catalog.my_catalog.warehouse&#34;</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;data/warehouse&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>getOrCreate<span style=color:#f92672>()</span>
</span></span></code></pre></div><p>Spark から Iceberg を使うためには extensions の設定、および catalog の設定が必要となる。<br>これらは設定ファイルやコマンドラインからも指定できるが、今回は実験のためソースコード上で簡易に設定した。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#75715e>// Create table
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>spark
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>sql<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;create table
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    my_catalog.my_db.device_temperature
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |(
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    device_id int,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    operation string,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    temperature double,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    ts timestamp
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |using iceberg
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |tblproperties (
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    &#39;format-version&#39; = &#39;2&#39;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    &#39;write.delete.mode&#39; = &#39;merge-on-read&#39;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    &#39;write.update.mode&#39; = &#39;merge-on-read&#39;,
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    &#39;write.merge.mode&#39; = &#39;merge-on-read&#39;
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |)
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |&#34;&#34;&#34;</span><span style=color:#f92672>.</span>stripMargin
</span></span><span style=display:flex><span>  <span style=color:#f92672>)</span>
</span></span></code></pre></div><p>table 作成のクエリを実行している。<br>頻度の高い更新・削除を想定しているため、ここでは各操作に対して <code>copy-on-write</code> ではなく <code>merge-on-read</code> を指定している。<br>これにより書き込み時にデータファイル全体をコピーするのではなく、差分のみ追加するという形となり書き込みのコストが小さくなる。<br><code>merge-on-read</code> は format version 2 でしか指定できないため、その設定もしている。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span><span style=color:#75715e>// Prepare input data
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>val</span> dfInput <span style=color:#66d9ef>=</span> spark
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>readStream
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>format<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;rate&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>option<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;rowsPerSecond&#34;</span><span style=color:#f92672>,</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>load<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>select<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Generate device_id in 0~127 randomly
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>(</span>rand<span style=color:#f92672>()</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>128</span><span style=color:#f92672>).</span>cast<span style=color:#f92672>(</span><span style=color:#a6e22e>IntegerType</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;device_id&#34;</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// 90% of operation is upsert and 10% is delete
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    when<span style=color:#f92672>(</span>rand<span style=color:#f92672>()</span> <span style=color:#f92672>&gt;</span> <span style=color:#ae81ff>0.1</span><span style=color:#f92672>,</span> <span style=color:#e6db74>&#34;upsert&#34;</span><span style=color:#f92672>).</span>otherwise<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;delete&#34;</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;operation&#34;</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// Generate temperature randomly based on standard normal distribution
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    <span style=color:#f92672>(</span>randn<span style=color:#f92672>()</span> <span style=color:#f92672>*</span> <span style=color:#ae81ff>5.0</span> <span style=color:#f92672>+</span> <span style=color:#ae81ff>20.0</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;temperature&#34;</span><span style=color:#f92672>),</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// timestamp is out of order
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    addOutOfOrderness<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;timestamp&#34;</span><span style=color:#f92672>).</span>as<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;ts&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>)</span>
</span></span></code></pre></div><p>ここでは IoT デバイスから送信されたとするストリームデータを作成している。<br>まずは <code>.readStream.foramt("rate")</code> によりストリームを発生させ、<code>select()</code> の部分で想定する schema にして値を入れている。<br>詳細はコメントを参照。<br>1点だけ補足すると、<code>addOutOfOrderness()</code> の部分では timestamp に対してわざと±5秒以内のランダムなゆらぎを与えおり、レコードが timestamp どおりに流れてこない状況を作っている。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span>dfInput
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>writeStream
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>trigger<span style=color:#f92672>(</span><span style=color:#a6e22e>Trigger</span><span style=color:#f92672>.</span><span style=color:#a6e22e>ProcessingTime</span><span style=color:#f92672>(</span><span style=color:#ae81ff>30.</span>seconds<span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>foreachBatch <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>start
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>awaitTermination<span style=color:#f92672>()</span>
</span></span></code></pre></div><p>ストリームデータは <code>foreachBatch</code> により、30秒ごとの mini batch の単位で処理される。<br>この mini batch の中で table 更新を行う。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span>      <span style=color:#75715e>// Eliminate duplicated device_id
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>      <span style=color:#66d9ef>val</span> dfDedup <span style=color:#66d9ef>=</span> dfBatch
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>withColumn<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>          <span style=color:#e6db74>&#34;row_num&#34;</span><span style=color:#f92672>,</span>
</span></span><span style=display:flex><span>          row_number<span style=color:#f92672>()</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>.</span>over<span style=color:#f92672>(</span><span style=color:#a6e22e>Window</span><span style=color:#f92672>.</span>partitionBy<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;device_id&#34;</span><span style=color:#f92672>).</span>orderBy<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;ts&#34;</span><span style=color:#f92672>.</span>desc<span style=color:#f92672>))</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>where<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;row_num&#34;</span> <span style=color:#f92672>===</span> <span style=color:#ae81ff>1</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>drop<span style=color:#f92672>(</span>$<span style=color:#e6db74>&#34;row_num&#34;</span><span style=color:#f92672>)</span>
</span></span></code></pre></div><p>Iceberg の <code>merge into</code> (後述) では更新をかける側の table において結合のキーとなる column の重複は許されず、重複があった場合は次のようなエラーになってしまう。</p><pre tabindex=0><code>org.apache.spark.SparkException: The ON search condition of the MERGE statement matched a single row from the target table with multiple rows of the source table. This could result in the target row being operated on more than once with an update or delete operation and is not allowed.
</code></pre><p>これを避けるため結合のキーとなる <code>device_id</code> ごとに一意となるよう、最新の行だけ残して重複を排除している。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span>      <span style=color:#75715e>// Insert, update and delete records by &#39;merge into&#39;
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>      spark
</span></span><span style=display:flex><span>        <span style=color:#f92672>.</span>sql<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>          <span style=color:#e6db74>&#34;&#34;&#34;merge into
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    my_catalog.my_db.device_temperature
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |using(
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    select
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |        *
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    from
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |        global_temp.input
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |) as input
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |on
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    device_temperature.device_id = input.device_id
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |    and device_temperature.ts &lt; input.ts
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |when matched and input.operation = &#39;upsert&#39; then update set *
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |when matched and input.operation = &#39;delete&#39; then delete
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |when not matched then insert *
</span></span></span><span style=display:flex><span><span style=color:#e6db74>            |&#34;&#34;&#34;</span><span style=color:#f92672>.</span>stripMargin
</span></span><span style=display:flex><span>        <span style=color:#f92672>)</span>
</span></span></code></pre></div><p>はい、ここが update, insert, delete の最もキモとなるところ。<br>個人的には <code>merge into</code> という SQL 構文は知らなかったのだが、どうやら Iceberg 特有のものでもないらしい。<br>table <code>device_temperature</code> に対して update, delete, insert を行う SQL となっている。<br>このクエリが実行されると Iceberg の table が更新され、snapshot が1つ前に進むことになる。<br>DDL のところで <code>merge-on-read</code> を指定したため、差分のみのファイルが作成される。</p><h2 id=table-更新の確認>table 更新の確認<a hidden class=anchor aria-hidden=true href=#table-更新の確認>#</a></h2><p>上記のコードを実行すると、table の更新処理が始まる。<br>しばらく流した後、SparkSQL で</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span>spark
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>sql<span style=color:#f92672>(</span>
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;&#34;&#34;select
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    *
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |from
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    my_catalog.my_db.device_temperature
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |order by
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |    device_id
</span></span></span><span style=display:flex><span><span style=color:#e6db74>      |&#34;&#34;&#34;</span><span style=color:#f92672>.</span>stripMargin
</span></span><span style=display:flex><span>  <span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>.</span>show<span style=color:#f92672>(</span><span style=color:#ae81ff>128</span><span style=color:#f92672>,</span> truncate <span style=color:#66d9ef>=</span> <span style=color:#66d9ef>false</span><span style=color:#f92672>)</span>
</span></span></code></pre></div><p>のようなクエリを実行すると、</p><pre tabindex=0><code>+---------+---------+------------------+-----------------------+
|device_id|operation|temperature       |ts                     |
+---------+---------+------------------+-----------------------+
|0        |upsert   |15.879340359832794|2023-05-08 07:39:56.637|
|1        |upsert   |20.303530210621492|2023-05-08 07:40:26.157|
|2        |upsert   |21.07822922592327 |2023-05-08 07:41:10.937|
|3        |upsert   |20.81228214216027 |2023-05-08 07:37:09.756|
|6        |upsert   |20.571664434275807|2023-05-08 07:38:43.124|
|7        |upsert   |19.44731196983606 |2023-05-08 07:39:56.1  |
|8        |upsert   |27.964942467735458|2023-05-08 07:39:39.623|
|9        |upsert   |23.319385015293673|2023-05-08 07:40:59.377|
|10       |upsert   |22.392313247902365|2023-05-08 07:40:40.946|
...
</code></pre><p>のような結果が得られる。<br>少し間をおいて実行すると中身が変わっており、更新されていることがわかる。<br>また、ある程度時間を経た後においても欠番があり (ex. 上記の <code>device_id = 4, 5</code>)、削除も行われていることが確認できる。</p><h2 id=雑感>雑感<a hidden class=anchor aria-hidden=true href=#雑感>#</a></h2><p>Apache Hudi に比べて動作が素直でわかりやすいように感じた。<br>一方で Hudi で言うところの <a href=https://hudi.apache.org/docs/0.12.3/basic_configurations#hoodiedatasourcewriteprecombinefield><code>PRECOMBINE_FIELD</code></a> のようなものがなく、自分で重複排除する必要がありちょっと面倒。<br>必然的にタイムトラベルできる粒度は mini batch の粒度となる。</p><p><code>merge-on-read</code> の table では差分ファイルが大きくなるにつれ、読み取りのコストも大きくなっていく。<br>上記の更新コードを一晩実行した後だと、単純な <code>select</code> に6分程度かかってしまった。<br>最新 snapshot としてはレコード数はたかだか128程度なのでこれはかなり遅い。</p><p>というところで compaction などの table のメンテナンス操作が必要となってくる。<br>これについては次のポストで扱いたい。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://soonraah.github.io/tags/data-lake/>Data Lake</a></li><li><a href=https://soonraah.github.io/tags/lakehouse/>Lakehouse</a></li><li><a href=https://soonraah.github.io/tags/apache-iceberg/>Apache Iceberg</a></li></ul><nav class=paginav><a class=prev href=https://soonraah.github.io/posts/maintain-iceberg-table-updated-in-near-real-time/><span class=title>« 前のページ</span><br><span>near real time で更新される Apache Iceberg の table のメンテナンス</span></a>
<a class=next href=https://soonraah.github.io/posts/looked-into-data-contracts/><span class=title>次のページ »</span><br><span>Data Contract について調べた</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Apache Iceberg の table を near real time で更新する on twitter" href="https://twitter.com/intent/tweet/?text=Apache%20Iceberg%20%e3%81%ae%20table%20%e3%82%92%20near%20real%20time%20%e3%81%a7%e6%9b%b4%e6%96%b0%e3%81%99%e3%82%8b&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fupdate-iceberg-table-in-near-real-time%2f&amp;hashtags=DataLake%2cLakehouse%2cApacheIceberg"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Iceberg の table を near real time で更新する on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fupdate-iceberg-table-in-near-real-time%2f&amp;title=Apache%20Iceberg%20%e3%81%ae%20table%20%e3%82%92%20near%20real%20time%20%e3%81%a7%e6%9b%b4%e6%96%b0%e3%81%99%e3%82%8b&amp;summary=Apache%20Iceberg%20%e3%81%ae%20table%20%e3%82%92%20near%20real%20time%20%e3%81%a7%e6%9b%b4%e6%96%b0%e3%81%99%e3%82%8b&amp;source=https%3a%2f%2fsoonraah.github.io%2fposts%2fupdate-iceberg-table-in-near-real-time%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Iceberg の table を near real time で更新する on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoonraah.github.io%2fposts%2fupdate-iceberg-table-in-near-real-time%2f&title=Apache%20Iceberg%20%e3%81%ae%20table%20%e3%82%92%20near%20real%20time%20%e3%81%a7%e6%9b%b4%e6%96%b0%e3%81%99%e3%82%8b"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Iceberg の table を near real time で更新する on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoonraah.github.io%2fposts%2fupdate-iceberg-table-in-near-real-time%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Iceberg の table を near real time で更新する on whatsapp" href="https://api.whatsapp.com/send?text=Apache%20Iceberg%20%e3%81%ae%20table%20%e3%82%92%20near%20real%20time%20%e3%81%a7%e6%9b%b4%e6%96%b0%e3%81%99%e3%82%8b%20-%20https%3a%2f%2fsoonraah.github.io%2fposts%2fupdate-iceberg-table-in-near-real-time%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Apache Iceberg の table を near real time で更新する on telegram" href="https://telegram.me/share/url?text=Apache%20Iceberg%20%e3%81%ae%20table%20%e3%82%92%20near%20real%20time%20%e3%81%a7%e6%9b%b4%e6%96%b0%e3%81%99%e3%82%8b&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fupdate-iceberg-table-in-near-real-time%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://soonraah.github.io>Froglog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>