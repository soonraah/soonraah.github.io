<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門 | Froglog</title>
<meta name=keywords content="AI agent,LLM,RAG,LangChain,LangGraph"><meta name=description content="書籍について

西見 公宏; 吉田 真吾; 大嶋 勇樹. LangChainとLangGraphによるRAG・AIエージェント［実践］入門 エンジニア選書. 株式会社技術評論社.

タイトルのとおりで RAG や AI エージェントについて書かれた本。
出版は2024年11月。
LangChain や LangGraph を使ったサンプルコードが豊富に載っている。
著者の方は3名ともジェネラティブエージェンツ社の方で、AI エージェントを扱う会社らしい。
前作として『ChatGPT/LangChainによるチャットシステム構築［実践］入門』という本もあり、本書の何章かは前作の内容を引き継いでアップデートしているとのこと。
個人的にはこれまで LLM や LangChain など追えていなかったので勉強になったし、自分でコードを写経して動かしてみるのがとても面白かった。
AI エージェントまわりの技術を実感したい人におすすめ。
ちなみにサンプルコードを動かすためには OpenAI をはじめとする様々なサービスに登録する必要があり、料金が発生するものも含まれている。
このポストについて
書籍「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」を読んで、面白かったので内容をまとめる。
各章ごとに内容を挙げていってもいいのだが、ここではそうはせず、本書に登場する言葉や概念をまとめていくことにする。
ちなみにこの記事で紹介するプロンプト等は書籍そのままではなく、少し変更している。
実際のプロンプトを知りたい場合は書籍を読んでください。
プロンプトエンジニアリング
これは知っている人も多いだろう。
プロンプトとは主に自然言語で記述される、LLM に与える命令のこと。
LLM をアプリケーションに組み込む場合はプロンプトはテンプレート化し、入力データをそれに差し込む形となる。
LLM は必ずしも人間の出す命令に対して望ましい回答を出力してくれるわけではない。
望ましい回答を出力してもらえるよう、プロンプトを工夫するテクニックがプロンプトエンジニアリングである。
本書ではプロンプトエンジニアリングの具体的な手法として次の3つが紹介されていた。
ちなみにここで例として示している出力は実際に OpenAI の LLM gpt-4o-mini で出力したものである。
Zero-shot プロンプティング
簡単なタスクであれば、特に追加の情報がなくとも (=Zero-shot) 望ましい回答を得ることができる。
system: 次の日本酒のレビューをポジティブ・ネガティブ・中立のどれかに分類してください。
user: ふくよかで芳醇な香り
出力
ポジティブ
Few-shot プロンプティング
より複雑なタスクになった場合、デモンストレーションを与えることで回答の精度を高めることができる。
いくつかのデモンストレーションを示すため、Zero-shot ではなく Few-shot である。"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/reading-note-agent-book/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ja href=https://soonraah.github.io/posts/reading-note-agent-book/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://soonraah.github.io/posts/reading-note-agent-book/"><meta property="og:site_name" content="Froglog"><meta property="og:title" content="読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門"><meta property="og:description" content="書籍について 西見 公宏; 吉田 真吾; 大嶋 勇樹. LangChainとLangGraphによるRAG・AIエージェント［実践］入門 エンジニア選書. 株式会社技術評論社. タイトルのとおりで RAG や AI エージェントについて書かれた本。
出版は2024年11月。
LangChain や LangGraph を使ったサンプルコードが豊富に載っている。
著者の方は3名ともジェネラティブエージェンツ社の方で、AI エージェントを扱う会社らしい。
前作として『ChatGPT/LangChainによるチャットシステム構築［実践］入門』という本もあり、本書の何章かは前作の内容を引き継いでアップデートしているとのこと。
個人的にはこれまで LLM や LangChain など追えていなかったので勉強になったし、自分でコードを写経して動かしてみるのがとても面白かった。
AI エージェントまわりの技術を実感したい人におすすめ。
ちなみにサンプルコードを動かすためには OpenAI をはじめとする様々なサービスに登録する必要があり、料金が発生するものも含まれている。
このポストについて 書籍「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」を読んで、面白かったので内容をまとめる。
各章ごとに内容を挙げていってもいいのだが、ここではそうはせず、本書に登場する言葉や概念をまとめていくことにする。
ちなみにこの記事で紹介するプロンプト等は書籍そのままではなく、少し変更している。
実際のプロンプトを知りたい場合は書籍を読んでください。
プロンプトエンジニアリング これは知っている人も多いだろう。
プロンプトとは主に自然言語で記述される、LLM に与える命令のこと。
LLM をアプリケーションに組み込む場合はプロンプトはテンプレート化し、入力データをそれに差し込む形となる。
LLM は必ずしも人間の出す命令に対して望ましい回答を出力してくれるわけではない。
望ましい回答を出力してもらえるよう、プロンプトを工夫するテクニックがプロンプトエンジニアリングである。
本書ではプロンプトエンジニアリングの具体的な手法として次の3つが紹介されていた。
ちなみにここで例として示している出力は実際に OpenAI の LLM gpt-4o-mini で出力したものである。
Zero-shot プロンプティング 簡単なタスクであれば、特に追加の情報がなくとも (=Zero-shot) 望ましい回答を得ることができる。
system: 次の日本酒のレビューをポジティブ・ネガティブ・中立のどれかに分類してください。 user: ふくよかで芳醇な香り 出力
ポジティブ Few-shot プロンプティング より複雑なタスクになった場合、デモンストレーションを与えることで回答の精度を高めることができる。
いくつかのデモンストレーションを示すため、Zero-shot ではなく Few-shot である。"><meta property="og:locale" content="ja"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-02T23:45:00+09:00"><meta property="article:modified_time" content="2025-03-02T23:45:00+09:00"><meta property="article:tag" content="AI Agent"><meta property="article:tag" content="LLM"><meta property="article:tag" content="RAG"><meta property="article:tag" content="LangChain"><meta property="article:tag" content="LangGraph"><meta property="og:image" content="https://soonraah.github.io/image/reading-note/ai_frog_graph_network_with_parrot.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/reading-note/ai_frog_graph_network_with_parrot.jpg"><meta name=twitter:title content="読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門"><meta name=twitter:description content="書籍について

西見 公宏; 吉田 真吾; 大嶋 勇樹. LangChainとLangGraphによるRAG・AIエージェント［実践］入門 エンジニア選書. 株式会社技術評論社.

タイトルのとおりで RAG や AI エージェントについて書かれた本。
出版は2024年11月。
LangChain や LangGraph を使ったサンプルコードが豊富に載っている。
著者の方は3名ともジェネラティブエージェンツ社の方で、AI エージェントを扱う会社らしい。
前作として『ChatGPT/LangChainによるチャットシステム構築［実践］入門』という本もあり、本書の何章かは前作の内容を引き継いでアップデートしているとのこと。
個人的にはこれまで LLM や LangChain など追えていなかったので勉強になったし、自分でコードを写経して動かしてみるのがとても面白かった。
AI エージェントまわりの技術を実感したい人におすすめ。
ちなみにサンプルコードを動かすためには OpenAI をはじめとする様々なサービスに登録する必要があり、料金が発生するものも含まれている。
このポストについて
書籍「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」を読んで、面白かったので内容をまとめる。
各章ごとに内容を挙げていってもいいのだが、ここではそうはせず、本書に登場する言葉や概念をまとめていくことにする。
ちなみにこの記事で紹介するプロンプト等は書籍そのままではなく、少し変更している。
実際のプロンプトを知りたい場合は書籍を読んでください。
プロンプトエンジニアリング
これは知っている人も多いだろう。
プロンプトとは主に自然言語で記述される、LLM に与える命令のこと。
LLM をアプリケーションに組み込む場合はプロンプトはテンプレート化し、入力データをそれに差し込む形となる。
LLM は必ずしも人間の出す命令に対して望ましい回答を出力してくれるわけではない。
望ましい回答を出力してもらえるよう、プロンプトを工夫するテクニックがプロンプトエンジニアリングである。
本書ではプロンプトエンジニアリングの具体的な手法として次の3つが紹介されていた。
ちなみにここで例として示している出力は実際に OpenAI の LLM gpt-4o-mini で出力したものである。
Zero-shot プロンプティング
簡単なタスクであれば、特に追加の情報がなくとも (=Zero-shot) 望ましい回答を得ることができる。
system: 次の日本酒のレビューをポジティブ・ネガティブ・中立のどれかに分類してください。
user: ふくよかで芳醇な香り
出力
ポジティブ
Few-shot プロンプティング
より複雑なタスクになった場合、デモンストレーションを与えることで回答の精度を高めることができる。
いくつかのデモンストレーションを示すため、Zero-shot ではなく Few-shot である。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soonraah.github.io/posts/"},{"@type":"ListItem","position":2,"name":"読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門","item":"https://soonraah.github.io/posts/reading-note-agent-book/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門","name":"読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門","description":"書籍について 西見 公宏; 吉田 真吾; 大嶋 勇樹. LangChainとLangGraphによるRAG・AIエージェント［実践］入門 エンジニア選書. 株式会社技術評論社. タイトルのとおりで RAG や AI エージェントについて書かれた本。\n出版は2024年11月。\nLangChain や LangGraph を使ったサンプルコードが豊富に載っている。\n著者の方は3名ともジェネラティブエージェンツ社の方で、AI エージェントを扱う会社らしい。\n前作として『ChatGPT/LangChainによるチャットシステム構築［実践］入門』という本もあり、本書の何章かは前作の内容を引き継いでアップデートしているとのこと。\n個人的にはこれまで LLM や LangChain など追えていなかったので勉強になったし、自分でコードを写経して動かしてみるのがとても面白かった。\nAI エージェントまわりの技術を実感したい人におすすめ。\nちなみにサンプルコードを動かすためには OpenAI をはじめとする様々なサービスに登録する必要があり、料金が発生するものも含まれている。\nこのポストについて 書籍「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」を読んで、面白かったので内容をまとめる。\n各章ごとに内容を挙げていってもいいのだが、ここではそうはせず、本書に登場する言葉や概念をまとめていくことにする。\nちなみにこの記事で紹介するプロンプト等は書籍そのままではなく、少し変更している。\n実際のプロンプトを知りたい場合は書籍を読んでください。\nプロンプトエンジニアリング これは知っている人も多いだろう。\nプロンプトとは主に自然言語で記述される、LLM に与える命令のこと。\nLLM をアプリケーションに組み込む場合はプロンプトはテンプレート化し、入力データをそれに差し込む形となる。\nLLM は必ずしも人間の出す命令に対して望ましい回答を出力してくれるわけではない。\n望ましい回答を出力してもらえるよう、プロンプトを工夫するテクニックがプロンプトエンジニアリングである。\n本書ではプロンプトエンジニアリングの具体的な手法として次の3つが紹介されていた。\nちなみにここで例として示している出力は実際に OpenAI の LLM gpt-4o-mini で出力したものである。\nZero-shot プロンプティング 簡単なタスクであれば、特に追加の情報がなくとも (=Zero-shot) 望ましい回答を得ることができる。\nsystem: 次の日本酒のレビューをポジティブ・ネガティブ・中立のどれかに分類してください。 user: ふくよかで芳醇な香り 出力\nポジティブ Few-shot プロンプティング より複雑なタスクになった場合、デモンストレーションを与えることで回答の精度を高めることができる。\nいくつかのデモンストレーションを示すため、Zero-shot ではなく Few-shot である。\n","keywords":["AI agent","LLM","RAG","LangChain","LangGraph"],"articleBody":"書籍について 西見 公宏; 吉田 真吾; 大嶋 勇樹. LangChainとLangGraphによるRAG・AIエージェント［実践］入門 エンジニア選書. 株式会社技術評論社. タイトルのとおりで RAG や AI エージェントについて書かれた本。\n出版は2024年11月。\nLangChain や LangGraph を使ったサンプルコードが豊富に載っている。\n著者の方は3名ともジェネラティブエージェンツ社の方で、AI エージェントを扱う会社らしい。\n前作として『ChatGPT/LangChainによるチャットシステム構築［実践］入門』という本もあり、本書の何章かは前作の内容を引き継いでアップデートしているとのこと。\n個人的にはこれまで LLM や LangChain など追えていなかったので勉強になったし、自分でコードを写経して動かしてみるのがとても面白かった。\nAI エージェントまわりの技術を実感したい人におすすめ。\nちなみにサンプルコードを動かすためには OpenAI をはじめとする様々なサービスに登録する必要があり、料金が発生するものも含まれている。\nこのポストについて 書籍「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」を読んで、面白かったので内容をまとめる。\n各章ごとに内容を挙げていってもいいのだが、ここではそうはせず、本書に登場する言葉や概念をまとめていくことにする。\nちなみにこの記事で紹介するプロンプト等は書籍そのままではなく、少し変更している。\n実際のプロンプトを知りたい場合は書籍を読んでください。\nプロンプトエンジニアリング これは知っている人も多いだろう。\nプロンプトとは主に自然言語で記述される、LLM に与える命令のこと。\nLLM をアプリケーションに組み込む場合はプロンプトはテンプレート化し、入力データをそれに差し込む形となる。\nLLM は必ずしも人間の出す命令に対して望ましい回答を出力してくれるわけではない。\n望ましい回答を出力してもらえるよう、プロンプトを工夫するテクニックがプロンプトエンジニアリングである。\n本書ではプロンプトエンジニアリングの具体的な手法として次の3つが紹介されていた。\nちなみにここで例として示している出力は実際に OpenAI の LLM gpt-4o-mini で出力したものである。\nZero-shot プロンプティング 簡単なタスクであれば、特に追加の情報がなくとも (=Zero-shot) 望ましい回答を得ることができる。\nsystem: 次の日本酒のレビューをポジティブ・ネガティブ・中立のどれかに分類してください。 user: ふくよかで芳醇な香り 出力\nポジティブ Few-shot プロンプティング より複雑なタスクになった場合、デモンストレーションを与えることで回答の精度を高めることができる。\nいくつかのデモンストレーションを示すため、Zero-shot ではなく Few-shot である。\nsystem: 次の内容が日本酒についての話かどうかを判定してください。 user: ふくよかで芳醇な香り assistant: True user: 明日は雨らしい assistant: False user: AI エージェントはソフトウェア開発を変えるだろう 出力\nFalse 回答の精度に加え、出力の形式も示すことができる。\nZero-shot Chain-of-Thought プロンプティング system: 以下の計算の結果のみ出力してください。 user: たかし君が200円のリンゴを3個、100円のミカンを2個買ったら財布に150円残りました。たかし君は最初何円持っていたでしょう？ 出力\nたかし君は最初500円持っていました。 この例では回答が間違っている。(またはたかし君の万引きが発覚したか)\nこのように中間的な推論が必要な場合に有効なのが Zero-shot Chain-of-Thought プロンプティングである。\nプロンプトを少し変えてみる。\nsystem: 以下の計算の結果をステップバイステップで考えてください。 user: たかし君が200円のリンゴを3個、100円のミカンを2個買ったら財布に150円残りました。たかし君は最初何円持っていたでしょう？ 出力\nたかし君の最初の金額を求めるために、次のステップで計算を進めます。 1. **リンゴの合計金額を計算する**： リンゴは1個200円で3個買ったので、 \\[ 200円 \\times 3 = 600円 \\] 2. **ミカンの合計金額を計算する**： ミカンは1個100円で2個買ったので、 \\[ 100円 \\times 2 = 200円 \\] 3. **リンゴとミカンの合計金額を求める**： リンゴとミカンの合計金額は、 \\[ 600円 + 200円 = 800円 \\] 4. **財布に残っている金額を考慮する**： たかし君は買い物をした後に150円残っているので、最初の金額を求めるために800円（使った金額）と150円（残っている金額）を足します。 \\[ 800円 + 150円 = 950円 \\] したがって、たかし君は最初に950円持っていたことになります。 見事正解した。\nこのように「ステップバイステップで考える」ことを示すだけで、回答が正確になるという有効な手法である。\nプロンプトエンジニアリングには上に挙げた以外の手法もある。\n詳しくは Prompt Engineering Guide | Prompt Engineering Guide などを参考にするとよい。\nLangChain LangChain の概要 LangChain とは LLM アプリケーションを開発するためのフレームワークである。\n公式ドキュメントによると、\nLangChain simplifies every stage of the LLM application lifecycle:\nDevelopment: Build your applications using LangChain’s open-source components and third-party integrations. Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support. Productionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence. Deployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform. のように開発ライフサイクルの各ステージについての機能がある。\nProductionization の LangSmith については後述するとして、ここでは主に Development について述べる。\nちなみに書籍では Deployment の部分についてはあまり触れられていなかった。\nLangChain の構成 LangChain は Python や JavaScript のライブラリとして OSS で提供されている。\n書籍では主に Python で紹介されていたので、ここでもそれにならう。\nLangChain には次のようなパッケージが含まれる。\nlangchain-core ベースとなる抽象化や LCEL (後述) langchain-openai や langchain-anthropic など OpenAI や Anthropic などパートナーとのインテグレーション langchain-community パートナーのパッケージとして独立していない各種インテグレーション langchain LLM アプリケーション特定のユースケースに特化した機能 langchain-text-splitter テキストの chunk への分割 langchain-experimental 研究・実験目的のコードなど コード例 実際にコードを見るとイメージしやすいというところで見てみよう。\nただしセットアップ方法などはこのポストでは省略。\nfrom langchain_core.prompts import ChatPromptTemplate from langchain_core.output_parsers import StrOutputParser from langchain_openai import ChatOpenAI # プロンプトを用意 prompt = ChatPromptTemplate.from_template( \"{drink}の原料を教えてください。\" ) # LLM を用意 llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0) # parser を用意 output_parser = StrOutputParser() # 用意したものをつなげて処理の連鎖を作成 chain = prompt | llm | output_parser # 実行 result = chain.invoke({\"drink\": \"日本酒\"}) print(result) 出力\n日本酒の主な原料は以下の4つです。 1. **米**: 日本酒の基本的な原料で、特に酒造りに適した「酒米」が使用されます。酒米は、一般的な食用米よりも大きく、デンプン含量が高いのが特徴です。 2. **水**: 日本酒の製造には大量の水が必要です。水の質は日本酒の味に大きく影響するため、清らかでミネラルバランスの良い水が求められます。 3. **酵母**: 発酵を促進するために使用される微生物で、アルコールと香りを生成します。日本酒専用の酵母が多く存在し、それぞれ異なる風味を引き出します。 4. **麹（こうじ）**: 米に麹菌を繁殖させたもので、デンプンを糖に変える役割を果たします。麹は日本酒の発酵過程において非常に重要な役割を担っています。 これらの原料を組み合わせて、発酵・熟成を経て日本酒が作られます。 このように LLM アプリケーションに必要な要素 (Runnable) を | でつなげて鎖のように記述する方法を LangChain Expression Language (LCEL) と言う。\n関数型プログラミングっぽくなっており、プログラミングとしての型が提示されていてとてもいいと思った。\nプロンプトはテンプレート化されているため、例えば日本酒をビールに変えて実行することもできる。\n# 実行 result = chain.invoke({\"drink\": \"ビール\"}) print(result) 上記は非常に簡単な例だが、次のような複雑なこともできる。\n詳しくは書籍を参照。\nPydantic のモデルを出力形式として指定 RunnableLambda で任意の関数を chain に差し込む RunnableParallel で並列処理 RunnablePassthrough で処理をスルー RAG の実装 発展型の Advanced RAG も含む LangSmith LangSmith とはプロダクショングレードの LLM アプリケーション構築のためのプラットフォーム。\nLangChain の開発元、LangChain, Inc. により提供されている web サービスである。\n以下の3つの機能がある。\nObservability: トレーシングなど Evals: LLM アプリケーションのオンライン／オフライン評価 Prompt Engineering: プロンプト管理 ここでは3つのうちの Observability, Evals について述べる。\nObservability LangChain による LLM アプリケーションを実行すると、LangSmith にその情報が送られ、詳細分析ができるというのがこの機能。\nトレーシングのためのセットアップを行っておく必要がある。\n例えば前述の LCEL の例で示したコードの実行結果は次のように表示される。\nLLM への Input/Output が表示されている。\nこの簡単な例ではあまりありがたみがわからないかもしれない。\nしかし後述するエージェントデザインパターンのような、複数の LLM への入出力を経て高度なタスクを実行するようなケースにおいては非常に強力なサポートになる。\nこれがないと各段階で LLM が何をやっているのかがわからない。(もしくは自分でロギングするか…これはこれでしんどい)\nEvals LangSmith を使って LLM アプリケーションのオフライン／オンライン評価を行うことができる。\nここではオフライン評価について見ていこう。\n書籍では Ragas という LLM アプリケーションの評価のためのライブラリを利用した RAG の評価を行っている。\nオフライン評価の流れは以下。\nちなみに書籍ではほとんどのコードは Google Colab で実行することになっている。\n(開発環境などと読み替えてもいいだろう)\nGoogle Colab 上でデータセットを生成 LangSmith にデータセットを登録 Google Colab 上でオフライン評価を実施し、LangSmith に登録 「このデータセットに対する評価」というのが Experiment という単位で LangSmith 上で管理され、LLM アプリケーションの性能改善に伴うメトリクス (評価指標) の変化を追うことができるようになる。\nこの例では context precision および answer relevancy というメトリクスを扱っている。\nRagas にはこの他にも様々なメトリクスがあるので、アプリケーションにあったものを選ぶ必要がある。\nList of available metrics - Ragas こちらのオフライン評価のコードはまあまあ複雑なので割愛。\n書籍のほぼすべてのコードは写経して実行したが、このオフライン評価の部分だけはうまくいかなかったため、\n「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」でつまずいたことメモ:7章 #langchain - Qiita を参考にして作成・実行した。\nLLM アプリケーションのオフラインの性能評価の方法をまったく知らなかったので、個人的には新鮮だった。\n評価データも LLM で作るのか、と。\nAI エージェント 今、世間でも話題になっている AI エージェント。\nAI エージェントの定義はいろいろありそうだが、本書では次のようになっている。\nAIエージェントとは、複雑な目標を自律的に遂行できるAIシステムを指します。従来のAIシステムが特定のタスクに特化していたのに対し、LLMを活用したAIエージェントは、与えられた目標を達成するために必要な行動を自ら決定し、実行することができます。この自律性により、より汎用的で柔軟なLLMアプリの実現が可能になります。\nいくつかの汎用 LLM エージェントのフレームワークが例として挙げられている。\nAutoGPT BabyAGI AutoGen crewAI 書籍ではこれらのフレームワークについてそれぞれ軽い説明が記載されているが、このあたりからエージェントやばいなと思い始めた。\n特にマルチエージェントのアプローチはほぼチームビルディングであり、マネジメントでは？\nマルチエージェントの定義は次のように書かれていた。\nマルチステップなマルチエージェント：一連の処理の中で、複数のシステムプロンプトを使って、役割やステップごとに別々のAIエージェントで処理を行う、ワークフローの最適化を目的とした処理形態 マルチロールなマルチエージェント：異なるペルソナや役割を持たせた複数のエージェントを、目的に向かって協調動作させる形態 マルチエージェントでソフトウェア開発を自動化するためのフレームワークも紹介されていた。\nDevin ChatDev MetaGPT MAGIS Devin などは今すごく話題になっており、これらのエージェントで今後ソフトウェア開発は変わってくんだろうなと思っている。\nLangGraph LangGraph とは LLM を活用した複雑なワークフローを開発するためのライブラリである。\nワークフローといえば Apache Airflow だが、あの DAG のようなものをイメージすればよい。\n(ただし cyclic であることは許されているので DAG ではない)\nDAG の task にあたるところで LLM の呼び出しがあるようなイメージ。\n例えば書籍ではサンプルとして要件定義書生成 AI エージェントの例が記載されている。\nこのエージェントは雑に「◯◯のようなアプリを作りたい」と言うと要件定義書を作成してくれるといったもの。\nワークフローは次のようになっている。\nflowchart TD S@{ shape: circle, label: \"Start\" } generate_personas[\"`generate_personas ペルソナを生成`\"] conduct_intervies[\"`conduct_intervies 生成したペルソナにインタビュー`\"] evaluate_information[\"`evaluate_information インタビュー結果を評価`\"] generate_requirements[\"`generate_requirements 要件定義書を作成`\"] E@{ shape: circle, label: \"End\" } S --\u003e generate_personas generate_personas --\u003e conduct_intervies conduct_intervies --\u003e evaluate_information evaluate_information --\u003e generate_requirements evaluate_information -- 情報量が不十分な場合 --\u003e generate_personas generate_requirements --\u003e E 内部的にアプリのユーザーを想定したペルソナを作成し (generate_personas)、それに対してインタビューを行う (conduct_intervies)。\nそのインタビューの結果を評価し (evaluate_information)、情報が十分なら要件定義書を作成して (generate_requirements) 終了する。\n情報が不十分ならペルソナを追加で作成する。\nLangGraph は名前のとおりこのグラフ構造を表現するものとなっている。\nグラフのノード間のデータの引き渡しには state という概念があり、まずこれを定義してやる必要がある。\nclass InterviewState(BaseModel): user_request: str = Field(..., description=\"ユーザーからのリクエスト\") personas: Annotated[list[Persona], operator.add] = Field( default_factory=list, description=\"生成されたペルソナのリスト\" ) ... 各ノードの処理も実装しておく。\nノード内の処理は LangChain で書くことができる。\nclass PersonaGenerator: def __init__(self, llm: ChatOpenAI, k: int = 5): self.llm = llm.with_structured_output(Personas) self.k = k def run(self, user_request: str) -\u003e Personas: prompt = ChatPromptTemplate.from_messages( # ペルソナ作成用のプロンプト ... ) chain = prompt | self.llm # ペルソナを生成 return chain.invoke({\"user_request\": user_request}) ... 各ノードの処理が実装できたらワークフローを構築する。\nclass DocumentationAgent: def __init__(self, llm: ChatOpenAI, k: Optional[int] = None): # 各種ジェネレータの初期化 self.persona_generator = PersonaGenerator(llm=llm, k=k) ... # グラフの作成 self.graph = self._create_graph() def _create_graph(self) -\u003e StateGraph: # グラフの初期化 workflow = StateGraph(InterviewState) # 各ノードの追加 workflow.add_node(\"generate_personas\", self._generate_personas) ... # エントリーポイントの設定 workflow.set_entry_point(\"generate_personas\") # ノード間のエッジの追加 workflow.add_edge(\"generate_personas\", \"conduct_interviews\") workflow.add_edge(\"conduct_interviews\", \"evaluate_information\") # 条件付きエッジの追加 workflow.add_conditional_edges( \"evaluate_information\", lambda state: not state.is_information_sufficient and state.iteration \u003c 5, {True: \"generate_personas\", False: \"generate_requirements\"}, ) workflow.add_edge(\"generate_requirements\", END) # グラフのコンパイル return workflow.compile() def _generate_personas(self, state: InterviewState) -\u003e dict[str, Any]: # ペルソナの生成 new_personas: Personas = self.persona_generator.run(state.user_request) return { \"personas\": new_personas.personas, \"iteration\": state.iteration + 1, } ... def run(self, user_request: str) -\u003e str: # 初期状態の設定 initial_state = InterviewState(user_request=user_request) # グラフの実行 final_state = self.graph.invoke(initial_state) # 最終的な要件定義書の取得 return final_state[\"requirements_doc\"] コードはかなり端折ったが、エッセンスはわかっていただけたと思う。\n最後の run() を実行すれば要件定義書が作成される。\nこれを写経して実際に動かしてみたところ、それっぽい要件定義書ができて感動した。\nLangGraph でちょっとしたコードを書けばこのような高度？なワークフローが実行できるのである。\n内部的にはペルソナ作ってインタビューしてってやっているが、外部のユーザーからはそれはわからないようになっている。\n逆に言うとこの程度の複雑さのワークフローになってくると LangSmith のトレーシングがかなり意味を持つようになってくる。\nエージェントデザインパターン ソフトウェア設計の言葉で「デザインパターン」というものがある。\nこれは設計でよくある問題を解決するための設計思想やアプローチを示すもの。\nデザインパターン (ソフトウェア) - Wikipedia エージェントデザインパターンはこれの AI エージェント版のようなものであり、AI エージェントの設計のパターンを示す。\nYue Liu らによって提案された。\nAgent Design Pattern Catalogue: A Collection of Architectural Patterns for Foundation Model based Agents 全 18 のパターンが紹介されている。\n目標設定と計画設定 Passive Goal Creator Proactive Goal Creator Prompt/Response Optimizer Single-path Plan Generator Multi-path Plan Generator One-shot Model Querying Incremental Model Querying 推論の確実性向上 Retrieval-Augmented Generation (RAG) Self-Reflection Cross-Reflection Human-Reflection Agent Evaluator エージェント間の協調 Voting-based Cooperation Role-based Cooperation Debate-based Cooperation 入出力制御 Multimodal Guardrails Tool/Agent Registry Agent Adapter 書籍ではこのうちのいくつかについてのサンプルコードを示している。\nここでは簡単なところで Passive Goal Creator の例を見てみる。\nPassive Goal Creator はユーザーの入力から具体的な目標を生成するパターンであり、この結果が後続の LLM への入力となる。\n例えば次のようなプロンプトを用いて、目標を具体化する。\nユーザーの入力を分析し、明確で実行可能な目標を生成してください。 要件: 1. 目標は具体的かつ明確であり、実行可能なレベルで詳細化されている必要があります。 2. ... ユーザーの入力: {query} これを LLM に食わせてより具体的な目標を得、それにより後続の LLM が仕事をしやすくなるわけである。\nサンプルコードでは様々なパターンを追加して組み合わせていくような例が示されており、LLM アプリケーションが賢くなっていく様を見て取ることができた。\n体感として Self-Reflection, Cross-Reflection はなかなか有効だと感じた。\n所感 個人的に LLM まわりをあまり追えていなかったこともあり、冒頭に述べたとおりだがとても興味深く、面白く読むことができた。\nとはいえ挙げられていたライブラリなども含め、この分野は日進月歩で発展しているのでここで得た知識が陳腐化するのも早いだろう。\n以下は細かい所感。\nテストが難しそう 必要な情報を渡せていないのか？LLM の性能の問題なのか？の見分けが難しい LangGraph のノード単位でコードを分割して手厚く単体テストしたり、LangSmith で調べたりなどで頑張るのだろうか 独特の不気味さ LangChain のプログラムとしての美しさ、その一方での LLM という得体の知れないもの この2つが組み合わさっていることに何とも言えない不気味さを感じる こんな簡単なプログラミングで抽象度の高い問題が解ける という感動 何かいろんなことができそうな気がする、しらんけど LLM アプリケーションはほぼマネジメントでは？ agent design pattern とかマルチエージェントとか ここで得た知識を業務に適用することを画策中。\n面白いことができたらまた記事にするかも。\n","wordCount":"924","inLanguage":"ja","image":"https://soonraah.github.io/image/reading-note/ai_frog_graph_network_with_parrot.jpg","datePublished":"2025-03-02T23:45:00+09:00","dateModified":"2025-03-02T23:45:00+09:00","author":{"@type":"Person","name":"soonraah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soonraah.github.io/posts/reading-note-agent-book/"},"publisher":{"@type":"Organization","name":"Froglog","logo":{"@type":"ImageObject","url":"https://soonraah.github.io/favicon2.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soonraah.github.io/>ホーム</a>&nbsp;»&nbsp;<a href=https://soonraah.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門</h1><div class=post-meta><span title='2025-03-02 23:45:00 +0900 JST'>3月 2, 2025</span>&nbsp;·&nbsp;soonraah</div></header><figure class=entry-cover><img loading=eager src=https://soonraah.github.io/image/reading-note/ai_frog_graph_network_with_parrot.jpg alt="AI frog graph network with parrot"><figcaption>Image by OpenAI DALL·E</figcaption></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目次</span></summary><div class=inner><ul><li><a href=#%e6%9b%b8%e7%b1%8d%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6 aria-label=書籍について>書籍について</a></li><li><a href=#%e3%81%93%e3%81%ae%e3%83%9d%e3%82%b9%e3%83%88%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6 aria-label=このポストについて>このポストについて</a></li><li><a href=#%e3%83%97%e3%83%ad%e3%83%b3%e3%83%97%e3%83%88%e3%82%a8%e3%83%b3%e3%82%b8%e3%83%8b%e3%82%a2%e3%83%aa%e3%83%b3%e3%82%b0 aria-label=プロンプトエンジニアリング>プロンプトエンジニアリング</a><ul><li><a href=#zero-shot-%e3%83%97%e3%83%ad%e3%83%b3%e3%83%97%e3%83%86%e3%82%a3%e3%83%b3%e3%82%b0 aria-label="Zero-shot プロンプティング">Zero-shot プロンプティング</a></li><li><a href=#few-shot-%e3%83%97%e3%83%ad%e3%83%b3%e3%83%97%e3%83%86%e3%82%a3%e3%83%b3%e3%82%b0 aria-label="Few-shot プロンプティング">Few-shot プロンプティング</a></li><li><a href=#zero-shot-chain-of-thought-%e3%83%97%e3%83%ad%e3%83%b3%e3%83%97%e3%83%86%e3%82%a3%e3%83%b3%e3%82%b0 aria-label="Zero-shot Chain-of-Thought プロンプティング">Zero-shot Chain-of-Thought プロンプティング</a></li></ul></li><li><a href=#langchain aria-label=LangChain>LangChain</a><ul><li><a href=#langchain-%e3%81%ae%e6%a6%82%e8%a6%81 aria-label="LangChain の概要">LangChain の概要</a></li><li><a href=#langchain-%e3%81%ae%e6%a7%8b%e6%88%90 aria-label="LangChain の構成">LangChain の構成</a></li><li><a href=#%e3%82%b3%e3%83%bc%e3%83%89%e4%be%8b aria-label=コード例>コード例</a></li></ul></li><li><a href=#langsmith aria-label=LangSmith>LangSmith</a><ul><li><a href=#observability aria-label=Observability>Observability</a></li><li><a href=#evals aria-label=Evals>Evals</a></li></ul></li><li><a href=#ai-%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88 aria-label="AI エージェント">AI エージェント</a></li><li><a href=#langgraph aria-label=LangGraph>LangGraph</a></li><li><a href=#%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%e3%83%87%e3%82%b6%e3%82%a4%e3%83%b3%e3%83%91%e3%82%bf%e3%83%bc%e3%83%b3 aria-label=エージェントデザインパターン>エージェントデザインパターン</a></li><li><a href=#%e6%89%80%e6%84%9f aria-label=所感>所感</a></li></ul></div></details></div><div class=post-content><h2 id=書籍について>書籍について<a hidden class=anchor aria-hidden=true href=#書籍について>#</a></h2><ul><li><a href=https://gihyo.jp/book/2024/978-4-297-14530-9>西見 公宏; 吉田 真吾; 大嶋 勇樹. LangChainとLangGraphによるRAG・AIエージェント［実践］入門 エンジニア選書. 株式会社技術評論社.</a></li></ul><p>タイトルのとおりで RAG や AI エージェントについて書かれた本。<br>出版は2024年11月。<br>LangChain や LangGraph を使ったサンプルコードが豊富に載っている。<br>著者の方は3名ともジェネラティブエージェンツ社の方で、AI エージェントを扱う会社らしい。<br>前作として『<a href=https://gihyo.jp/book/2023/978-4-297-13839-4>ChatGPT/LangChainによるチャットシステム構築［実践］入門</a>』という本もあり、本書の何章かは前作の内容を引き継いでアップデートしているとのこと。</p><p>個人的にはこれまで LLM や LangChain など追えていなかったので勉強になったし、自分でコードを写経して動かしてみるのがとても面白かった。<br>AI エージェントまわりの技術を実感したい人におすすめ。<br>ちなみにサンプルコードを動かすためには OpenAI をはじめとする様々なサービスに登録する必要があり、料金が発生するものも含まれている。</p><h2 id=このポストについて>このポストについて<a hidden class=anchor aria-hidden=true href=#このポストについて>#</a></h2><p>書籍「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」を読んで、面白かったので内容をまとめる。<br>各章ごとに内容を挙げていってもいいのだが、ここではそうはせず、本書に登場する言葉や概念をまとめていくことにする。</p><p>ちなみにこの記事で紹介するプロンプト等は書籍そのままではなく、少し変更している。<br>実際のプロンプトを知りたい場合は書籍を読んでください。</p><h2 id=プロンプトエンジニアリング>プロンプトエンジニアリング<a hidden class=anchor aria-hidden=true href=#プロンプトエンジニアリング>#</a></h2><p>これは知っている人も多いだろう。<br>プロンプトとは主に自然言語で記述される、LLM に与える命令のこと。<br>LLM をアプリケーションに組み込む場合はプロンプトはテンプレート化し、入力データをそれに差し込む形となる。</p><p>LLM は必ずしも人間の出す命令に対して望ましい回答を出力してくれるわけではない。<br>望ましい回答を出力してもらえるよう、プロンプトを工夫するテクニックがプロンプトエンジニアリングである。<br>本書ではプロンプトエンジニアリングの具体的な手法として次の3つが紹介されていた。</p><p>ちなみにここで例として示している出力は実際に OpenAI の LLM <code>gpt-4o-mini</code> で出力したものである。</p><h3 id=zero-shot-プロンプティング>Zero-shot プロンプティング<a hidden class=anchor aria-hidden=true href=#zero-shot-プロンプティング>#</a></h3><p>簡単なタスクであれば、特に追加の情報がなくとも (=Zero-shot) 望ましい回答を得ることができる。</p><pre tabindex=0><code>system: 次の日本酒のレビューをポジティブ・ネガティブ・中立のどれかに分類してください。
user: ふくよかで芳醇な香り
</code></pre><p>出力</p><pre tabindex=0><code>ポジティブ
</code></pre><h3 id=few-shot-プロンプティング>Few-shot プロンプティング<a hidden class=anchor aria-hidden=true href=#few-shot-プロンプティング>#</a></h3><p>より複雑なタスクになった場合、デモンストレーションを与えることで回答の精度を高めることができる。<br>いくつかのデモンストレーションを示すため、Zero-shot ではなく Few-shot である。</p><pre tabindex=0><code>system: 次の内容が日本酒についての話かどうかを判定してください。
user: ふくよかで芳醇な香り
assistant: True
user: 明日は雨らしい
assistant: False
user: AI エージェントはソフトウェア開発を変えるだろう
</code></pre><p>出力</p><pre tabindex=0><code>False
</code></pre><p>回答の精度に加え、出力の形式も示すことができる。</p><h3 id=zero-shot-chain-of-thought-プロンプティング>Zero-shot Chain-of-Thought プロンプティング<a hidden class=anchor aria-hidden=true href=#zero-shot-chain-of-thought-プロンプティング>#</a></h3><pre tabindex=0><code>system: 以下の計算の結果のみ出力してください。
user: たかし君が200円のリンゴを3個、100円のミカンを2個買ったら財布に150円残りました。たかし君は最初何円持っていたでしょう？
</code></pre><p>出力</p><pre tabindex=0><code>たかし君は最初500円持っていました。
</code></pre><p>この例では回答が間違っている。(またはたかし君の万引きが発覚したか)</p><p>このように中間的な推論が必要な場合に有効なのが Zero-shot Chain-of-Thought プロンプティングである。<br>プロンプトを少し変えてみる。</p><pre tabindex=0><code>system: 以下の計算の結果をステップバイステップで考えてください。
user: たかし君が200円のリンゴを3個、100円のミカンを2個買ったら財布に150円残りました。たかし君は最初何円持っていたでしょう？
</code></pre><p>出力</p><pre tabindex=0><code>たかし君の最初の金額を求めるために、次のステップで計算を進めます。

1. **リンゴの合計金額を計算する**：
   リンゴは1個200円で3個買ったので、
   \[
   200円 \times 3 = 600円
   \]

2. **ミカンの合計金額を計算する**：
   ミカンは1個100円で2個買ったので、
   \[
   100円 \times 2 = 200円
   \]

3. **リンゴとミカンの合計金額を求める**：
   リンゴとミカンの合計金額は、
   \[
   600円 + 200円 = 800円
   \]

4. **財布に残っている金額を考慮する**：
   たかし君は買い物をした後に150円残っているので、最初の金額を求めるために800円（使った金額）と150円（残っている金額）を足します。
   \[
   800円 + 150円 = 950円
   \]

したがって、たかし君は最初に950円持っていたことになります。
</code></pre><p>見事正解した。<br>このように「ステップバイステップで考える」ことを示すだけで、回答が正確になるという有効な手法である。</p><p>プロンプトエンジニアリングには上に挙げた以外の手法もある。<br>詳しくは <a href=https://www.promptingguide.ai/jp>Prompt Engineering Guide | Prompt Engineering Guide</a> などを参考にするとよい。</p><h2 id=langchain>LangChain<a hidden class=anchor aria-hidden=true href=#langchain>#</a></h2><h3 id=langchain-の概要>LangChain の概要<a hidden class=anchor aria-hidden=true href=#langchain-の概要>#</a></h3><p><a href=https://www.langchain.com/>LangChain</a> とは LLM アプリケーションを開発するためのフレームワークである。<br><a href=https://python.langchain.com/docs/introduction/>公式ドキュメント</a>によると、</p><blockquote><p>LangChain simplifies every stage of the LLM application lifecycle:</p><ul><li>Development: Build your applications using LangChain&rsquo;s open-source components and third-party integrations. Use LangGraph to build stateful agents with first-class streaming and human-in-the-loop support.</li><li>Productionization: Use LangSmith to inspect, monitor and evaluate your applications, so that you can continuously optimize and deploy with confidence.</li><li>Deployment: Turn your LangGraph applications into production-ready APIs and Assistants with LangGraph Platform.</li></ul></blockquote><p>のように開発ライフサイクルの各ステージについての機能がある。<br>Productionization の LangSmith については後述するとして、ここでは主に Development について述べる。<br>ちなみに書籍では Deployment の部分についてはあまり触れられていなかった。</p><h3 id=langchain-の構成>LangChain の構成<a hidden class=anchor aria-hidden=true href=#langchain-の構成>#</a></h3><p>LangChain は Python や JavaScript のライブラリとして OSS で提供されている。<br>書籍では主に Python で紹介されていたので、ここでもそれにならう。<br>LangChain には次のようなパッケージが含まれる。</p><ul><li><code>langchain-core</code><ul><li>ベースとなる抽象化や LCEL (後述)</li></ul></li><li><code>langchain-openai</code> や <code>langchain-anthropic</code> など<ul><li>OpenAI や Anthropic などパートナーとのインテグレーション</li></ul></li><li><code>langchain-community</code><ul><li>パートナーのパッケージとして独立していない各種インテグレーション</li></ul></li><li><code>langchain</code><ul><li>LLM アプリケーション特定のユースケースに特化した機能</li></ul></li><li><code>langchain-text-splitter</code><ul><li>テキストの chunk への分割</li></ul></li><li><code>langchain-experimental</code><ul><li>研究・実験目的のコードなど</li></ul></li></ul><h3 id=コード例>コード例<a hidden class=anchor aria-hidden=true href=#コード例>#</a></h3><p>実際にコードを見るとイメージしやすいというところで見てみよう。<br>ただしセットアップ方法などはこのポストでは省略。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.prompts <span style=color:#f92672>import</span> ChatPromptTemplate
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_core.output_parsers <span style=color:#f92672>import</span> StrOutputParser
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> langchain_openai <span style=color:#f92672>import</span> ChatOpenAI
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># プロンプトを用意</span>
</span></span><span style=display:flex><span>prompt <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_template(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;</span><span style=color:#e6db74>{drink}</span><span style=color:#e6db74>の原料を教えてください。&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># LLM を用意</span>
</span></span><span style=display:flex><span>llm <span style=color:#f92672>=</span> ChatOpenAI(model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-4o-mini&#34;</span>, temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0.0</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># parser を用意</span>
</span></span><span style=display:flex><span>output_parser <span style=color:#f92672>=</span> StrOutputParser()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 用意したものをつなげて処理の連鎖を作成</span>
</span></span><span style=display:flex><span>chain <span style=color:#f92672>=</span> prompt <span style=color:#f92672>|</span> llm <span style=color:#f92672>|</span> output_parser
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># 実行</span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> chain<span style=color:#f92672>.</span>invoke({<span style=color:#e6db74>&#34;drink&#34;</span>: <span style=color:#e6db74>&#34;日本酒&#34;</span>})
</span></span><span style=display:flex><span>print(result)
</span></span></code></pre></div><p>出力</p><pre tabindex=0><code>日本酒の主な原料は以下の4つです。

1. **米**: 日本酒の基本的な原料で、特に酒造りに適した「酒米」が使用されます。酒米は、一般的な食用米よりも大きく、デンプン含量が高いのが特徴です。

2. **水**: 日本酒の製造には大量の水が必要です。水の質は日本酒の味に大きく影響するため、清らかでミネラルバランスの良い水が求められます。

3. **酵母**: 発酵を促進するために使用される微生物で、アルコールと香りを生成します。日本酒専用の酵母が多く存在し、それぞれ異なる風味を引き出します。

4. **麹（こうじ）**: 米に麹菌を繁殖させたもので、デンプンを糖に変える役割を果たします。麹は日本酒の発酵過程において非常に重要な役割を担っています。

これらの原料を組み合わせて、発酵・熟成を経て日本酒が作られます。
</code></pre><p>このように LLM アプリケーションに必要な要素 (<code>Runnable</code>) を <code>|</code> でつなげて鎖のように記述する方法を <a href=https://python.langchain.com/docs/concepts/lcel/>LangChain Expression Language (LCEL)</a> と言う。<br>関数型プログラミングっぽくなっており、プログラミングとしての型が提示されていてとてもいいと思った。</p><p>プロンプトはテンプレート化されているため、例えば日本酒をビールに変えて実行することもできる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># 実行</span>
</span></span><span style=display:flex><span>result <span style=color:#f92672>=</span> chain<span style=color:#f92672>.</span>invoke({<span style=color:#e6db74>&#34;drink&#34;</span>: <span style=color:#e6db74>&#34;ビール&#34;</span>})
</span></span><span style=display:flex><span>print(result)
</span></span></code></pre></div><p>上記は非常に簡単な例だが、次のような複雑なこともできる。<br>詳しくは書籍を参照。</p><ul><li>Pydantic のモデルを出力形式として指定</li><li><code>RunnableLambda</code> で任意の関数を chain に差し込む</li><li><code>RunnableParallel</code> で並列処理</li><li><code>RunnablePassthrough</code> で処理をスルー</li><li>RAG の実装<ul><li>発展型の Advanced RAG も含む</li></ul></li></ul><h2 id=langsmith>LangSmith<a hidden class=anchor aria-hidden=true href=#langsmith>#</a></h2><p><a href=https://www.langchain.com/langsmith>LangSmith</a> とはプロダクショングレードの LLM アプリケーション構築のためのプラットフォーム。<br>LangChain の開発元、LangChain, Inc. により提供されている web サービスである。<br>以下の3つの機能がある。</p><ul><li>Observability: トレーシングなど</li><li>Evals: LLM アプリケーションのオンライン／オフライン評価</li><li>Prompt Engineering: プロンプト管理</li></ul><p>ここでは3つのうちの Observability, Evals について述べる。</p><h3 id=observability>Observability<a hidden class=anchor aria-hidden=true href=#observability>#</a></h3><p>LangChain による LLM アプリケーションを実行すると、LangSmith にその情報が送られ、詳細分析ができるというのがこの機能。<br>トレーシングのための<a href=https://docs.smith.langchain.com/observability#3-set-up-your-environment>セットアップ</a>を行っておく必要がある。</p><p>例えば前述の LCEL の例で示したコードの実行結果は次のように表示される。</p><p><img alt="LangSmith Tracing" loading=lazy src=/image/reading-note/langsmith_tracing.png></p><p>LLM への Input/Output が表示されている。<br>この簡単な例ではあまりありがたみがわからないかもしれない。<br>しかし後述するエージェントデザインパターンのような、複数の LLM への入出力を経て高度なタスクを実行するようなケースにおいては非常に強力なサポートになる。<br>これがないと各段階で LLM が何をやっているのかがわからない。(もしくは自分でロギングするか…これはこれでしんどい)</p><h3 id=evals>Evals<a hidden class=anchor aria-hidden=true href=#evals>#</a></h3><p>LangSmith を使って LLM アプリケーションのオフライン／オンライン評価を行うことができる。<br>ここではオフライン評価について見ていこう。<br>書籍では <a href=https://docs.ragas.io/en/stable/>Ragas</a> という LLM アプリケーションの評価のためのライブラリを利用した RAG の評価を行っている。</p><p>オフライン評価の流れは以下。<br>ちなみに書籍ではほとんどのコードは Google Colab で実行することになっている。<br>(開発環境などと読み替えてもいいだろう)</p><ol><li>Google Colab 上でデータセットを生成</li><li>LangSmith にデータセットを登録</li><li>Google Colab 上でオフライン評価を実施し、LangSmith に登録</li></ol><p>「このデータセットに対する評価」というのが Experiment という単位で LangSmith 上で管理され、LLM アプリケーションの性能改善に伴うメトリクス (評価指標) の変化を追うことができるようになる。</p><p><img alt="LangSmith Experiment" loading=lazy src=/image/reading-note/langsmith_experiment.png></p><p>この例では context precision および answer relevancy というメトリクスを扱っている。<br>Ragas にはこの他にも様々なメトリクスがあるので、アプリケーションにあったものを選ぶ必要がある。</p><ul><li><a href=https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/>List of available metrics - Ragas</a></li></ul><p>こちらのオフライン評価のコードはまあまあ複雑なので割愛。<br>書籍のほぼすべてのコードは写経して実行したが、このオフライン評価の部分だけはうまくいかなかったため、</p><ul><li><a href=https://qiita.com/segavvy/items/ac0ce03f9b3cd83ee5ed>「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」でつまずいたことメモ:7章 #langchain - Qiita</a></li></ul><p>を参考にして作成・実行した。</p><p>LLM アプリケーションのオフラインの性能評価の方法をまったく知らなかったので、個人的には新鮮だった。<br>評価データも LLM で作るのか、と。</p><h2 id=ai-エージェント>AI エージェント<a hidden class=anchor aria-hidden=true href=#ai-エージェント>#</a></h2><p>今、世間でも話題になっている AI エージェント。<br>AI エージェントの定義はいろいろありそうだが、本書では次のようになっている。</p><blockquote><p>AIエージェントとは、複雑な目標を自律的に遂行できるAIシステムを指します。従来のAIシステムが特定のタスクに特化していたのに対し、LLMを活用したAIエージェントは、与えられた目標を達成するために必要な行動を自ら決定し、実行することができます。この自律性により、より汎用的で柔軟なLLMアプリの実現が可能になります。</p></blockquote><p>いくつかの汎用 LLM エージェントのフレームワークが例として挙げられている。</p><ul><li><a href=https://agpt.co/>AutoGPT</a></li><li><a href=https://github.com/yoheinakajima/babyagi>BabyAGI</a></li><li><a href=https://arxiv.org/abs/2308.08155>AutoGen</a></li><li><a href=https://github.com/crewAIInc/crewAI>crewAI</a></li></ul><p>書籍ではこれらのフレームワークについてそれぞれ軽い説明が記載されているが、このあたりからエージェントやばいなと思い始めた。<br>特にマルチエージェントのアプローチはほぼチームビルディングであり、マネジメントでは？<br>マルチエージェントの定義は次のように書かれていた。</p><blockquote><ul><li>マルチステップなマルチエージェント：一連の処理の中で、複数のシステムプロンプトを使って、役割やステップごとに別々のAIエージェントで処理を行う、ワークフローの最適化を目的とした処理形態</li><li>マルチロールなマルチエージェント：異なるペルソナや役割を持たせた複数のエージェントを、目的に向かって協調動作させる形態</li></ul></blockquote><p>マルチエージェントでソフトウェア開発を自動化するためのフレームワークも紹介されていた。</p><ul><li><a href=https://www.cognition.ai/blog/introducing-devin>Devin</a></li><li><a href=https://arxiv.org/abs/2307.07924>ChatDev</a></li><li><a href=https://arxiv.org/abs/2308.00352>MetaGPT</a></li><li><a href=https://arxiv.org/abs/2403.17927>MAGIS</a></li></ul><p>Devin などは今すごく話題になっており、これらのエージェントで今後ソフトウェア開発は変わってくんだろうなと思っている。</p><h2 id=langgraph>LangGraph<a hidden class=anchor aria-hidden=true href=#langgraph>#</a></h2><p><a href=https://www.langchain.com/langgraph>LangGraph</a> とは LLM を活用した複雑なワークフローを開発するためのライブラリである。<br>ワークフローといえば Apache Airflow だが、あの DAG のようなものをイメージすればよい。<br>(ただし cyclic であることは許されているので DAG ではない)<br>DAG の task にあたるところで LLM の呼び出しがあるようなイメージ。</p><p>例えば書籍ではサンプルとして要件定義書生成 AI エージェントの例が記載されている。<br>このエージェントは雑に「◯◯のようなアプリを作りたい」と言うと要件定義書を作成してくれるといったもの。<br>ワークフローは次のようになっている。</p><pre class=mermaid>flowchart TD
    S@{ shape: circle, label: "Start" }
    generate_personas["`generate_personas
    ペルソナを生成`"]
    conduct_intervies["`conduct_intervies
    生成したペルソナにインタビュー`"]
    evaluate_information["`evaluate_information
    インタビュー結果を評価`"]
    generate_requirements["`generate_requirements
    要件定義書を作成`"]
    E@{ shape: circle, label: "End" }

    S --> generate_personas
    generate_personas --> conduct_intervies
    conduct_intervies --> evaluate_information
    evaluate_information --> generate_requirements
    evaluate_information -- 情報量が不十分な場合 --> generate_personas
    generate_requirements --> E
</pre><p>内部的にアプリのユーザーを想定したペルソナを作成し (<code>generate_personas</code>)、それに対してインタビューを行う (<code>conduct_intervies</code>)。<br>そのインタビューの結果を評価し (<code>evaluate_information</code>)、情報が十分なら要件定義書を作成して (<code>generate_requirements</code>) 終了する。<br>情報が不十分ならペルソナを追加で作成する。</p><p>LangGraph は名前のとおりこのグラフ構造を表現するものとなっている。<br>グラフのノード間のデータの引き渡しには state という概念があり、まずこれを定義してやる必要がある。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>InterviewState</span>(BaseModel):
</span></span><span style=display:flex><span>     user_request: str <span style=color:#f92672>=</span> Field(<span style=color:#f92672>...</span>, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;ユーザーからのリクエスト&#34;</span>)
</span></span><span style=display:flex><span>     personas: Annotated[list[Persona], operator<span style=color:#f92672>.</span>add] <span style=color:#f92672>=</span> Field(
</span></span><span style=display:flex><span>         default_factory<span style=color:#f92672>=</span>list, description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;生成されたペルソナのリスト&#34;</span>
</span></span><span style=display:flex><span>     )
</span></span><span style=display:flex><span>     <span style=color:#f92672>...</span>
</span></span></code></pre></div><p>各ノードの処理も実装しておく。<br>ノード内の処理は LangChain で書くことができる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>PersonaGenerator</span>:
</span></span><span style=display:flex><span>     <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, llm: ChatOpenAI, k: int <span style=color:#f92672>=</span> <span style=color:#ae81ff>5</span>):
</span></span><span style=display:flex><span>         self<span style=color:#f92672>.</span>llm <span style=color:#f92672>=</span> llm<span style=color:#f92672>.</span>with_structured_output(Personas)
</span></span><span style=display:flex><span>         self<span style=color:#f92672>.</span>k <span style=color:#f92672>=</span> k
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>     <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(self, user_request: str) <span style=color:#f92672>-&gt;</span> Personas:
</span></span><span style=display:flex><span>         prompt <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_messages(
</span></span><span style=display:flex><span>            <span style=color:#75715e># ペルソナ作成用のプロンプト</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>         )
</span></span><span style=display:flex><span>         chain <span style=color:#f92672>=</span> prompt <span style=color:#f92672>|</span> self<span style=color:#f92672>.</span>llm
</span></span><span style=display:flex><span>         <span style=color:#75715e># ペルソナを生成</span>
</span></span><span style=display:flex><span>         <span style=color:#66d9ef>return</span> chain<span style=color:#f92672>.</span>invoke({<span style=color:#e6db74>&#34;user_request&#34;</span>: user_request})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>
</span></span></code></pre></div><p>各ノードの処理が実装できたらワークフローを構築する。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>DocumentationAgent</span>:
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, llm: ChatOpenAI, k: Optional[int] <span style=color:#f92672>=</span> <span style=color:#66d9ef>None</span>):
</span></span><span style=display:flex><span>        <span style=color:#75715e># 各種ジェネレータの初期化</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>persona_generator <span style=color:#f92672>=</span> PersonaGenerator(llm<span style=color:#f92672>=</span>llm, k<span style=color:#f92672>=</span>k)
</span></span><span style=display:flex><span>        <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># グラフの作成</span>
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>graph <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_create_graph()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_create_graph</span>(self) <span style=color:#f92672>-&gt;</span> StateGraph:
</span></span><span style=display:flex><span>        <span style=color:#75715e># グラフの初期化</span>
</span></span><span style=display:flex><span>        workflow <span style=color:#f92672>=</span> StateGraph(InterviewState)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 各ノードの追加</span>
</span></span><span style=display:flex><span>        workflow<span style=color:#f92672>.</span>add_node(<span style=color:#e6db74>&#34;generate_personas&#34;</span>, self<span style=color:#f92672>.</span>_generate_personas)
</span></span><span style=display:flex><span>        <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># エントリーポイントの設定</span>
</span></span><span style=display:flex><span>        workflow<span style=color:#f92672>.</span>set_entry_point(<span style=color:#e6db74>&#34;generate_personas&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># ノード間のエッジの追加</span>
</span></span><span style=display:flex><span>        workflow<span style=color:#f92672>.</span>add_edge(<span style=color:#e6db74>&#34;generate_personas&#34;</span>, <span style=color:#e6db74>&#34;conduct_interviews&#34;</span>)
</span></span><span style=display:flex><span>        workflow<span style=color:#f92672>.</span>add_edge(<span style=color:#e6db74>&#34;conduct_interviews&#34;</span>, <span style=color:#e6db74>&#34;evaluate_information&#34;</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 条件付きエッジの追加</span>
</span></span><span style=display:flex><span>        workflow<span style=color:#f92672>.</span>add_conditional_edges(
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;evaluate_information&#34;</span>,
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>lambda</span> state: <span style=color:#f92672>not</span> state<span style=color:#f92672>.</span>is_information_sufficient <span style=color:#f92672>and</span> state<span style=color:#f92672>.</span>iteration <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>5</span>,
</span></span><span style=display:flex><span>            {<span style=color:#66d9ef>True</span>: <span style=color:#e6db74>&#34;generate_personas&#34;</span>, <span style=color:#66d9ef>False</span>: <span style=color:#e6db74>&#34;generate_requirements&#34;</span>},
</span></span><span style=display:flex><span>        )
</span></span><span style=display:flex><span>        workflow<span style=color:#f92672>.</span>add_edge(<span style=color:#e6db74>&#34;generate_requirements&#34;</span>, END)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># グラフのコンパイル</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> workflow<span style=color:#f92672>.</span>compile()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_generate_personas</span>(self, state: InterviewState) <span style=color:#f92672>-&gt;</span> dict[str, Any]:
</span></span><span style=display:flex><span>        <span style=color:#75715e># ペルソナの生成</span>
</span></span><span style=display:flex><span>        new_personas: Personas <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>persona_generator<span style=color:#f92672>.</span>run(state<span style=color:#f92672>.</span>user_request)
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> {
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;personas&#34;</span>: new_personas<span style=color:#f92672>.</span>personas,
</span></span><span style=display:flex><span>            <span style=color:#e6db74>&#34;iteration&#34;</span>: state<span style=color:#f92672>.</span>iteration <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>,
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>run</span>(self, user_request: str) <span style=color:#f92672>-&gt;</span> str:
</span></span><span style=display:flex><span>        <span style=color:#75715e># 初期状態の設定</span>
</span></span><span style=display:flex><span>        initial_state <span style=color:#f92672>=</span> InterviewState(user_request<span style=color:#f92672>=</span>user_request)
</span></span><span style=display:flex><span>        <span style=color:#75715e># グラフの実行</span>
</span></span><span style=display:flex><span>        final_state <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>graph<span style=color:#f92672>.</span>invoke(initial_state)
</span></span><span style=display:flex><span>        <span style=color:#75715e># 最終的な要件定義書の取得</span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> final_state[<span style=color:#e6db74>&#34;requirements_doc&#34;</span>]
</span></span></code></pre></div><p>コードはかなり端折ったが、エッセンスはわかっていただけたと思う。<br>最後の <code>run()</code> を実行すれば要件定義書が作成される。</p><p>これを写経して実際に動かしてみたところ、それっぽい要件定義書ができて感動した。<br>LangGraph でちょっとしたコードを書けばこのような高度？なワークフローが実行できるのである。</p><p>内部的にはペルソナ作ってインタビューしてってやっているが、外部のユーザーからはそれはわからないようになっている。<br>逆に言うとこの程度の複雑さのワークフローになってくると LangSmith のトレーシングがかなり意味を持つようになってくる。</p><h2 id=エージェントデザインパターン>エージェントデザインパターン<a hidden class=anchor aria-hidden=true href=#エージェントデザインパターン>#</a></h2><p>ソフトウェア設計の言葉で「デザインパターン」というものがある。<br>これは設計でよくある問題を解決するための設計思想やアプローチを示すもの。</p><ul><li><a href=https://ja.wikipedia.org/wiki/%E3%83%87%E3%82%B6%E3%82%A4%E3%83%B3%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3_%28%E3%82%BD%E3%83%95%E3%83%88%E3%82%A6%E3%82%A7%E3%82%A2%29>デザインパターン (ソフトウェア) - Wikipedia</a></li></ul><p>エージェントデザインパターンはこれの AI エージェント版のようなものであり、AI エージェントの設計のパターンを示す。<br>Yue Liu らによって提案された。</p><ul><li><a href=https://arxiv.org/abs/2405.10467>Agent Design Pattern Catalogue: A Collection of Architectural Patterns for Foundation Model based Agents</a></li></ul><p>全 18 のパターンが紹介されている。</p><ol><li>目標設定と計画設定<ul><li>Passive Goal Creator</li><li>Proactive Goal Creator</li><li>Prompt/Response Optimizer</li><li>Single-path Plan Generator</li><li>Multi-path Plan Generator</li><li>One-shot Model Querying</li><li>Incremental Model Querying</li></ul></li><li>推論の確実性向上<ul><li>Retrieval-Augmented Generation (RAG)</li><li>Self-Reflection</li><li>Cross-Reflection</li><li>Human-Reflection</li><li>Agent Evaluator</li></ul></li><li>エージェント間の協調<ul><li>Voting-based Cooperation</li><li>Role-based Cooperation</li><li>Debate-based Cooperation</li></ul></li><li>入出力制御<ul><li>Multimodal Guardrails</li><li>Tool/Agent Registry</li><li>Agent Adapter</li></ul></li></ol><p>書籍ではこのうちのいくつかについてのサンプルコードを示している。<br>ここでは簡単なところで Passive Goal Creator の例を見てみる。</p><p>Passive Goal Creator はユーザーの入力から具体的な目標を生成するパターンであり、この結果が後続の LLM への入力となる。<br>例えば次のようなプロンプトを用いて、目標を具体化する。</p><pre tabindex=0><code>ユーザーの入力を分析し、明確で実行可能な目標を生成してください。
要件:
1. 目標は具体的かつ明確であり、実行可能なレベルで詳細化されている必要があります。
2. ...

ユーザーの入力: {query}
</code></pre><p>これを LLM に食わせてより具体的な目標を得、それにより後続の LLM が仕事をしやすくなるわけである。</p><p>サンプルコードでは様々なパターンを追加して組み合わせていくような例が示されており、LLM アプリケーションが賢くなっていく様を見て取ることができた。<br>体感として Self-Reflection, Cross-Reflection はなかなか有効だと感じた。</p><h2 id=所感>所感<a hidden class=anchor aria-hidden=true href=#所感>#</a></h2><p>個人的に LLM まわりをあまり追えていなかったこともあり、冒頭に述べたとおりだがとても興味深く、面白く読むことができた。<br>とはいえ挙げられていたライブラリなども含め、この分野は日進月歩で発展しているのでここで得た知識が陳腐化するのも早いだろう。<br>以下は細かい所感。</p><ul><li>テストが難しそう<ul><li>必要な情報を渡せていないのか？LLM の性能の問題なのか？の見分けが難しい</li><li>LangGraph のノード単位でコードを分割して手厚く単体テストしたり、LangSmith で調べたりなどで頑張るのだろうか</li></ul></li><li>独特の不気味さ<ul><li>LangChain のプログラムとしての美しさ、その一方での LLM という得体の知れないもの</li><li>この2つが組み合わさっていることに何とも言えない不気味さを感じる</li></ul></li><li>こんな簡単なプログラミングで抽象度の高い問題が解ける<ul><li>という感動</li><li>何かいろんなことができそうな気がする、しらんけど</li></ul></li><li>LLM アプリケーションはほぼマネジメントでは？<ul><li>agent design pattern とかマルチエージェントとか</li></ul></li></ul><p>ここで得た知識を業務に適用することを画策中。<br>面白いことができたらまた記事にするかも。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://soonraah.github.io/tags/ai-agent/>AI Agent</a></li><li><a href=https://soonraah.github.io/tags/llm/>LLM</a></li><li><a href=https://soonraah.github.io/tags/rag/>RAG</a></li><li><a href=https://soonraah.github.io/tags/langchain/>LangChain</a></li><li><a href=https://soonraah.github.io/tags/langgraph/>LangGraph</a></li></ul><nav class=paginav><a class=prev href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-3/><span class=title>« 前へ</span><br><span>ふつうのデータ基盤移行 - Part 3. アーキテクチャ編</span>
</a><a class=next href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/><span class=title>次へ »</span><br><span>ふつうのデータ基盤移行 - Part 2. 技術選定編</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share 読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門 on x" href="https://x.com/intent/tweet/?text=%e8%aa%ad%e6%9b%b8%e3%83%a1%e3%83%a2%3a%20LangChain%e3%81%a8LangGraph%e3%81%ab%e3%82%88%e3%82%8bRAG%e3%83%bbAI%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%ef%bc%bb%e5%ae%9f%e8%b7%b5%ef%bc%bd%e5%85%a5%e9%96%80&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2freading-note-agent-book%2f&amp;hashtags=AIagent%2cLLM%2cRAG%2cLangChain%2cLangGraph"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2freading-note-agent-book%2f&amp;title=%e8%aa%ad%e6%9b%b8%e3%83%a1%e3%83%a2%3a%20LangChain%e3%81%a8LangGraph%e3%81%ab%e3%82%88%e3%82%8bRAG%e3%83%bbAI%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%ef%bc%bb%e5%ae%9f%e8%b7%b5%ef%bc%bd%e5%85%a5%e9%96%80&amp;summary=%e8%aa%ad%e6%9b%b8%e3%83%a1%e3%83%a2%3a%20LangChain%e3%81%a8LangGraph%e3%81%ab%e3%82%88%e3%82%8bRAG%e3%83%bbAI%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%ef%bc%bb%e5%ae%9f%e8%b7%b5%ef%bc%bd%e5%85%a5%e9%96%80&amp;source=https%3a%2f%2fsoonraah.github.io%2fposts%2freading-note-agent-book%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoonraah.github.io%2fposts%2freading-note-agent-book%2f&title=%e8%aa%ad%e6%9b%b8%e3%83%a1%e3%83%a2%3a%20LangChain%e3%81%a8LangGraph%e3%81%ab%e3%82%88%e3%82%8bRAG%e3%83%bbAI%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%ef%bc%bb%e5%ae%9f%e8%b7%b5%ef%bc%bd%e5%85%a5%e9%96%80"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoonraah.github.io%2fposts%2freading-note-agent-book%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門 on whatsapp" href="https://api.whatsapp.com/send?text=%e8%aa%ad%e6%9b%b8%e3%83%a1%e3%83%a2%3a%20LangChain%e3%81%a8LangGraph%e3%81%ab%e3%82%88%e3%82%8bRAG%e3%83%bbAI%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%ef%bc%bb%e5%ae%9f%e8%b7%b5%ef%bc%bd%e5%85%a5%e9%96%80%20-%20https%3a%2f%2fsoonraah.github.io%2fposts%2freading-note-agent-book%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門 on telegram" href="https://telegram.me/share/url?text=%e8%aa%ad%e6%9b%b8%e3%83%a1%e3%83%a2%3a%20LangChain%e3%81%a8LangGraph%e3%81%ab%e3%82%88%e3%82%8bRAG%e3%83%bbAI%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%ef%bc%bb%e5%ae%9f%e8%b7%b5%ef%bc%bd%e5%85%a5%e9%96%80&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2freading-note-agent-book%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share 読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%e8%aa%ad%e6%9b%b8%e3%83%a1%e3%83%a2%3a%20LangChain%e3%81%a8LangGraph%e3%81%ab%e3%82%88%e3%82%8bRAG%e3%83%bbAI%e3%82%a8%e3%83%bc%e3%82%b8%e3%82%a7%e3%83%b3%e3%83%88%ef%bc%bb%e5%ae%9f%e8%b7%b5%ef%bc%bd%e5%85%a5%e9%96%80&u=https%3a%2f%2fsoonraah.github.io%2fposts%2freading-note-agent-book%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://soonraah.github.io/>Froglog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="コピー";function s(){t.innerHTML="コピーされました!",setTimeout(()=>{t.innerHTML="コピー"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
  </script></body></html>