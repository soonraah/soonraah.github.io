<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu | Froglog</title>
<meta name=keywords content="Data Lake,Delta Lake,Apache Hudi,Apache Kudu"><meta name=description content="はじめに
前回のポストではデータレイクとはどういうものかというのを調べた。
今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。
以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。


    大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05）  from NTT DATA Technology & Innovation 




Delta Lake
Apache Hudi
Apache Kudu

これらはすべて論理的なストレージレイヤーを担う。
こちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。
当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。
Delta Lake
https://delta.io/

Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.

     
            
                    Delta Lake
        


Delta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。
Databricks が作り、2019年4月に v0.1.0 がリリースされたのが最初だ。
使い方はめちゃ簡単で、dependency を設定した上で Spark で"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/oss-for-data-lake/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ja href=https://soonraah.github.io/posts/oss-for-data-lake/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://soonraah.github.io/posts/oss-for-data-lake/"><meta property="og:site_name" content="Froglog"><meta property="og:title" content="データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu"><meta property="og:description" content="はじめに 前回のポストではデータレイクとはどういうものかというのを調べた。
今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。
以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。
大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05） from NTT DATA Technology & Innovation Delta Lake Apache Hudi Apache Kudu これらはすべて論理的なストレージレイヤーを担う。
こちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。
当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。
Delta Lake https://delta.io/
Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.
Delta Lake
Delta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。
Databricks が作り、2019年4月に v0.1.0 がリリースされたのが最初だ。
使い方はめちゃ簡単で、dependency を設定した上で Spark で"><meta property="og:locale" content="ja"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-01-26T08:00:00+09:00"><meta property="article:modified_time" content="2021-01-26T08:00:00+09:00"><meta property="article:tag" content="Data Lake"><meta property="article:tag" content="Delta Lake"><meta property="article:tag" content="Apache Hudi"><meta property="article:tag" content="Apache Kudu"><meta property="og:image" content="https://soonraah.github.io/image/photo/claudia-chiavazza-N9vsB6OEeKM-unsplash.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/photo/claudia-chiavazza-N9vsB6OEeKM-unsplash.jpg"><meta name=twitter:title content="データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu"><meta name=twitter:description content="はじめに
前回のポストではデータレイクとはどういうものかというのを調べた。
今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。
以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。


    大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05）  from NTT DATA Technology & Innovation 




Delta Lake
Apache Hudi
Apache Kudu

これらはすべて論理的なストレージレイヤーを担う。
こちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。
当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。
Delta Lake
https://delta.io/

Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.

     
            
                    Delta Lake
        


Delta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。
Databricks が作り、2019年4月に v0.1.0 がリリースされたのが最初だ。
使い方はめちゃ簡単で、dependency を設定した上で Spark で"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soonraah.github.io/posts/"},{"@type":"ListItem","position":2,"name":"データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu","item":"https://soonraah.github.io/posts/oss-for-data-lake/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu","name":"データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu","description":"はじめに 前回のポストではデータレイクとはどういうものかというのを調べた。\n今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。\n以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。\n大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05） from NTT DATA Technology \u0026amp; Innovation Delta Lake Apache Hudi Apache Kudu これらはすべて論理的なストレージレイヤーを担う。\nこちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。\n当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。\nDelta Lake https://delta.io/\nDelta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.\nDelta Lake\nDelta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。\nDatabricks が作り、2019年4月に v0.1.0 がリリースされたのが最初だ。\n使い方はめちゃ簡単で、dependency を設定した上で Spark で\n","keywords":["Data Lake","Delta Lake","Apache Hudi","Apache Kudu"],"articleBody":"はじめに 前回のポストではデータレイクとはどういうものかというのを調べた。\n今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。\n以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。\n大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05） from NTT DATA Technology \u0026 Innovation Delta Lake Apache Hudi Apache Kudu これらはすべて論理的なストレージレイヤーを担う。\nこちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。\n当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。\nDelta Lake https://delta.io/\nDelta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.\nDelta Lake\nDelta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。\nDatabricks が作り、2019年4月に v0.1.0 がリリースされたのが最初だ。\n使い方はめちゃ簡単で、dependency を設定した上で Spark で\ndataframe .write .format(\"delta\") .save(\"/data\") のように読み書きすればよい。\nデータレイク化が進むと多種多様なデータが一元的に管理され、それらデータに対して横断的なクエリを実行できるようになる。\n各データの更新タイミングも様々であり、そのような状況では ACID 特性の中でも特に Isolation (独立性) が問題となってくる。\nSpark を処理エンジンとして使う場合、データソース・読み方によっては isolation level が弱くなってしまうことがあるというのは過去のポストでも述べた。\nおそらくこのことが Delta Lake の開発の強い動機となっているのではないだろうか。\nDelta Lake は最も強い isolation level である “serializability” を提供する。\nACID transaction の他には schema に合わないデータを弾いたり過去のデータのスナップショットにアクセスしたりなどの機能がある。\nどれもデータレイクの治安を守る方向であり、データスワンプ化に抵抗したいようだ。\nこれらを実現しているのが transaction log という仕組みとのこと。\nDelta Lake は table に対する変更の transaction を atomic な commit という単位に分け、commit ごとに操作を JSON file に書き出していく。\nJSON file には 000000.json, 000001.json のように連番が振られており、2つの application が同時に table を更新するような場合は各 application が次の番号の JSON file を作れるかどうかで衝突を制御している。\nJSON file はずっと蓄積していくため再計算のコストが大きくなっていくが、その時点での table の完全な状態を parquet にした checkpoint file というものを時折出力するという、compaction のようなことも行われる。\n(Delta Lake は parquet 形式のデータ保存を前提としている)\n詳しくは Databricks の blog を参照。\nDiving Into Delta Lake: Unpacking The Transaction Log Apache Hudi https://hudi.apache.org/\nHudi brings stream processing to big data, providing fresh data while being an order of magnitude efficient over traditional batch processing.\nApache Hudi\nApache Hudi で何ができるかを一言で説明するのは難しい。\n簡単にまとめると HDFS や S3 等にある table にリアルタイムに近いデータ取り込みと、処理速度とデータの新鮮さのトレードオフに配慮した読み込みを提供する。\n2016年から Uber が開発をしており、2020年に Apache Software Fundation の top-level project となった。\nデータレイクではあらゆる種類のデータを一元管理するが、その中には当然リアルタイム性の高いデータも含むことになる。\nデータレイク中のリアルタイム性の高いデータについては次のような要求が出てくる。\ntable へのデータの取り込みはリアルタイムに近いスピードで細かくやりたい 分析クエリ等の table の読み込みにおけるクエリの速度は速くしたい (例えば列指向形式で保存されたデータの様に) 取り込まれたデータをすぐに読めるようにしたい Hudi はこれに応えるものとなっている。\nこれらを実現するのが Merge On Read のデータ構造だ。\nHudi の table には Copy On Write と Merge On Read の2種類がある。\nここでは Hudi の肝である後者について触れておきたい。\nApache Hudi Merge On Read TablePermalink\ntable に加えられた変更についての情報は timeline に追加される。\n時系列になった変更についてのメタデータのようなものだろうか。\nこの timeline によって snapshot isolation が保証される。\n最初にデータが追加されたときは parquet 等の列指向のフォーマットで保存される。\nその一方でその後のデータの追加・更新については Avro 等の行指向のフォーマットの delta log に記載される。\nここがミソであり、列指向のフォーマットでは1レコードずつなどの細かい追加・更新が高コストになるのでその部分を行指向の delta log にまかせている。\n追加・更新が増えてくると delta log がどんどん長くなってしまうので、あるタイミングで compaction を行って直近までの delta log の変更内容を反映した列指向ファイルを作成する。\nこれを読む方法は2通りある。\nSnapshot Queries では読み取り時に列指向ファイルと行指向の delta log をどちらも読んで merge して最新の結果を返す。\n(これが “Merge On Read” ということ)\n一方で Read Optimized Queries では直近で compaction が行われた時点での列指向ファイルだけを読み、その時点の結果を返す。\nつまりデータの新鮮さが重要な場合は Snapshot Queries, データの新鮮さよりもクエリの速度を優先したい場合は Read Optimized Queries が有利ということだ。\nこれらはトレードオフとなるので状況に応じて使いわけることになる。\n2通りと述べたが実際はもう1つ、 Incremental Queries というものもある。\nこれはある時点からの差分のみを読み出して処理するというものとなっている。\nevent time と processing time の差があるものを DFS 上に書き出すのに適している。\nちなみに Merge On Read ではないもう1つの table type である Copy On Write は、Merge On Read の構造から delta log を消したものとなっている。\nすなわち書き込み時に常に列指向ファイルの更新がおこり、新しく作り直される。(という意味で “Copy On Write”)\n書き込みのたびに常に compaction が発生していると言ってもよい。\n更新頻度が低いデータならこちらの table type を使うのが適しているだろう。\nHudi の table は Spark, Hive, Presto 等からクエリすることができる。\n公式ドキュメント的には Spark 推しの感がある。\nApache Kudu https://kudu.apache.org/\nApache Kudu is an open source distributed data storage engine that makes fast analytics on fast and changing data easy.\nApache Kudu はストリーム処理などの追加・更新の速いデータをすぐに分析できるようにすることを目的としている。\nCloudera 社の内部プロジェクトとして始まり、2016年から Apache Software Foundation の top-level project となった。\nKudu の目指すところは Hudi とよく似ているが、次の点で異なっている。\nKudu は OLTP つまり小さなデータアクセスを大量にさばくのにも向いている Kudu は Hudi の incremental queries のようなことはできない Kudu は HDFS や S3 のような cloud storage 上にデータを持つのでははく、Raft の合意で制御された独自のサーバー群を要する Kudu では各 table のデータが tablet という単位により構成される。\ntablet はいわゆる partition によく似た概念となっており、key の範囲による分割、ハッシュ値による分割、またはその組み合わせにより分割される。\n1つの tablet は複数の tablet server に replication されており、そのうちの1つが leader として振る舞い書き込みを受け付ける。\nleader と follower の関係は Raft 合意アルゴリズム により管理される。\n一方で master server では tablet のメタデータ等が管理されており、client はまず master と通信することになる。\nApache Kudu Architectural Overview\n読み書きに関する内部的な振る舞いについては Cloudera 社のブログ記事 (日本語訳) が参考になる。\nCLOUDERA Blog Apache Kudu Read \u0026 Write Paths\nclient 側からはおそらく見えないが、内部的には\nメモリ上の MemRowSet, DeltaMemStore 列指向の base data file 差分を表す delta file (UNDO/REDO records) の3段の構成になっている。 (それと WAL も)\ndelta file を使うのは Hudi 等と同じだが一度メモリ上で変更を受けるという段があるのが特徴的だ。\n挿入はある tablet のメモリ上の MemRowSet にまず追加される。\nまた任意の timestamp の snapshot を得るために、MemRowSet 上のデータへの更新・削除はの差分は REDO records へと保存される。\nMemRowSet がいっぱいになると最新の状態が列指向の base data file へ書き出され、更新・削除前の状態は UNDO records へと書き出される。\n読み取りのときは MemRowSet とディスク上の base data file + delta file をスキャンすることになる。\nしたがって delta file の数やサイズが大きくなると遅くなる。\nやはりここでも compaction が必要となってくる。\nこのように memory を使うため server が必要であり、データレイクでよく言われるコンピューティングとストレージの分離が完全にはできない。\nCloudera 的と言えるかもしれない。\n読み取りには2つのモードがある。\nデフォルトは READ_LATEST であり、名前のとおり snapshot をとってすぐにデータを読むとのこと。\nREAD_LATEST は比較的弱い read committed の isolation level を示す。\nこれはおそらく Raft や WAL を経て変更が可視になるまでに時間を要するためだ。\nread committed は実用では問題が起こることもある。(ex. Spark クエリの分離レベル)\nもう一つは READ_AT_SNAPSHOT であり、明示的 (推奨) または暗黙的に読み取る対象の timestamp を指定する。\n書き込みの operation が完了し、その timestamp までの変更が安全に読めるようになるまで待って結果を返すことになる。\nisolation level はおそらく最も強い serializable となっている。\nしたがって2つのモードはデータの新鮮さと isolation level (consistency も？) のトレードオフとなっている。\nまとめ Delta Lake, Apache Hudi, Apache Kudu の3つを見比べて見てとても面白いのは、課題感は少しずつ違っているのにどれも列指向ファイル + 差分ファイル (delta file) というアーキテクチャを中心に置いているということだ。\nDelta Lake では transaction を重視している一方で Hudi ではリアルタイムデータをすぐに分析することを目指し、かつ Kudu ではさらに OLTP もサポートする。\nおそらく導入は Delta Lake が最も簡単であり、Kudu に至っては server を用意する必要があるのでハードルが1段高い。\n同じアーキテクチャということもあり、例えば time travel の機能などは共通して提供されている。\nバランス的には Apache Hudi がよさそうだが、どれを使うべきかは work load 次第だろう。\nhourly のデータ更新に慣れすぎていて fast data - fast analysis の需要に気づけないといこともよくありそう。\n","wordCount":"652","inLanguage":"ja","image":"https://soonraah.github.io/image/photo/claudia-chiavazza-N9vsB6OEeKM-unsplash.jpg","datePublished":"2021-01-26T08:00:00+09:00","dateModified":"2021-01-26T08:00:00+09:00","author":{"@type":"Person","name":"soonraah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soonraah.github.io/posts/oss-for-data-lake/"},"publisher":{"@type":"Organization","name":"Froglog","logo":{"@type":"ImageObject","url":"https://soonraah.github.io/favicon2.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soonraah.github.io/>ホーム</a>&nbsp;»&nbsp;<a href=https://soonraah.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu</h1><div class=post-meta><span title='2021-01-26 08:00:00 +0900 JST'>1月 26, 2021</span>&nbsp;·&nbsp;soonraah</div></header><figure class=entry-cover><img loading=eager src=https://soonraah.github.io/image/photo/claudia-chiavazza-N9vsB6OEeKM-unsplash.jpg alt=Lake><p><a href=https://unsplash.com/photos/N9vsB6OEeKM>Photo by Claudia Chiavazza on Unsplash</a></p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目次</span></summary><div class=inner><ul><li><a href=#%e3%81%af%e3%81%98%e3%82%81%e3%81%ab aria-label=はじめに>はじめに</a></li><li><a href=#delta-lake aria-label="Delta Lake">Delta Lake</a></li><li><a href=#apache-hudi aria-label="Apache Hudi">Apache Hudi</a></li><li><a href=#apache-kudu aria-label="Apache Kudu">Apache Kudu</a></li><li><a href=#%e3%81%be%e3%81%a8%e3%82%81 aria-label=まとめ>まとめ</a></li></ul></div></details></div><div class=post-content><h2 id=はじめに>はじめに<a hidden class=anchor aria-hidden=true href=#はじめに>#</a></h2><p><a href=https://soonraah.github.io/posts/what-is-a-data-lake/>前回のポスト</a>ではデータレイクとはどういうものかというのを調べた。<br>今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。</p><p>以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。</p><div style=text-align:center><iframe src="//www.slideshare.net/slideshow/embed_code/key/5sVeEqby7oL0AE?startSlide=37" width=510 height=420 frameborder=0 marginwidth=0 marginheight=0 scrolling=no style="border:1px solid #ccc;border-width:1px;margin-bottom:5px;max-width:100%" allowfullscreen></iframe><div style=margin-bottom:5px><strong><a href=//www.slideshare.net/nttdata-tech/bigdata-storage-layer-software-nttdata title="大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05）" target=_blank>大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05）</a> </strong>from <strong><a href=//www.slideshare.net/nttdata-tech target=_blank>NTT DATA Technology & Innovation</a></strong></div></div><br><ul><li>Delta Lake</li><li>Apache Hudi</li><li>Apache Kudu</li></ul><p>これらはすべて論理的なストレージレイヤーを担う。<br>こちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。</p><p>当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。</p><h2 id=delta-lake>Delta Lake<a hidden class=anchor aria-hidden=true href=#delta-lake>#</a></h2><p><a href=https://delta.io/>https://delta.io/</a></p><blockquote><p>Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.</p></blockquote><figure><img loading=lazy src=/image/deltalake/Delta-Lake-marketecture-0423c.png><figcaption><p><a href=https://delta.io/>Delta Lake</a></p></figcaption></figure><p>Delta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。<br>Databricks が作り、2019年4月に v0.1.0 がリリースされたのが最初だ。<br>使い方はめちゃ簡単で、dependency を設定した上で Spark で</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-scala data-lang=scala><span style=display:flex><span>dataframe
</span></span><span style=display:flex><span>   <span style=color:#f92672>.</span>write
</span></span><span style=display:flex><span>   <span style=color:#f92672>.</span>format<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;delta&#34;</span><span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>   <span style=color:#f92672>.</span>save<span style=color:#f92672>(</span><span style=color:#e6db74>&#34;/data&#34;</span><span style=color:#f92672>)</span>
</span></span></code></pre></div><p>のように読み書きすればよい。</p><p>データレイク化が進むと多種多様なデータが一元的に管理され、それらデータに対して横断的なクエリを実行できるようになる。<br>各データの更新タイミングも様々であり、そのような状況では ACID 特性の中でも特に Isolation (独立性) が問題となってくる。<br>Spark を処理エンジンとして使う場合、データソース・読み方によっては isolation level が弱くなってしまうことがあるというのは<a href=https://soonraah.github.io/posts/weak_isolation_level_of_dataframe/>過去のポスト</a>でも述べた。</p><p>おそらくこのことが Delta Lake の開発の強い動機となっているのではないだろうか。<br>Delta Lake は最も強い isolation level である &ldquo;serializability&rdquo; を提供する。<br>ACID transaction の他には schema に合わないデータを弾いたり過去のデータのスナップショットにアクセスしたりなどの機能がある。<br>どれもデータレイクの治安を守る方向であり、データスワンプ化に抵抗したいようだ。</p><p>これらを実現しているのが transaction log という仕組みとのこと。<br>Delta Lake は table に対する変更の transaction を atomic な commit という単位に分け、commit ごとに操作を JSON file に書き出していく。<br>JSON file には 000000.json, 000001.json のように連番が振られており、2つの application が同時に table を更新するような場合は各 application が次の番号の JSON file を作れるかどうかで衝突を制御している。<br>JSON file はずっと蓄積していくため再計算のコストが大きくなっていくが、その時点での table の完全な状態を parquet にした checkpoint file というものを時折出力するという、compaction のようなことも行われる。<br>(Delta Lake は parquet 形式のデータ保存を前提としている)</p><p>詳しくは Databricks の blog を参照。</p><ul><li><a href=https://databricks.com/blog/2019/08/21/diving-into-delta-lake-unpacking-the-transaction-log.html>Diving Into Delta Lake: Unpacking The Transaction Log</a></li></ul><h2 id=apache-hudi>Apache Hudi<a hidden class=anchor aria-hidden=true href=#apache-hudi>#</a></h2><p><a href=https://hudi.apache.org/>https://hudi.apache.org/</a></p><blockquote><p>Hudi brings stream processing to big data, providing fresh data while being an order of magnitude efficient over traditional batch processing.</p></blockquote><figure><img loading=lazy src=/image/hudi/hudi-lake.png><figcaption><p><a href=https://hudi.apache.org/>Apache Hudi</a></p></figcaption></figure><p>Apache Hudi で何ができるかを一言で説明するのは難しい。<br>簡単にまとめると HDFS や S3 等にある table にリアルタイムに近いデータ取り込みと、処理速度とデータの新鮮さのトレードオフに配慮した読み込みを提供する。<br>2016年から Uber が開発をしており、2020年に Apache Software Fundation の top-level project となった。</p><p>データレイクではあらゆる種類のデータを一元管理するが、その中には当然リアルタイム性の高いデータも含むことになる。<br>データレイク中のリアルタイム性の高いデータについては次のような要求が出てくる。</p><ul><li>table へのデータの取り込みはリアルタイムに近いスピードで細かくやりたい</li><li>分析クエリ等の table の読み込みにおけるクエリの速度は速くしたい (例えば列指向形式で保存されたデータの様に)</li><li>取り込まれたデータをすぐに読めるようにしたい</li></ul><p>Hudi はこれに応えるものとなっている。</p><p>これらを実現するのが Merge On Read のデータ構造だ。<br>Hudi の table には Copy On Write と Merge On Read の2種類がある。<br>ここでは Hudi の肝である後者について触れておきたい。</p><figure><img loading=lazy src=/image/hudi/hudi_mor.png alt="Apache Hudi"><figcaption><p>Apache Hudi
<a href=https://hudi.apache.org/docs/concepts.html#merge-on-read-table>Merge On Read TablePermalink</a></p></figcaption></figure><p>table に加えられた変更についての情報は timeline に追加される。<br>時系列になった変更についてのメタデータのようなものだろうか。<br>この timeline によって snapshot isolation が保証される。</p><p>最初にデータが追加されたときは parquet 等の列指向のフォーマットで保存される。<br>その一方でその後のデータの追加・更新については Avro 等の行指向のフォーマットの delta log に記載される。<br>ここがミソであり、列指向のフォーマットでは1レコードずつなどの細かい追加・更新が高コストになるのでその部分を行指向の delta log にまかせている。<br>追加・更新が増えてくると delta log がどんどん長くなってしまうので、あるタイミングで compaction を行って直近までの delta log の変更内容を反映した列指向ファイルを作成する。</p><p>これを読む方法は2通りある。<br>Snapshot Queries では読み取り時に列指向ファイルと行指向の delta log をどちらも読んで merge して最新の結果を返す。<br>(これが &ldquo;Merge On Read&rdquo; ということ)<br>一方で Read Optimized Queries では直近で compaction が行われた時点での列指向ファイルだけを読み、その時点の結果を返す。<br>つまりデータの新鮮さが重要な場合は Snapshot Queries, データの新鮮さよりもクエリの速度を優先したい場合は Read Optimized Queries が有利ということだ。<br>これらはトレードオフとなるので状況に応じて使いわけることになる。</p><p>2通りと述べたが実際はもう1つ、 Incremental Queries というものもある。<br>これはある時点からの差分のみを読み出して処理するというものとなっている。<br><a href=https://soonraah.github.io/posts/study-streaming-system/#%E6%99%82%E9%96%93%E3%81%AE%E6%A6%82%E5%BF%B5>event time と processing time</a> の差があるものを DFS 上に書き出すのに適している。</p><p>ちなみに Merge On Read ではないもう1つの table type である Copy On Write は、Merge On Read の構造から delta log を消したものとなっている。<br>すなわち書き込み時に常に列指向ファイルの更新がおこり、新しく作り直される。(という意味で &ldquo;Copy On Write&rdquo;)<br>書き込みのたびに常に compaction が発生していると言ってもよい。<br>更新頻度が低いデータならこちらの table type を使うのが適しているだろう。</p><p>Hudi の table は Spark, Hive, Presto 等からクエリすることができる。<br>公式ドキュメント的には Spark 推しの感がある。</p><h2 id=apache-kudu>Apache Kudu<a hidden class=anchor aria-hidden=true href=#apache-kudu>#</a></h2><p><a href=https://kudu.apache.org/>https://kudu.apache.org/</a></p><blockquote><p>Apache Kudu is an open source distributed data storage engine that makes fast analytics on fast and changing data easy.</p></blockquote><p>Apache Kudu はストリーム処理などの追加・更新の速いデータをすぐに分析できるようにすることを目的としている。<br>Cloudera 社の内部プロジェクトとして始まり、2016年から Apache Software Foundation の top-level project となった。</p><p>Kudu の目指すところは Hudi とよく似ているが、次の点で異なっている。</p><ul><li>Kudu は OLTP つまり小さなデータアクセスを大量にさばくのにも向いている</li><li>Kudu は Hudi の incremental queries のようなことはできない</li><li>Kudu は HDFS や S3 のような cloud storage 上にデータを持つのでははく、Raft の合意で制御された独自のサーバー群を要する</li></ul><p>Kudu では各 table のデータが tablet という単位により構成される。<br>tablet はいわゆる partition によく似た概念となっており、key の範囲による分割、ハッシュ値による分割、またはその組み合わせにより分割される。<br>1つの tablet は複数の tablet server に replication されており、そのうちの1つが leader として振る舞い書き込みを受け付ける。<br>leader と follower の関係は <a href=https://raft.github.io/>Raft 合意アルゴリズム</a> により管理される。<br>一方で master server では tablet のメタデータ等が管理されており、client はまず master と通信することになる。</p><figure><img loading=lazy src=/image/kudu/kudu-architecture-2.png alt="Apache Kudu"><figcaption><p>Apache Kudu
<a href=https://kudu.apache.org/docs/#_architectural_overview>Architectural Overview</a></p></figcaption></figure><p>読み書きに関する内部的な振る舞いについては <a href=https://blog.cloudera.com/apache-kudu-read-write-paths/>Cloudera 社のブログ記事</a> (<a href=https://blog.cloudera.co.jp/apache-kudu-read-write-paths-11c3a749a81b>日本語訳</a>) が参考になる。</p><figure><img loading=lazy src=/image/kudu/Kudu-Snapshots.png alt="CLOUDERA Blog"><figcaption><p>CLOUDERA Blog
<a href=https://blog.cloudera.com/apache-kudu-read-write-paths/>Apache Kudu Read & Write Paths</a></p></figcaption></figure><p>client 側からはおそらく見えないが、内部的には</p><ul><li>メモリ上の MemRowSet, DeltaMemStore</li><li>列指向の base data file</li><li>差分を表す delta file (UNDO/REDO records)</li></ul><p>の3段の構成になっている。 (それと WAL も)<br>delta file を使うのは Hudi 等と同じだが一度メモリ上で変更を受けるという段があるのが特徴的だ。</p><p>挿入はある tablet のメモリ上の MemRowSet にまず追加される。<br>また任意の timestamp の snapshot を得るために、MemRowSet 上のデータへの更新・削除はの差分は REDO records へと保存される。<br>MemRowSet がいっぱいになると最新の状態が列指向の base data file へ書き出され、更新・削除前の状態は UNDO records へと書き出される。</p><p>読み取りのときは MemRowSet とディスク上の base data file + delta file をスキャンすることになる。<br>したがって delta file の数やサイズが大きくなると遅くなる。<br>やはりここでも compaction が必要となってくる。</p><p>このように memory を使うため server が必要であり、データレイクでよく言われるコンピューティングとストレージの分離が完全にはできない。<br>Cloudera 的と言えるかもしれない。</p><p>読み取りには2つのモードがある。<br>デフォルトは <code>READ_LATEST</code> であり、名前のとおり snapshot をとってすぐにデータを読むとのこと。<br><code>READ_LATEST</code> は比較的弱い read committed の isolation level を示す。<br>これはおそらく Raft や WAL を経て変更が可視になるまでに時間を要するためだ。<br>read committed は実用では問題が起こることもある。(ex. <a href=https://soonraah.github.io/posts/weak_isolation_level_of_dataframe/#spark-%e3%82%af%e3%82%a8%e3%83%aa%e3%81%ae%e5%88%86%e9%9b%a2%e3%83%ac%e3%83%99%e3%83%ab>Spark クエリの分離レベル</a>)</p><p>もう一つは <code>READ_AT_SNAPSHOT</code> であり、明示的 (推奨) または暗黙的に読み取る対象の timestamp を指定する。<br>書き込みの operation が完了し、その timestamp までの変更が安全に読めるようになるまで待って結果を返すことになる。<br>isolation level はおそらく最も強い serializable となっている。<br>したがって2つのモードはデータの新鮮さと isolation level (consistency も？) のトレードオフとなっている。</p><h2 id=まとめ>まとめ<a hidden class=anchor aria-hidden=true href=#まとめ>#</a></h2><p>Delta Lake, Apache Hudi, Apache Kudu の3つを見比べて見てとても面白いのは、課題感は少しずつ違っているのにどれも列指向ファイル + 差分ファイル (delta file) というアーキテクチャを中心に置いているということだ。<br>Delta Lake では transaction を重視している一方で Hudi ではリアルタイムデータをすぐに分析することを目指し、かつ Kudu ではさらに OLTP もサポートする。<br>おそらく導入は Delta Lake が最も簡単であり、Kudu に至っては server を用意する必要があるのでハードルが1段高い。<br>同じアーキテクチャということもあり、例えば time travel の機能などは共通して提供されている。</p><p>バランス的には Apache Hudi がよさそうだが、どれを使うべきかは work load 次第だろう。<br>hourly のデータ更新に慣れすぎていて fast data - fast analysis の需要に気づけないといこともよくありそう。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://soonraah.github.io/tags/data-lake/>Data Lake</a></li><li><a href=https://soonraah.github.io/tags/delta-lake/>Delta Lake</a></li><li><a href=https://soonraah.github.io/tags/apache-hudi/>Apache Hudi</a></li><li><a href=https://soonraah.github.io/tags/apache-kudu/>Apache Kudu</a></li></ul><nav class=paginav><a class=prev href=https://soonraah.github.io/posts/backpressure-for-flink/><span class=title>« 前へ</span><br><span>Apache Flink の Backpressure の仕組みについて調べた</span>
</a><a class=next href=https://soonraah.github.io/posts/what-is-a-data-lake/><span class=title>次へ »</span><br><span>いまさらながらのデータレイク</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu on x" href="https://x.com/intent/tweet/?text=%e3%83%87%e3%83%bc%e3%82%bf%e3%83%ac%e3%82%a4%e3%82%af%e9%96%a2%e9%80%a3%e3%81%ae%20OSS%20-%20Delta%20Lake%2c%20Apache%20Hudi%2c%20Apache%20Kudu&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2foss-for-data-lake%2f&amp;hashtags=DataLake%2cDeltaLake%2cApacheHudi%2cApacheKudu"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2foss-for-data-lake%2f&amp;title=%e3%83%87%e3%83%bc%e3%82%bf%e3%83%ac%e3%82%a4%e3%82%af%e9%96%a2%e9%80%a3%e3%81%ae%20OSS%20-%20Delta%20Lake%2c%20Apache%20Hudi%2c%20Apache%20Kudu&amp;summary=%e3%83%87%e3%83%bc%e3%82%bf%e3%83%ac%e3%82%a4%e3%82%af%e9%96%a2%e9%80%a3%e3%81%ae%20OSS%20-%20Delta%20Lake%2c%20Apache%20Hudi%2c%20Apache%20Kudu&amp;source=https%3a%2f%2fsoonraah.github.io%2fposts%2foss-for-data-lake%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoonraah.github.io%2fposts%2foss-for-data-lake%2f&title=%e3%83%87%e3%83%bc%e3%82%bf%e3%83%ac%e3%82%a4%e3%82%af%e9%96%a2%e9%80%a3%e3%81%ae%20OSS%20-%20Delta%20Lake%2c%20Apache%20Hudi%2c%20Apache%20Kudu"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoonraah.github.io%2fposts%2foss-for-data-lake%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu on whatsapp" href="https://api.whatsapp.com/send?text=%e3%83%87%e3%83%bc%e3%82%bf%e3%83%ac%e3%82%a4%e3%82%af%e9%96%a2%e9%80%a3%e3%81%ae%20OSS%20-%20Delta%20Lake%2c%20Apache%20Hudi%2c%20Apache%20Kudu%20-%20https%3a%2f%2fsoonraah.github.io%2fposts%2foss-for-data-lake%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu on telegram" href="https://telegram.me/share/url?text=%e3%83%87%e3%83%bc%e3%82%bf%e3%83%ac%e3%82%a4%e3%82%af%e9%96%a2%e9%80%a3%e3%81%ae%20OSS%20-%20Delta%20Lake%2c%20Apache%20Hudi%2c%20Apache%20Kudu&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2foss-for-data-lake%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu on ycombinator" href="https://news.ycombinator.com/submitlink?t=%e3%83%87%e3%83%bc%e3%82%bf%e3%83%ac%e3%82%a4%e3%82%af%e9%96%a2%e9%80%a3%e3%81%ae%20OSS%20-%20Delta%20Lake%2c%20Apache%20Hudi%2c%20Apache%20Kudu&u=https%3a%2f%2fsoonraah.github.io%2fposts%2foss-for-data-lake%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://soonraah.github.io/>Froglog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="コピー";function s(){t.innerHTML="コピーされました!",setTimeout(()=>{t.innerHTML="コピー"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>