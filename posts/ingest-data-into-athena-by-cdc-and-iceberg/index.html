<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>CDC + Apache Iceberg で Amazon Athena にデータを取り込む | Froglog</title>
<meta name=keywords content="Apache Iceberg,CDC,AWS,Amazon Athena,AWS DMS"><meta name=description content="このポストについて このポストは Distributed computing Advent Calendar 2023 の3日目の記事になります。
1日目、2日目に続いて Apache Iceberg について書きますが、このポストでは Iceberg の実用例を書きます。
AWS DMS による CDC の結果を Apache Iceberg 形式にして Amazon Athena でクエリできるようにするという内容になります。
やっていることとしては Perform upserts in a data lake using Amazon Athena and Apache Iceberg | AWS Big Data Blog で紹介されている内容と近いですが、実務としての背景や工夫したところなどを書いていきます。
背景 私の所属する事業会社では日々プロダクトから様々なデータが発生しており、プロダクトの分析やレポーティング、ML など様々な用途で利用されている。
それを支える基盤としてデータ基盤が存在している。
データ基盤ではクエリエンジンとして Amazon Athena を使っている。
ストレージとしては S3 を使用しており、主に分析用として Parquet 形式でデータが置かれる。
ここに業務用の operational な database から日次でデータを取り込んでいる。
データソースは RDS (Aurora MySQL) であり、比較的大きなデータとなっている。
これまではこの RDS -> S3 のデータ取り込みには RDS の S3 snapshot export という機能を利用していた。"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/ingest-data-into-athena-by-cdc-and-iceberg/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://soonraah.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-73329599-2","auto"),ga("send","pageview"))</script><meta property="og:title" content="CDC + Apache Iceberg で Amazon Athena にデータを取り込む"><meta property="og:description" content="このポストについて このポストは Distributed computing Advent Calendar 2023 の3日目の記事になります。
1日目、2日目に続いて Apache Iceberg について書きますが、このポストでは Iceberg の実用例を書きます。
AWS DMS による CDC の結果を Apache Iceberg 形式にして Amazon Athena でクエリできるようにするという内容になります。
やっていることとしては Perform upserts in a data lake using Amazon Athena and Apache Iceberg | AWS Big Data Blog で紹介されている内容と近いですが、実務としての背景や工夫したところなどを書いていきます。
背景 私の所属する事業会社では日々プロダクトから様々なデータが発生しており、プロダクトの分析やレポーティング、ML など様々な用途で利用されている。
それを支える基盤としてデータ基盤が存在している。
データ基盤ではクエリエンジンとして Amazon Athena を使っている。
ストレージとしては S3 を使用しており、主に分析用として Parquet 形式でデータが置かれる。
ここに業務用の operational な database から日次でデータを取り込んでいる。
データソースは RDS (Aurora MySQL) であり、比較的大きなデータとなっている。
これまではこの RDS -> S3 のデータ取り込みには RDS の S3 snapshot export という機能を利用していた。"><meta property="og:type" content="article"><meta property="og:url" content="https://soonraah.github.io/posts/ingest-data-into-athena-by-cdc-and-iceberg/"><meta property="og:image" content="https://soonraah.github.io/image/photo/christian-pfeifer-l6OraG-v0d8-unsplash.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-12-03T22:00:00+09:00"><meta property="article:modified_time" content="2023-12-03T22:00:00+09:00"><meta property="og:site_name" content="Froglog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/photo/christian-pfeifer-l6OraG-v0d8-unsplash.jpg"><meta name=twitter:title content="CDC + Apache Iceberg で Amazon Athena にデータを取り込む"><meta name=twitter:description content="このポストについて このポストは Distributed computing Advent Calendar 2023 の3日目の記事になります。
1日目、2日目に続いて Apache Iceberg について書きますが、このポストでは Iceberg の実用例を書きます。
AWS DMS による CDC の結果を Apache Iceberg 形式にして Amazon Athena でクエリできるようにするという内容になります。
やっていることとしては Perform upserts in a data lake using Amazon Athena and Apache Iceberg | AWS Big Data Blog で紹介されている内容と近いですが、実務としての背景や工夫したところなどを書いていきます。
背景 私の所属する事業会社では日々プロダクトから様々なデータが発生しており、プロダクトの分析やレポーティング、ML など様々な用途で利用されている。
それを支える基盤としてデータ基盤が存在している。
データ基盤ではクエリエンジンとして Amazon Athena を使っている。
ストレージとしては S3 を使用しており、主に分析用として Parquet 形式でデータが置かれる。
ここに業務用の operational な database から日次でデータを取り込んでいる。
データソースは RDS (Aurora MySQL) であり、比較的大きなデータとなっている。
これまではこの RDS -> S3 のデータ取り込みには RDS の S3 snapshot export という機能を利用していた。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://soonraah.github.io/posts/"},{"@type":"ListItem","position":3,"name":"CDC + Apache Iceberg で Amazon Athena にデータを取り込む","item":"https://soonraah.github.io/posts/ingest-data-into-athena-by-cdc-and-iceberg/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"CDC + Apache Iceberg で Amazon Athena にデータを取り込む","name":"CDC \u002b Apache Iceberg で Amazon Athena にデータを取り込む","description":"このポストについて このポストは Distributed computing Advent Calendar 2023 の3日目の記事になります。\n1日目、2日目に続いて Apache Iceberg について書きますが、このポストでは Iceberg の実用例を書きます。\nAWS DMS による CDC の結果を Apache Iceberg 形式にして Amazon Athena でクエリできるようにするという内容になります。\nやっていることとしては Perform upserts in a data lake using Amazon Athena and Apache Iceberg | AWS Big Data Blog で紹介されている内容と近いですが、実務としての背景や工夫したところなどを書いていきます。\n背景 私の所属する事業会社では日々プロダクトから様々なデータが発生しており、プロダクトの分析やレポーティング、ML など様々な用途で利用されている。\nそれを支える基盤としてデータ基盤が存在している。\nデータ基盤ではクエリエンジンとして Amazon Athena を使っている。\nストレージとしては S3 を使用しており、主に分析用として Parquet 形式でデータが置かれる。\nここに業務用の operational な database から日次でデータを取り込んでいる。\nデータソースは RDS (Aurora MySQL) であり、比較的大きなデータとなっている。\nこれまではこの RDS -\u0026gt; S3 のデータ取り込みには RDS の S3 snapshot export という機能を利用していた。","keywords":["Apache Iceberg","CDC","AWS","Amazon Athena","AWS DMS"],"articleBody":"このポストについて このポストは Distributed computing Advent Calendar 2023 の3日目の記事になります。\n1日目、2日目に続いて Apache Iceberg について書きますが、このポストでは Iceberg の実用例を書きます。\nAWS DMS による CDC の結果を Apache Iceberg 形式にして Amazon Athena でクエリできるようにするという内容になります。\nやっていることとしては Perform upserts in a data lake using Amazon Athena and Apache Iceberg | AWS Big Data Blog で紹介されている内容と近いですが、実務としての背景や工夫したところなどを書いていきます。\n背景 私の所属する事業会社では日々プロダクトから様々なデータが発生しており、プロダクトの分析やレポーティング、ML など様々な用途で利用されている。\nそれを支える基盤としてデータ基盤が存在している。\nデータ基盤ではクエリエンジンとして Amazon Athena を使っている。\nストレージとしては S3 を使用しており、主に分析用として Parquet 形式でデータが置かれる。\nここに業務用の operational な database から日次でデータを取り込んでいる。\nデータソースは RDS (Aurora MySQL) であり、比較的大きなデータとなっている。\nこれまではこの RDS -\u003e S3 のデータ取り込みには RDS の S3 snapshot export という機能を利用していた。\nこの機能では比較的簡単な設定により、バックアップ用のスナップショットの内容を S3 に export することができる。\nちなみに対象 database のスナップショットのサイズは数十 TB ある。\n課題 RDS の S3 snapshot export には次のような課題があった。\n料金が高い 💸 料金はデータ送信の量で決まるとのこと 具体的な額は伏せるが、思った以上にかかっていた export に時間がかかる 🕓 数時間程度 まれに通常より遅延することがあり、1日以上かかることもあった export の頻度を高くできない 🐌 コストも時間もかかるので1日より短くするのは無理 データソース側で更新されたレコードをデータ基盤上で分析に利用できるまで、最大で1日+数時間のラグがある もっと早く分析できるようにしたいという要望もあった 対象 database の特にデータ量の多い table についてレコードの更新タイミングを確認したところ、日によって波はあるが1日の中で更新されているレコードはおおよそ1~4割だった。\nスナップショットをまるまる export する場合は更新されていないデータも対象となるため、本来は不要であるはずのデータ移動が発生してしまっている。\nソリューション概要 スナップショット全体のコピーには無駄が多い。\nCDC (Change Data Capture) で差分のみ送るようにすればよりデータの移動が少なくなり、上記の問題が解決できると考えた。\nCDC とは RDB のデータを外部にレプリケーションする方法の一つで、レコードの追加・更新・削除などのイベントをログとして送信するというやり方。\nこのようなイベントログがあれば送信先にて table の状態を復元することができる。\nLog-Based Change Data Capture, Change Data Capture (CDC): What it is and How it Works - Striim\nCDC については以下も参照。\nLog-Based Change Data Capture in Change Data Capture (CDC): What it is and How it Works - Striim Track Data Changes - SQL Server | Microsoft Learn CDC を実現する方法はいくつかある。\nmodern data stack 的には Debezium が最も有名だろう。\n今回は元々クラウドサービスとして AWS を利用していたため、比較的導入が容易な AWS DMS (Database Migration Service) を使うことにした。\nsource として RDS、target として S3 を指定して DMS の replication task を動かすことになる。\nちなみに CDC を始める前に現在の table 全体をコピーする full load という処理を実行する必要があるが、このポストでは割愛。\nDMS の CDC で S3 へと送信されたイベントログはそのままでは分析に使えない。\n元の table と同じ形に組み上げる必要がある。\nここでは Apache Iceberg という table 形式を使ってそれを行うことにした。\nIceberg については当アドベントカレンダーの他のポストや本ブログの Iceberg についてのポストも参考にしてほしい。\nIceberg を採用した理由は以下のとおり。\nAthena でサポートされている table 形式である SQL の merge into 文 (後述) により比較的容易にイベントログを元の table の形に復元できる MOR (Merge on Read、後述) により、コストの低い table 更新を実現できる Athena および Glue (後述) で使いたいので Iceberg catalog としては Glue Data Catalog を使うことになる。\n他に Athena で使えて似たことができる table 形式としては Apache Hudi がある。\nしかし以前技術検証したときに Athena のエンジンが Hudi の MOR に対応していなかったため、採用しなかった。\n(今はできるかもしれない、未確認)\nアーキテクチャは以下のようになる。\nsolution architecture\nソリューション詳細 主に Iceberg まわりについて詳しく見ていく。\nmerge into 文による Iceberg table の更新 アーキテクチャ図の 2. にあたる処理。\nDMS の CDC では near real time で S3 にイベントログが出力される。\nただ、今回はデータ基盤については near real time の更新の要件はなかったため、1時間ごとの更新を試みることにした。\nソースである RDS 上の table が 2023-11-11 09:59:59.999999 の時点で次のような状態 (A) だったとする。\nid name phone_number 1 Alice 123-456 2 Bob 456-789 これが1時間後には次のようになっていたとする。(B)\nid name phone_number 1 Alice 123-000 3 Charlie 456-789 このとき、DMS による1時間分の CDC 結果の出力は例えば次のようになっている。(C)\nOp timestamp id name phone_number I 2023-11-11 10:05:00.000000 3 Charlie 333-333 U 2023-11-11 10:10:00.000000 1 Alice 123-000 D 2023-11-11 10:15:00.000000 2 Bob 456-789 column Op は DMS によって付与される column であり、イベントの種別を表す。\nI: 挿入 (Insert) U: 更新 (Update) D: 削除 (Delete) column timestamp も DMS によって付与された column であり、ソース側でその変更が commit された時刻を表す。 (column 名は設定で指定可能)\nソースの table が (A) の状態から (C) に記載されているような変更を経て (B) の状態になった、ということである。\n前回までの変更を Iceberg table が追従できているのであれば (A) の状態になっているはずであり、ここで (C) の差分を適用して (B) の状態にする必要がある。\nこれを自分で実装するとなると結構めんどうだが、幸いに SQL の merge into 文を使って Iceberg table を更新することができる。\nWrites - Apache Iceberg この例だと例えば次のような SQL で挿入・更新・削除を一度に適用できる。\nmerge into my_catalog.my_database.iceberg_table as iceberg using ( select * from cdc_table as cdc -- CDC 結果を1時間分だけ読み込んだ DataFrame ) on -- この column の一致で同一レコードとみなす (複数指定も可) iceberg.id = cdc.id -- 一致する id があり Op=D の場合は削除 when matched and cdc.Op = 'D' then delete -- 一致する id があり Op=I or U の場合は更新 when matched and cdc.Op != 'D' then update set id = cdc.id, name = cdc.name, phone_number = cdc.phone_number -- 一致する id がなく Op=I or U の場合は挿入 when not matched and cdc.Op != 'D' then insert(id, name, phone_number) values(cdc.id, cdc.name, cdc.phone_number) 今回の実装では column 名取得の都合などから Glue Job の Spark SQL でこの SQL を実行するものとした。\nちなみに merge into 文自体は Athena でもサポートしているので、Athena でも実行することができる。\nIceberg table は MOR (Merge on Read) 形式にしており、table 更新時は列指向形式データをすべて書き換えるのではなく差分のみが追加されるようになっている。\nこのため大きな table であっても比較的低コストでの table 更新が可能となる。\n一方で読み取りは COW (Copy on Write) の場合と比べて遅くなるが、基本的には列指向なので分析クエリに対してはそこそこのパフォーマンスとなる。\nMOR, COW については以下を参考。\nRow-Level Changes on the Lakehouse: Copy-On-Write vs. Merge-On-Read in Apache Iceberg | Dremio (Dremio さんの Iceberg 解説記事にはいつもお世話になっています！)\ndaily snapshot の作成 アーキテクチャ図の 4. にあたる処理。\nIceberg table は hourly で更新する一方、Iceberg table から daily でスナップショットとして Parquet 形式に書き出すという処理も追加した。\nIceberg には time travel の機能があり、Iceberg table 自身の中でスナップショットを持つことも可能である。\nしかしわざわざ daily スナップショットを外に書き出しているのは、チームとして Iceberg table の運用経験がなく、長期的に安定運用できるかわからなかったため。\n例えばもし Iceberg table の metadata がぶっ壊れたら…などと考えると、Iceberg の外にデータを別で持っておきたい気持ちがわかっていただけるのではないだろうか。\n元々が daily の更新だったため、最低限 daily のスナップショットが残っていれば少なくとも現在の業務は継続することができる。\n分析者視点だと\n直近1週間 (後述) の鮮度の高いデータの分析 -\u003e hourly 更新の table (Iceberg) 長期間におけるデータの分析 -\u003e daily 更新の table (Parquet) と使い分けてもらうことになる。\n後々 Iceberg table が安定運用できることが分かれば Iceberg 1本にしてもいい。\nIceberg table のメンテナンス 前後してアーキテクチャ図の 3. にあたる処理。\nここでは Iceberg table の compaction と古いスナップショットの削除を行う。\nこれらも daily で実行するものとする。\nMOR の場合、更新が何回も行われ差分の世代が多くなってくるとそれらを merge して table としてのデータを読み取る速度が遅くなってくる。\nこれを解消するためには差分を統合して1つのファイルにまとめる必要があり、これを compaction と言う。\nこの compaction の処理を追加している。\nFine-Tuning Apache Iceberg Tables - Dremio Blog | Dremio Iceberg table は内部にスナップショットという概念があり、table の状態を複数バージョン持っている。\nこれにより time travel query が実行できたり、ACID transction を提供できたりと大きなメリットとなっている。\n前述のとおり daily でデータを Parquet として書き出しているので、Iceberg 内で過去の古いスナップショットを持っているとデータの重複になってしまう。\nよって定期的に Iceberg 内の古いスナップショットを削除する処理を追加している。\nここでは1週間分残すようにし、それより古いスナップショットは削除するようにした。\ncompaction、古い snashot の削除はともに Spark SQL から実行することができる。\nそれぞれ rewrite_data_files(), expire_snapshots() という procedure が対応している。\nMaintenance - Apache Iceberg 運用上の工夫 DMS mirgration task の監視 ソースである RDS 側で手動または自動でフェイルオーバーが実行されたり、エンジンバージョンアップが行われたりすると、CDC を継続的に行っている DMS の replication task が Failed で死んでしまうことがある。\nしたがって replication task の実行状況を監視して通知する仕組みが必須となる。\nreplication task が失敗した場合は速やかに再度実行することになる。\nこのあたりの運用はちょっと面倒なので、再実行の自動化を検討している。\n遅延チェック 上記とも関係しているが、何らかの理由で CDC の結果が S3 に届くのが遅れることも想定される。\n遅れているのに気づかずに「HH 時台の CDC イベントログは全部届いたよね！」とみなして Iceberg table に更新をかけると table が意図しない状態になってしまうかもしれない。\nこれを防ぐために各時間の merge into 文を実行する前に過去 N 時間分の CDC の出力をチェックして、イベントログが遅れて届いていることがないことを確認するようにしている。\n遅れて届いているイベントログがあった場合、procedure rollback_to_snapshot() などで table の状態を rollback することになる。\nちなみにこういった処理の依存関係はおなじみ Airflow (Amazon MWAA) で管理している。\nまた、合わせて DMS の CloudWatch Mterics の CDCLatencySource や CDCLatencyTarget を見ておくとよい。\nそれぞれソースと replication instance, replication instance とターゲット間の遅延を表している。\nschema evolution column 追加など、ソース側の table の schema が変更されることは当然起こりうる。\nRDS の table を管理しているチームには schema を変更するときは前もって教えてもらえる一応伝えてある。\n我々のチームでは通常 Athena というか Glue Data Catalog 上の table の定義は CDK で IaC として管理している。(dbt は未導入)\nただし Iceberg table の schema 変更は metadata として管理される。\n当然 CDK というかその中身の CloudFormation では Iceberg の metadata は扱えない。\nIceberg table の schema については IaC に乗せることはできず、DDL で管理することになっている。\nmerge into 文における単一レコードの複数回操作への配慮 前述の merge into 文のサンプル SQL を見て、例えば同じ id のレコードに対して1時間の中で\n複数回更新が行われた 挿入の後、削除が行われた など複数回の操作があった場合はどうなるんだ？と思った方はごもっとも。\n実際上記のサンプル SQL では複数回の操作を考慮できていない。\nなので cdc のレコードをどの順で読み取るかによる、未定義な挙動になると考えられる。\nではどうすればいいかというと、ある id に対して1時間の中で最後に行われた操作だけを見ればよい。\n最後の操作が削除であればそのレコードは最終的に存在しないし、最後の操作が挿入または更新であれば存在する。\n具体的には using (...) の中の select 文を id ごとに最後の操作だけ見るように書き換えればよい。\nここで「最後」を定義するために column timestamp が必要になってくる。\ntimestamp と window 関数を使ってごにょごにょすると…？\n適用の結果 (まだない) この記事において、適用の結果 AWS コストが◯◯%削減できました！と言えればよかったのだが、まだこの仕組みは運用を始めたばかりであり実績値は出せない。\nプロジェクト着手前の試算では結構がっつり減らせる想定ではあった。\n前述のとおり処理が多段的になり運用の手間も増えているが、ペイできる程度のコスト削減を見込んでいる。\n気が向いたら結果を追記するかもしれない。\nまとめ 実際に Apache Iceberg を使っているプロジェクトの実務としての背景や運用について書いてみた。\nそんなに新しい内容はないが、ノウハウ的なところはあまり見かけない気がするのでまあ許していただきたい。\n今回は Iceberg に注目したので DMS について詳しく書かなかったが、こっちはこっちでいろいろあったりする。\nDistributed computing Advent Calendar 2023、明日は Delta Lake についてのお話のようですね。\nこちらも興味深いです。\n弊チームではこういったお仕事や modern data stack の導入などを一緒にやってくれるデータエンジニアを募集しています。\nご興味のある方は X にて DM ください。\nカジュアル面談しましょう。\n","wordCount":"923","inLanguage":"ja","image":"https://soonraah.github.io/image/photo/christian-pfeifer-l6OraG-v0d8-unsplash.jpg","datePublished":"2023-12-03T22:00:00+09:00","dateModified":"2023-12-03T22:00:00+09:00","author":{"@type":"Person","name":"soonraah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soonraah.github.io/posts/ingest-data-into-athena-by-cdc-and-iceberg/"},"publisher":{"@type":"Organization","name":"Froglog","logo":{"@type":"ImageObject","url":"https://soonraah.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soonraah.github.io>ホーム</a>&nbsp;»&nbsp;<a href=https://soonraah.github.io/posts/>Posts</a></div><h1 class=post-title>CDC + Apache Iceberg で Amazon Athena にデータを取り込む</h1><div class=post-meta><span title='2023-12-03 22:00:00 +0900 JST'>12月 3, 2023</span>&nbsp;·&nbsp;soonraah</div></header><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/christian-pfeifer-l6OraG-v0d8-unsplash.jpg alt=iceberg><p><a href=https://unsplash.com/ja/%E5%86%99%E7%9C%9F/%E6%98%BC%E9%96%93%E3%81%AE%E9%9D%92%E3%81%84%E7%A9%BA%E3%81%AE%E4%B8%8B%E3%81%A7%E9%9D%92%E3%81%84%E6%B5%B7%E3%81%AB%E7%99%BD%E3%81%A8%E7%81%B0%E8%89%B2%E3%81%AE%E5%B2%A9%E3%81%AE%E5%BD%A2%E6%88%90-l6OraG-v0d8>Photo by Christian Pfeifer on Unsplash</a></p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目次</span></summary><div class=inner><ul><li><a href=#%e3%81%93%e3%81%ae%e3%83%9d%e3%82%b9%e3%83%88%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6 aria-label=このポストについて>このポストについて</a></li><li><a href=#%e8%83%8c%e6%99%af aria-label=背景>背景</a></li><li><a href=#%e8%aa%b2%e9%a1%8c aria-label=課題>課題</a></li><li><a href=#%e3%82%bd%e3%83%aa%e3%83%a5%e3%83%bc%e3%82%b7%e3%83%a7%e3%83%b3%e6%a6%82%e8%a6%81 aria-label=ソリューション概要>ソリューション概要</a></li><li><a href=#%e3%82%bd%e3%83%aa%e3%83%a5%e3%83%bc%e3%82%b7%e3%83%a7%e3%83%b3%e8%a9%b3%e7%b4%b0 aria-label=ソリューション詳細>ソリューション詳細</a><ul><li><a href=#merge-into-%e6%96%87%e3%81%ab%e3%82%88%e3%82%8b-iceberg-table-%e3%81%ae%e6%9b%b4%e6%96%b0 aria-label="merge into 文による Iceberg table の更新"><code>merge into</code> 文による Iceberg table の更新</a></li><li><a href=#daily-snapshot-%e3%81%ae%e4%bd%9c%e6%88%90 aria-label="daily snapshot の作成">daily snapshot の作成</a></li><li><a href=#iceberg-table-%e3%81%ae%e3%83%a1%e3%83%b3%e3%83%86%e3%83%8a%e3%83%b3%e3%82%b9 aria-label="Iceberg table のメンテナンス">Iceberg table のメンテナンス</a></li></ul></li><li><a href=#%e9%81%8b%e7%94%a8%e4%b8%8a%e3%81%ae%e5%b7%a5%e5%a4%ab aria-label=運用上の工夫>運用上の工夫</a><ul><li><a href=#dms-mirgration-task-%e3%81%ae%e7%9b%a3%e8%a6%96 aria-label="DMS mirgration task の監視">DMS mirgration task の監視</a></li><li><a href=#%e9%81%85%e5%bb%b6%e3%83%81%e3%82%a7%e3%83%83%e3%82%af aria-label=遅延チェック>遅延チェック</a></li><li><a href=#schema-evolution aria-label="schema evolution">schema evolution</a></li><li><a href=#merge-into-%e6%96%87%e3%81%ab%e3%81%8a%e3%81%91%e3%82%8b%e5%8d%98%e4%b8%80%e3%83%ac%e3%82%b3%e3%83%bc%e3%83%89%e3%81%ae%e8%a4%87%e6%95%b0%e5%9b%9e%e6%93%8d%e4%bd%9c%e3%81%b8%e3%81%ae%e9%85%8d%e6%85%ae aria-label="merge into 文における単一レコードの複数回操作への配慮"><code>merge into</code> 文における単一レコードの複数回操作への配慮</a></li></ul></li><li><a href=#%e9%81%a9%e7%94%a8%e3%81%ae%e7%b5%90%e6%9e%9c-%e3%81%be%e3%81%a0%e3%81%aa%e3%81%84 aria-label="適用の結果 (まだない)">適用の結果 (まだない)</a></li><li><a href=#%e3%81%be%e3%81%a8%e3%82%81 aria-label=まとめ>まとめ</a></li></ul></div></details></div><div class=post-content><h2 id=このポストについて>このポストについて<a hidden class=anchor aria-hidden=true href=#このポストについて>#</a></h2><p>このポストは <a href=https://qiita.com/advent-calendar/2023/distributed-computing>Distributed computing Advent Calendar 2023</a> の3日目の記事になります。<br>1日目、2日目に続いて Apache Iceberg について書きますが、このポストでは Iceberg の実用例を書きます。</p><p>AWS DMS による CDC の結果を Apache Iceberg 形式にして Amazon Athena でクエリできるようにするという内容になります。<br>やっていることとしては <a href=https://aws.amazon.com/jp/blogs/big-data/perform-upserts-in-a-data-lake-using-amazon-athena-and-apache-iceberg/>Perform upserts in a data lake using Amazon Athena and Apache Iceberg | AWS Big Data Blog</a> で紹介されている内容と近いですが、実務としての背景や工夫したところなどを書いていきます。</p><h2 id=背景>背景<a hidden class=anchor aria-hidden=true href=#背景>#</a></h2><p>私の所属する事業会社では日々プロダクトから様々なデータが発生しており、プロダクトの分析やレポーティング、ML など様々な用途で利用されている。<br>それを支える基盤としてデータ基盤が存在している。</p><p>データ基盤ではクエリエンジンとして <a href=https://docs.aws.amazon.com/athena/latest/ug/what-is.html>Amazon Athena</a> を使っている。<br>ストレージとしては S3 を使用しており、主に分析用として Parquet 形式でデータが置かれる。</p><p>ここに業務用の operational な database から日次でデータを取り込んでいる。<br>データソースは RDS (Aurora MySQL) であり、比較的大きなデータとなっている。</p><p>これまではこの RDS -> S3 のデータ取り込みには RDS の <a href=https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ExportSnapshot.html>S3 snapshot export</a> という機能を利用していた。<br>この機能では比較的簡単な設定により、バックアップ用のスナップショットの内容を S3 に export することができる。<br>ちなみに対象 database のスナップショットのサイズは数十 TB ある。</p><h2 id=課題>課題<a hidden class=anchor aria-hidden=true href=#課題>#</a></h2><p>RDS の S3 snapshot export には次のような課題があった。</p><ul><li>料金が高い 💸<ul><li>料金はデータ送信の量で決まるとのこと</li><li>具体的な額は伏せるが、思った以上にかかっていた</li></ul></li><li>export に時間がかかる 🕓<ul><li>数時間程度</li><li>まれに通常より遅延することがあり、1日以上かかることもあった</li></ul></li><li>export の頻度を高くできない 🐌<ul><li>コストも時間もかかるので1日より短くするのは無理</li><li>データソース側で更新されたレコードをデータ基盤上で分析に利用できるまで、最大で1日+数時間のラグがある</li><li>もっと早く分析できるようにしたいという要望もあった</li></ul></li></ul><p>対象 database の特にデータ量の多い table についてレコードの更新タイミングを確認したところ、日によって波はあるが1日の中で更新されているレコードはおおよそ1~4割だった。<br>スナップショットをまるまる export する場合は更新されていないデータも対象となるため、本来は不要であるはずのデータ移動が発生してしまっている。</p><h2 id=ソリューション概要>ソリューション概要<a hidden class=anchor aria-hidden=true href=#ソリューション概要>#</a></h2><p>スナップショット全体のコピーには無駄が多い。<br>CDC (Change Data Capture) で差分のみ送るようにすればよりデータの移動が少なくなり、上記の問題が解決できると考えた。<br>CDC とは RDB のデータを外部にレプリケーションする方法の一つで、レコードの追加・更新・削除などのイベントをログとして送信するというやり方。<br>このようなイベントログがあれば送信先にて table の状態を復元することができる。</p><figure class=center><img loading=lazy src=https://media.striim.com/wp-content/uploads/2021/04/06232959/Option-1.png alt="Log-Based Change Data Capture, Change Data Capture (CDC): What it is and How it Works - Striim"><figcaption><p>Log-Based Change Data Capture, <a href=https://www.striim.com/blog/change-data-capture-cdc-what-it-is-and-how-it-works/>Change Data Capture (CDC): What it is and How it Works - Striim</a></p></figcaption></figure><p>CDC については以下も参照。</p><ul><li>Log-Based Change Data Capture in <a href=https://www.striim.com/blog/change-data-capture-cdc-what-it-is-and-how-it-works/>Change Data Capture (CDC): What it is and How it Works - Striim</a></li><li><a href="https://learn.microsoft.com/en-us/sql/relational-databases/track-changes/track-data-changes-sql-server?view=sql-server-ver16#Capture">Track Data Changes - SQL Server | Microsoft Learn</a></li></ul><p>CDC を実現する方法はいくつかある。<br>modern data stack 的には <a href=https://debezium.io/>Debezium</a> が最も有名だろう。<br>今回は元々クラウドサービスとして AWS を利用していたため、比較的導入が容易な <a href=https://docs.aws.amazon.com/dms/latest/userguide/Welcome.html>AWS DMS (Database Migration Service)</a> を使うことにした。<br>source として RDS、target として S3 を指定して DMS の replication task を動かすことになる。</p><p>ちなみに CDC を始める前に現在の table 全体をコピーする full load という処理を実行する必要があるが、このポストでは割愛。</p><p>DMS の CDC で S3 へと送信されたイベントログはそのままでは分析に使えない。<br>元の table と同じ形に組み上げる必要がある。<br>ここでは <a href=https://iceberg.apache.org/>Apache Iceberg</a> という table 形式を使ってそれを行うことにした。<br>Iceberg については当アドベントカレンダーの他のポストや<a href=../../tags/apache-iceberg>本ブログの Iceberg についてのポスト</a>も参考にしてほしい。</p><p>Iceberg を採用した理由は以下のとおり。</p><ul><li>Athena でサポートされている table 形式である</li><li>SQL の <code>merge into</code> 文 (後述) により比較的容易にイベントログを元の table の形に復元できる</li><li>MOR (Merge on Read、後述) により、コストの低い table 更新を実現できる</li></ul><p>Athena および Glue (後述) で使いたいので Iceberg catalog としては Glue Data Catalog を使うことになる。</p><p>他に Athena で使えて似たことができる table 形式としては <a href=https://hudi.apache.org/>Apache Hudi</a> がある。<br>しかし以前技術検証したときに Athena のエンジンが Hudi の MOR に対応していなかったため、採用しなかった。<br>(今はできるかもしれない、未確認)</p><p>アーキテクチャは以下のようになる。</p><figure class=center><img loading=lazy src=/image/iceberg/rds_to_iceberg_architecture.png alt="solution architecture"><figcaption><p>solution architecture</p></figcaption></figure><h2 id=ソリューション詳細>ソリューション詳細<a hidden class=anchor aria-hidden=true href=#ソリューション詳細>#</a></h2><p>主に Iceberg まわりについて詳しく見ていく。</p><h3 id=merge-into-文による-iceberg-table-の更新><code>merge into</code> 文による Iceberg table の更新<a hidden class=anchor aria-hidden=true href=#merge-into-文による-iceberg-table-の更新>#</a></h3><p>アーキテクチャ図の 2. にあたる処理。</p><p>DMS の CDC では near real time で S3 にイベントログが出力される。<br>ただ、今回はデータ基盤については near real time の更新の要件はなかったため、1時間ごとの更新を試みることにした。</p><p>ソースである RDS 上の table が 2023-11-11 09:59:59.999999 の時点で次のような状態 (A) だったとする。</p><table><thead><tr><th>id</th><th>name</th><th>phone_number</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>123-456</td></tr><tr><td>2</td><td>Bob</td><td>456-789</td></tr></tbody></table><p>これが1時間後には次のようになっていたとする。(B)</p><table><thead><tr><th>id</th><th>name</th><th>phone_number</th></tr></thead><tbody><tr><td>1</td><td>Alice</td><td>123-000</td></tr><tr><td>3</td><td>Charlie</td><td>456-789</td></tr></tbody></table><p>このとき、DMS による1時間分の CDC 結果の出力は例えば次のようになっている。(C)</p><table><thead><tr><th>Op</th><th>timestamp</th><th>id</th><th>name</th><th>phone_number</th></tr></thead><tbody><tr><td>I</td><td>2023-11-11 10:05:00.000000</td><td>3</td><td>Charlie</td><td>333-333</td></tr><tr><td>U</td><td>2023-11-11 10:10:00.000000</td><td>1</td><td>Alice</td><td>123-000</td></tr><tr><td>D</td><td>2023-11-11 10:15:00.000000</td><td>2</td><td>Bob</td><td>456-789</td></tr></tbody></table><p>column <code>Op</code> は DMS によって付与される column であり、イベントの種別を表す。</p><ul><li>I: 挿入 (Insert)</li><li>U: 更新 (Update)</li><li>D: 削除 (Delete)</li></ul><p>column <code>timestamp</code> も DMS によって付与された column であり、ソース側でその変更が commit された時刻を表す。 (column 名は設定で指定可能)<br>ソースの table が (A) の状態から (C) に記載されているような変更を経て (B) の状態になった、ということである。</p><p>前回までの変更を Iceberg table が追従できているのであれば (A) の状態になっているはずであり、ここで (C) の差分を適用して (B) の状態にする必要がある。<br>これを自分で実装するとなると結構めんどうだが、幸いに SQL の <code>merge into</code> 文を使って Iceberg table を更新することができる。</p><ul><li><a href=https://iceberg.apache.org/docs/latest/spark-writes/#merge-into>Writes - Apache Iceberg</a></li></ul><p>この例だと例えば次のような SQL で挿入・更新・削除を一度に適用できる。</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=display:flex><span>merge <span style=color:#66d9ef>into</span>
</span></span><span style=display:flex><span>    my_catalog.my_database.iceberg_table <span style=color:#66d9ef>as</span> iceberg
</span></span><span style=display:flex><span><span style=color:#66d9ef>using</span> (
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>select</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>*</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>from</span>
</span></span><span style=display:flex><span>        cdc_table <span style=color:#66d9ef>as</span> cdc  <span style=color:#75715e>-- CDC 結果を1時間分だけ読み込んだ DataFrame
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>on</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>-- この column の一致で同一レコードとみなす (複数指定も可)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    iceberg.id <span style=color:#f92672>=</span> cdc.id
</span></span><span style=display:flex><span><span style=color:#75715e>-- 一致する id があり Op=D の場合は削除
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>when</span> matched <span style=color:#66d9ef>and</span> cdc.Op <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;D&#39;</span> <span style=color:#66d9ef>then</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>delete</span>
</span></span><span style=display:flex><span><span style=color:#75715e>-- 一致する id があり Op=I or U の場合は更新
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>when</span> matched <span style=color:#66d9ef>and</span> cdc.Op <span style=color:#f92672>!=</span> <span style=color:#e6db74>&#39;D&#39;</span> <span style=color:#66d9ef>then</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>update</span> <span style=color:#66d9ef>set</span>
</span></span><span style=display:flex><span>        id <span style=color:#f92672>=</span> cdc.id,
</span></span><span style=display:flex><span>        name <span style=color:#f92672>=</span> cdc.name,
</span></span><span style=display:flex><span>        phone_number <span style=color:#f92672>=</span> cdc.phone_number
</span></span><span style=display:flex><span><span style=color:#75715e>-- 一致する id がなく Op=I or U の場合は挿入
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>when</span> <span style=color:#66d9ef>not</span> matched <span style=color:#66d9ef>and</span> cdc.Op <span style=color:#f92672>!=</span> <span style=color:#e6db74>&#39;D&#39;</span> <span style=color:#66d9ef>then</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>insert</span>(id, name, phone_number)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>values</span>(cdc.id, cdc.name, cdc.phone_number)
</span></span></code></pre></div><p>今回の実装では column 名取得の都合などから Glue Job の Spark SQL でこの SQL を実行するものとした。<br>ちなみに <code>merge into</code> 文自体は <a href=https://docs.aws.amazon.com/ja_jp/athena/latest/ug/merge-into-statement.html>Athena でもサポート</a>しているので、Athena でも実行することができる。</p><p>Iceberg table は MOR (Merge on Read) 形式にしており、table 更新時は列指向形式データをすべて書き換えるのではなく差分のみが追加されるようになっている。<br>このため大きな table であっても比較的低コストでの table 更新が可能となる。<br>一方で読み取りは COW (Copy on Write) の場合と比べて遅くなるが、基本的には列指向なので分析クエリに対してはそこそこのパフォーマンスとなる。<br>MOR, COW については以下を参考。</p><ul><li><a href=https://www.dremio.com/blog/row-level-changes-on-the-lakehouse-copy-on-write-vs-merge-on-read-in-apache-iceberg/>Row-Level Changes on the Lakehouse: Copy-On-Write vs. Merge-On-Read in Apache Iceberg | Dremio</a></li></ul><p>(Dremio さんの Iceberg 解説記事にはいつもお世話になっています！)</p><h3 id=daily-snapshot-の作成>daily snapshot の作成<a hidden class=anchor aria-hidden=true href=#daily-snapshot-の作成>#</a></h3><p>アーキテクチャ図の 4. にあたる処理。</p><p>Iceberg table は hourly で更新する一方、Iceberg table から daily でスナップショットとして Parquet 形式に書き出すという処理も追加した。<br>Iceberg には time travel の機能があり、Iceberg table 自身の中でスナップショットを持つことも可能である。<br>しかしわざわざ daily スナップショットを外に書き出しているのは、チームとして Iceberg table の運用経験がなく、長期的に安定運用できるかわからなかったため。</p><p>例えばもし Iceberg table の metadata がぶっ壊れたら…などと考えると、Iceberg の外にデータを別で持っておきたい気持ちがわかっていただけるのではないだろうか。<br>元々が daily の更新だったため、最低限 daily のスナップショットが残っていれば少なくとも現在の業務は継続することができる。</p><p>分析者視点だと</p><ul><li>直近1週間 (後述) の鮮度の高いデータの分析 -> hourly 更新の table (Iceberg)</li><li>長期間におけるデータの分析 -> daily 更新の table (Parquet)</li></ul><p>と使い分けてもらうことになる。</p><p>後々 Iceberg table が安定運用できることが分かれば Iceberg 1本にしてもいい。</p><h3 id=iceberg-table-のメンテナンス>Iceberg table のメンテナンス<a hidden class=anchor aria-hidden=true href=#iceberg-table-のメンテナンス>#</a></h3><p>前後してアーキテクチャ図の 3. にあたる処理。</p><p>ここでは Iceberg table の compaction と古いスナップショットの削除を行う。<br>これらも daily で実行するものとする。</p><p>MOR の場合、更新が何回も行われ差分の世代が多くなってくるとそれらを merge して table としてのデータを読み取る速度が遅くなってくる。<br>これを解消するためには差分を統合して1つのファイルにまとめる必要があり、これを compaction と言う。<br>この compaction の処理を追加している。</p><ul><li><a href=https://www.dremio.com/blog/compaction-in-apache-iceberg-fine-tuning-your-iceberg-tables-data-files/>Fine-Tuning Apache Iceberg Tables - Dremio Blog | Dremio</a></li></ul><p>Iceberg table は内部にスナップショットという概念があり、table の状態を複数バージョン持っている。<br>これにより time travel query が実行できたり、ACID transction を提供できたりと大きなメリットとなっている。<br>前述のとおり daily でデータを Parquet として書き出しているので、Iceberg 内で過去の古いスナップショットを持っているとデータの重複になってしまう。<br>よって定期的に Iceberg 内の古いスナップショットを削除する処理を追加している。<br>ここでは1週間分残すようにし、それより古いスナップショットは削除するようにした。</p><p>compaction、古い snashot の削除はともに Spark SQL から実行することができる。<br>それぞれ <code>rewrite_data_files()</code>, <code>expire_snapshots()</code> という procedure が対応している。</p><ul><li><a href=https://iceberg.apache.org/docs/latest/spark-procedures/>Maintenance - Apache Iceberg</a></li></ul><h2 id=運用上の工夫>運用上の工夫<a hidden class=anchor aria-hidden=true href=#運用上の工夫>#</a></h2><h3 id=dms-mirgration-task-の監視>DMS mirgration task の監視<a hidden class=anchor aria-hidden=true href=#dms-mirgration-task-の監視>#</a></h3><p>ソースである RDS 側で手動または自動でフェイルオーバーが実行されたり、エンジンバージョンアップが行われたりすると、CDC を継続的に行っている DMS の replication task が <code>Failed</code> で死んでしまうことがある。<br>したがって replication task の実行状況を監視して通知する仕組みが必須となる。</p><p>replication task が失敗した場合は速やかに再度実行することになる。<br>このあたりの運用はちょっと面倒なので、再実行の自動化を検討している。</p><h3 id=遅延チェック>遅延チェック<a hidden class=anchor aria-hidden=true href=#遅延チェック>#</a></h3><p>上記とも関係しているが、何らかの理由で CDC の結果が S3 に届くのが遅れることも想定される。<br>遅れているのに気づかずに「HH 時台の CDC イベントログは全部届いたよね！」とみなして Iceberg table に更新をかけると table が意図しない状態になってしまうかもしれない。</p><p>これを防ぐために各時間の <code>merge into</code> 文を実行する前に過去 N 時間分の CDC の出力をチェックして、イベントログが遅れて届いていることがないことを確認するようにしている。<br>遅れて届いているイベントログがあった場合、procedure <a href=https://iceberg.apache.org/docs/latest/spark-procedures/#rollback_to_snapshot><code>rollback_to_snapshot()</code></a> などで table の状態を rollback することになる。</p><p>ちなみにこういった処理の依存関係はおなじみ Airflow (Amazon MWAA) で管理している。</p><p>また、合わせて DMS の CloudWatch Mterics の <code>CDCLatencySource</code> や <code>CDCLatencyTarget</code> を見ておくとよい。<br>それぞれソースと replication instance, replication instance とターゲット間の遅延を表している。</p><h3 id=schema-evolution>schema evolution<a hidden class=anchor aria-hidden=true href=#schema-evolution>#</a></h3><p>column 追加など、ソース側の table の schema が変更されることは当然起こりうる。<br>RDS の table を管理しているチームには schema を変更するときは前もって教えてもらえる一応伝えてある。</p><p>我々のチームでは通常 Athena というか Glue Data Catalog 上の table の定義は CDK で IaC として管理している。(dbt は未導入)<br>ただし Iceberg table の schema 変更は metadata として管理される。<br>当然 CDK というかその中身の CloudFormation では Iceberg の metadata は扱えない。<br>Iceberg table の schema については IaC に乗せることはできず、DDL で管理することになっている。</p><h3 id=merge-into-文における単一レコードの複数回操作への配慮><code>merge into</code> 文における単一レコードの複数回操作への配慮<a hidden class=anchor aria-hidden=true href=#merge-into-文における単一レコードの複数回操作への配慮>#</a></h3><p>前述の <code>merge into</code> 文のサンプル SQL を見て、例えば同じ <code>id</code> のレコードに対して1時間の中で</p><ul><li>複数回更新が行われた</li><li>挿入の後、削除が行われた</li></ul><p>など複数回の操作があった場合はどうなるんだ？と思った方はごもっとも。</p><p>実際上記のサンプル SQL では複数回の操作を考慮できていない。<br>なので <code>cdc</code> のレコードをどの順で読み取るかによる、未定義な挙動になると考えられる。</p><p>ではどうすればいいかというと、ある <code>id</code> に対して1時間の中で最後に行われた操作だけを見ればよい。<br>最後の操作が削除であればそのレコードは最終的に存在しないし、最後の操作が挿入または更新であれば存在する。<br>具体的には <code>using (...)</code> の中の <code>select</code> 文を <code>id</code> ごとに最後の操作だけ見るように書き換えればよい。<br>ここで「最後」を定義するために column <code>timestamp</code> が必要になってくる。<br><code>timestamp</code> と window 関数を使ってごにょごにょすると…？</p><h2 id=適用の結果-まだない>適用の結果 (まだない)<a hidden class=anchor aria-hidden=true href=#適用の結果-まだない>#</a></h2><p>この記事において、適用の結果 AWS コストが◯◯%削減できました！と言えればよかったのだが、まだこの仕組みは運用を始めたばかりであり実績値は出せない。<br>プロジェクト着手前の試算では結構がっつり減らせる想定ではあった。<br>前述のとおり処理が多段的になり運用の手間も増えているが、ペイできる程度のコスト削減を見込んでいる。<br>気が向いたら結果を追記するかもしれない。</p><h2 id=まとめ>まとめ<a hidden class=anchor aria-hidden=true href=#まとめ>#</a></h2><p>実際に Apache Iceberg を使っているプロジェクトの実務としての背景や運用について書いてみた。<br>そんなに新しい内容はないが、ノウハウ的なところはあまり見かけない気がするのでまあ許していただきたい。<br>今回は Iceberg に注目したので DMS について詳しく書かなかったが、こっちはこっちでいろいろあったりする。</p><p><a href=https://qiita.com/advent-calendar/2023/distributed-computing>Distributed computing Advent Calendar 2023</a>、明日は Delta Lake についてのお話のようですね。<br>こちらも興味深いです。</p><hr><p>弊チームではこういったお仕事や modern data stack の導入などを一緒にやってくれるデータエンジニアを募集しています。<br>ご興味のある方は X にて DM ください。<br>カジュアル面談しましょう。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://soonraah.github.io/tags/apache-iceberg/>Apache Iceberg</a></li><li><a href=https://soonraah.github.io/tags/cdc/>CDC</a></li><li><a href=https://soonraah.github.io/tags/aws/>AWS</a></li><li><a href=https://soonraah.github.io/tags/amazon-athena/>Amazon Athena</a></li><li><a href=https://soonraah.github.io/tags/aws-dms/>AWS DMS</a></li></ul><nav class=paginav><a class=prev href=https://soonraah.github.io/posts/dmbok-chapter-12/><span class=title>« 前へ</span><br><span>読書メモ: DMBOK2 第12章 メタデータ管理</span>
</a><a class=next href=https://soonraah.github.io/posts/dmbok-chapter-3/><span class=title>次へ »</span><br><span>読書メモ: DMBOK2 第3章 データガバナンス</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share CDC + Apache Iceberg で Amazon Athena にデータを取り込む on x" href="https://x.com/intent/tweet/?text=CDC%20%2b%20Apache%20Iceberg%20%e3%81%a7%20Amazon%20Athena%20%e3%81%ab%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e5%8f%96%e3%82%8a%e8%be%bc%e3%82%80&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fingest-data-into-athena-by-cdc-and-iceberg%2f&amp;hashtags=ApacheIceberg%2cCDC%2cAWS%2cAmazonAthena%2cAWSDMS"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CDC + Apache Iceberg で Amazon Athena にデータを取り込む on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fingest-data-into-athena-by-cdc-and-iceberg%2f&amp;title=CDC%20%2b%20Apache%20Iceberg%20%e3%81%a7%20Amazon%20Athena%20%e3%81%ab%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e5%8f%96%e3%82%8a%e8%be%bc%e3%82%80&amp;summary=CDC%20%2b%20Apache%20Iceberg%20%e3%81%a7%20Amazon%20Athena%20%e3%81%ab%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e5%8f%96%e3%82%8a%e8%be%bc%e3%82%80&amp;source=https%3a%2f%2fsoonraah.github.io%2fposts%2fingest-data-into-athena-by-cdc-and-iceberg%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CDC + Apache Iceberg で Amazon Athena にデータを取り込む on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoonraah.github.io%2fposts%2fingest-data-into-athena-by-cdc-and-iceberg%2f&title=CDC%20%2b%20Apache%20Iceberg%20%e3%81%a7%20Amazon%20Athena%20%e3%81%ab%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e5%8f%96%e3%82%8a%e8%be%bc%e3%82%80"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CDC + Apache Iceberg で Amazon Athena にデータを取り込む on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoonraah.github.io%2fposts%2fingest-data-into-athena-by-cdc-and-iceberg%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CDC + Apache Iceberg で Amazon Athena にデータを取り込む on whatsapp" href="https://api.whatsapp.com/send?text=CDC%20%2b%20Apache%20Iceberg%20%e3%81%a7%20Amazon%20Athena%20%e3%81%ab%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e5%8f%96%e3%82%8a%e8%be%bc%e3%82%80%20-%20https%3a%2f%2fsoonraah.github.io%2fposts%2fingest-data-into-athena-by-cdc-and-iceberg%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CDC + Apache Iceberg で Amazon Athena にデータを取り込む on telegram" href="https://telegram.me/share/url?text=CDC%20%2b%20Apache%20Iceberg%20%e3%81%a7%20Amazon%20Athena%20%e3%81%ab%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e5%8f%96%e3%82%8a%e8%be%bc%e3%82%80&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fingest-data-into-athena-by-cdc-and-iceberg%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share CDC + Apache Iceberg で Amazon Athena にデータを取り込む on ycombinator" href="https://news.ycombinator.com/submitlink?t=CDC%20%2b%20Apache%20Iceberg%20%e3%81%a7%20Amazon%20Athena%20%e3%81%ab%e3%83%87%e3%83%bc%e3%82%bf%e3%82%92%e5%8f%96%e3%82%8a%e8%be%bc%e3%82%80&u=https%3a%2f%2fsoonraah.github.io%2fposts%2fingest-data-into-athena-by-cdc-and-iceberg%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://soonraah.github.io>Froglog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="コピー";function s(){t.innerHTML="コピーされました!",setTimeout(()=>{t.innerHTML="コピー"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>