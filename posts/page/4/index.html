<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Froglog</title>
<meta name=keywords content><meta name=description content="Posts - Froglog"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://soonraah.github.io/posts/index.xml><link rel=alternate hreflang=ja href=https://soonraah.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://soonraah.github.io/posts/"><meta property="og:site_name" content="Froglog"><meta property="og:title" content="Posts"><meta property="og:description" content="blog"><meta property="og:locale" content="ja"><meta property="og:type" content="website"><meta property="og:image" content="https://soonraah.github.io/image/brand/soonraah_full.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/brand/soonraah_full.png"><meta name=twitter:title content="Posts"><meta name=twitter:description content="blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soonraah.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span class=active>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://soonraah.github.io/>ホーム</a></div><h1>Posts</h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/sharon-mccutcheon-8lnbXtxFGZw-unsplash.jpg alt=Profit></figure><header class=entry-header><h2 class=entry-hint-parent>機械学習の精度と利益と倫理とイシューと</h2></header><div class=entry-content><p>ちょっと昔話 かつて参画したプロジェクトの話。
そのプロジェクトでは他社から受注した受託開発として機械学習系のシステムを開発していた。
当時としては新しいフレームワークを使い、かなり頑張ってなんとか納期内で完成させた。
その中の1つの機能として A/B テストができるようにしていた。
パラメータチューニングによりパフォーマンスを改善することを想定していた。
しかし結局その機能は使われることがなかった。
なぜか。
A/B テストを実施するためのクライアントの追加の予算がつかなかったためである。
受託なのでなおさらなのだが、売上にならなければ工数をかけるこはできない。
工数を使ってパフォーマンス改善することはできなかった。
手はあるのに。
機械学習の精度は必ずしも利益に結びつかない この昔話で何が言いたいかというと、機械学習の精度改善は必ずしも利益に結びつかないということである。
そのことを示しているとても素晴らしい資料がこちら。
機械学習の精度と売上の関係 from Tokoroten Nakayama 前述の昔話の例はこの資料で言うところの③ロジスティック型 (=外注) となる。
いったん売上が立った後、追加予算がつかなかったので精度改善では売上は増えなかったのだ。
倫理感による精度改善 受託開発を主としている組織であれば工数にはシビアなので、売上の立たない工数をかけることはあまりないだろう。
(よっぽどの炎上鎮火とかでなければ)
しかし自社で製品やサービスを作って提供しているような組織の場合、利益にならない精度改善をしているのを時折見かける。
なぜそのようなことが起こるかと言うと多くの場合はデータサイエンティスト／機械学習エンジニアとしての倫理感からなのではないだろうか。
「◯◯予測という機能なのでできるだけ良い予測精度を示すべきだ」
「ユーザには気づかれない部分だが精度が悪いので改善したい」
倫理感や興味が先行してしまっているのだ。
しかしその精度を上げた先に利益があるとは限らない。
機械学習で職を得ている人間は自分の仕事を機械学習の精度を上げるゲームだとみなす傾向があるように思う。
例えばインターネット広告の CTR 予測。
これは予測精度が高いほど利益は改善するし、広告主に価値も提供できる。
精度改善に倫理と利益が伴っている、とても機械学習がハマる例だと思う。
本来はこれらを兼ね備えているのが良い適用先であるはずだ。
イシューは行き渡っているのか 利益に結びつかない、または間接的にしか結びつかないような精度改善をやることが許されるというのは組織に余裕があるということで悪いことではないのかもしれない。
しかし単によいイシューの設定ができてないだけという可能性もある。
自社で製品やサービスを作って提供しているような組織において、単純なロジスティック回帰でコアなところのビジネスを大きく加速させることができた時期を過ぎると機械学習で解くのに適したよい問題を恒常的に見つけ出すのは実は難しいのではないだろうかと最近考えるようになった。
ビジネスの領域拡大よりも既存領域への機械学習の適用の方が速いということは十分ありうる。
もちろんチームの規模にもよる。
機械学習チームの人的リソースの規模に対して機械学習で解くべきよいイシューを見つけ出せているのか、ということだ。
少し前にちょっと話題になったこちらの件もイシューが大事だと言っている。
全ての機械学習の論文は新しいアルゴリズムを提案しているのですか？ - Quora キャリアの行く末 事業会社においてビジネスの領域拡大よりも既存領域への機械学習の適用の方が速く、よいイシューを提供しにくいということがよく起こるのであれば、機械学習チームのリソースは余剰気味になりやすいということになる。
これが続くと今後機械学習しかやらない人材の市場価値は下がっていくのかもしれない。
もしくは自社で製品やサービスを持っている組織ではなく、受託開発やコンサルが主戦場になっていくのかもしれない。
何にせよ特定のプロダクトに commit したいのであれば機械学習エンジニアは機械学習以外のスキルも磨いていく必要があるように思う。
おわりに 見える範囲にいる人が利益にならない精度改善をしているのを横目で見てこのようなことを考えていた。
難しいけどできるだけ金を生んでいきたい。</p></div><footer class=entry-footer><span title='2020-11-12 09:30:00 +0900 JST'>11月 12, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 機械学習の精度と利益と倫理とイシューと" href=https://soonraah.github.io/posts/ml-accuracy-profit-ethic-issue/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/nathan-anderson-8X1-pcDF8l0-unsplash.jpg alt=Stream></figure><header class=entry-header><h2 class=entry-hint-parent>ストリーム処理システムに求められる機能性、および Apache Flink におけるその対応</h2></header><div class=entry-content><p>はじめに このポストではストリーム処理の survay 論文の話題に対して Apache Flink における例を挙げて紹介する。
論文概要 Fragkoulis, M., Carbone, P., Kalavri, V., & Katsifodimos, A. (2020). A Survey on the Evolution of Stream Processing Systems.
2020年の論文。
過去30年ぐらいのストリーム処理のフレームワークを調査し、その発展を論じている。
ストリーム処理に特徴的に求められるいくつかの機能性 (functionality) についてその実現方法をいくつか挙げ、比較的古いフレームワークと最近のフレームワークでの対比を行っている。
このポストのスコープ このポストでは前述のストリーム処理システムに求められる機能性とそれがなぜ必要となるかについて簡単にまとめる。
論文ではそこからさらにその実現方法がいくつか挙げられるが、ここでは個人的に興味がある Apache Flink ではどのように対処しているかを見ていく。
ちなみに論文中では Apache Flink はモダンなフレームワークの1つとしてちょいちょい引き合いに出されている。
ここでは Flink v1.11 をターゲットとする。
以下では論文で挙げられている機能性に沿って記載していく。
Out-of-order Data Management Out-of-order ストリーム処理システムにやってくるデータの順序は外的・内的要因により期待される順序になっていないことがある。
外的要因としてよくあるのはネットワークの問題。
データソース (producer) からストリーム処理システムに届くまでのルーティング、負荷など諸々の条件により各レコードごとに転送時間は一定にはならない。
各 operator の処理などストリーム処理システムの内的な要因で順序が乱されることもある。
out-of-order は処理の遅延や正しくない結果の原因となることがある。
out-of-order を管理するためにストリーム処理システムは処理の進捗を検出する必要がある。
“進捗” とはある時間経過でレコードの処理がどれだけ進んだかというもので、レコードの順序を表す属性 A (ex. event time) により定量化される。
ある期間で処理された最古の A を進捗の尺度とみなすことができる。
...</p></div><footer class=entry-footer><span title='2020-11-07 16:00:00 +0900 JST'>11月 7, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to ストリーム処理システムに求められる機能性、および Apache Flink におけるその対応" href=https://soonraah.github.io/posts/functionality-of-streaming-system/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/jon-flobrant-rB7-LCa_diU-unsplash.jpg alt=Stream></figure><header class=entry-header><h2 class=entry-hint-parent>バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと</h2></header><div class=entry-content><p>ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。
それにあたって独学で調べたことなどまとめておく。
ストリーム処理とは そもそも “ストリーム処理” とは何を指しているのか。
以下の引用が簡潔に示している。
a type of data processing engine that is designed with infinite data sets in mind. Nothing more.
– Streaming 101: The world beyond batch
こちらは “streaming system” について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。
例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。
web サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。
これに対して “1日分のユーザ行動ログ” 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。
ストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。
この後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。
なぜストリーム処理なのか なぜストリーム処理なのか。
ひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。
迅速なフィードバックがビジネス上のメリットとなることは自明だ。
SNS の配信 カーシェアリングにおける配車や料金設定 クレジットカードや広告クリックなどの不正検知 もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。
まあ待っていられない。
...</p></div><footer class=entry-footer><span title='2020-09-06 16:30:00 +0900 JST'>9月 6, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと" href=https://soonraah.github.io/posts/study-streaming-system/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/jason-dent-JVD3XPqjLaQ-unsplash.jpg alt="A/B Testing"></figure><header class=entry-header><h2 class=entry-hint-parent>A/B テストの運用が重くてつらいという話</h2></header><div class=entry-content><p>前提 ここでは web システムで使われている機械学習のモデルやアルゴリズムを改善するための online の A/B テストを考える。
具体的に述べると web 広告における CTR 予測や EC サイトのレコメンデーション等が対象である。
よくあるやつ。
web システムにおいて online の A/B テストは KPI 改善の根幹でありとても重要だ。
それが重くなるとつらい、という話。
ここで「重い」と言っているのは計算資源のことではなく、A/B テストを実施する担当者の運用コストについて。
A/B テストの運用が重い場合のデメリット デメリット 1. KPI 改善が遅くなる デメリットと言えばこれが一番大きい。
単純に A/B テストを1回まわすのに時間がかかってしまうし、それがゆえに online の A/B テストに入るまでの offline のテストが厚くなりここでも時間がかかってしまう。
KPI 改善に時間がかかるというのはつまり売上や利益を大きくするのに時間がかかってしまうということである。
デメリット 2. KPI 改善における offline テストの比重が大きくなる 前述のとおりだが online の A/B テストが重いとそこで失敗できなくなり、結果としてその前段の offline のテストを厚くするということになる。
offline のテストが厚いことの何が問題だろうか。
ここで前提としている CTR 予測やレコメンデーションのようなタスクの場合、offline のデータは既存のモデルやアルゴリズムの影響を受けることになる。
例えばレコメンデーションの場合を考えると、新しいモデルを offline で評価するための実験データの正例 (コンテンツの閲覧等) は既存モデルによって生み出される。
既存モデルが「このコンテンツがいいよ」といってユーザに出したリスト、その中からコンテンツの閲覧が行われ正例となるからだ。
このような状況下での offline テストにおいては既存モデルと近い好みを持ったモデルのスコアが高くなる傾向がある。
...</p></div><footer class=entry-footer><span title='2020-08-23 12:30:00 +0900 JST'>8月 23, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to A/B テストの運用が重くてつらいという話" href=https://soonraah.github.io/posts/heavy-ab-testing-operation/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/logo/flink_squirrel_color_logo.png alt="Apache Flink"></figure><header class=entry-header><h2 class=entry-hint-parent>Apache Flink の Temporary Table Function を用いた stream data と static data の join</h2></header><div class=entry-content><p>前回の記事 では Apache Flink における stream data と static data の join において、DataStream API における broadcast state pattern を使う方法を示した。
今回の記事では Table API の temporal table function を用いた実験を行う。
Table API Table API は名前のとおりで class Table を中心として SQL-like な DSL により処理を記述するという、DataStream API より high-level な API となっている。
これらの関係は Apaceh Spark の RDD と DataFrame (DataSet) の関係に似ている。
SQL-like な API で記述された処理が実行時に最適化されて low-level API の処理に翻訳されるところも同じだ。
RDB の table の概念を元にしているものと考えられるが、本質的に table の概念とストリーム処理はあまりマッチしないと思う。
table はある時点のデータセット全体を表すのに対し、ストリーム処理ではやってくるレコードを逐次的に処理したい。
ここを合わせているため、ストリーム処理における Table API による処理の挙動の理解には注意が必要だ。
Streaming Concepts 以下のドキュメントを確認しておきたい。
...</p></div><footer class=entry-footer><span title='2020-08-16 00:30:00 +0900 JST'>8月 16, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Flink の Temporary Table Function を用いた stream data と static data の join" href=https://soonraah.github.io/posts/flink-join-by-temporal-table-function/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/logo/flink_squirrel_color_logo.png alt="Apache Flink"></figure><header class=entry-header><h2 class=entry-hint-parent>Apache Flink の Broadcast State Pattern を用いた stream data と static data の join</h2></header><div class=entry-content><p>star schema における fact table と dimension table の join のようなことを Apache Flink におけるストリーム処理で行いたい。
stream data と static data の join ということになる。
ただし dimension table 側も更新されるため、完全な static というわけではない。
このポストでは Flink v1.11 を前提とした。
join の方法 今回は DataStream API でこれを実現することを考える。
Flink のドキュメントを読むと broadcast state pattern でできそうだ。
The Broadcast State Pattern やり方としては次のようになる。
static data のファイルを FileProcessingMode.PROCESS_CONTINUOUSLY で読み込み DataStream 化 1 を broadcast() stream data の DataStream と 2 を connect() static data を PROCESS_CONTINUOUSLY で読むのは変更を得るため。
PROCESS_ONCE で読んでしまうとストリーム処理の開始時に1回読むだけになり、dimension table の変更を得られない。
このあたりの仕様については Data Sources を参照。
...</p></div><footer class=entry-footer><span title='2020-08-06 22:00:00 +0900 JST'>8月 6, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Flink の Broadcast State Pattern を用いた stream data と static data の join" href=https://soonraah.github.io/posts/flink-join-by-broadcast-state-pattern/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>あまり大きな Pull Request を作ってほしくない</h2></header><div class=entry-content><p>GitHub Flow ベースの開発においてはあまり大きな pull request を作ってほしくないという話。
なんというか今更わざわざ言わなくてもいいんだけど…
仕事で何度か大きな pull request が投げられているのを見てしまったので、それはあまりよくないよというのを自分でも指摘しやすくするためにまとめておく。
Reference 最初に参考資料を挙げておく。
100 Duck-Sized Pull Requests 「巨大プルリク1件vs細かいプルリク100件」問題を考える（翻訳） Optimal pull request size これらを読めば特に私から言うこともないのだが…
これらに書いてあるとおりだが補足しておく。
Pull Request を小分けにしたときのメリット module を適切に切り出すモチベーションが得られる 次のような話がある。
共通化という考え方はアンチパターンを生み出すだけ説 これを理由に module を分けるべきところが分けられず、いろんなことができてしまうベタッと大きな module が生まれるのを見た。
もちろんよく考えられていない共通化は駄目だが、上記ポストでは一方で
ただし共通化という名の下におこなわれるのは「同じロジックを持つコードをまとめる」行為であって、抽象化のようにそのコード単位の意味を捉える作業はその範疇にない。抽象化というのはロジックを意味単位ごとにひとくくりにしていく行為で、これがどういうことなのかは次以降で述べていく。
– 共通化という考え方はアンチパターンを生み出すだけ説 - タオルケット体操
と述べており抽象化、つまりコードの意味を考慮した上で適切な単位でまとめておくことは否定していない。
pull request を小さく分けるという行為のためには module や機能を適度なまとまりで切り分けること、つまり抽象化を考えていくことが必要となる。
したがって何でもできてしまう大きな module が生まれるのを防ぐ方向に働く。
(もちろんここで駄目な共通化がなされてしまうこともあるだろう)
リリースまでの期間が短く済む 前述の参考資料においても pull request が大きいと
...</p></div><footer class=entry-footer><span title='2020-08-03 22:00:00 +0900 JST'>8月 3, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to あまり大きな Pull Request を作ってほしくない" href=https://soonraah.github.io/posts/no-more-huge-pull-request/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>勉強会メモ: Spark Meetup Tokyo #3 Online</h2></header><div class=entry-content><p>2020-07-31 にオンライン開催された Spark Meetup Tokyo #3 Online に参加した。
感想などメモしておく。
全体感 トピックとしては主に
Spark 3.0 Spark + AI Summit 2020 Spark 周辺要素 といったところだろうか。
最近のコミュニティの動向や関心を日本語で聞くことができてよかった。
運営 & スピーカーの皆様、ありがとうございます。
発表 発表資料は公開されたら追加していく。
SPARK+AI Summit 2020 イベント概要 スピーカー: @tokyodataguy さん
Summit は金融業界の参加者が増えているらしい Spark で最も使われている言語は Python とのことだったが、Databricks の notebook サービスの話だった プロダクションコードではまた違うのだろう Spark 3.0 の update をざっくりと Spark 周辺要素の話をざっくりと Koalas Delta Lake Redash MLflow Introducing Koalas 1.0 Introducing Koalas 1.0 (and 1.1) from Takuya UESHIN スピーカー: @ueshin さん
...</p></div><footer class=entry-footer><span title='2020-08-01 15:00:00 +0900 JST'>8月 1, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 勉強会メモ: Spark Meetup Tokyo #3 Online" href=https://soonraah.github.io/posts/spark-meetup-tokyo-3/></a></article><article class=post-entry><header class=entry-header><h2 class=entry-hint-parent>Spark DataFrame クエリの弱い分離レベル</h2></header><div class=entry-content><p>Spark バッチ処理の問題を調べていたら分離レベルという概念にたどりついた。
分離レベルについて調べたので、Spark の問題の内容と絡めて記しておく。
考えてみれば当たり前でたいした話ではない。
分離レベルとは トランザクションの挙動についての暗黙の理解 アドホックな分析クエリやプロダクションコード中のクエリを書くとき、その単一のクエリのトランザクションにおいて「同時に実行されている別のクエリの commit 前の状態や commit 結果に影響され、このクエリの結果がおかしくなるかもしれない」ということは通常考えない。
トランザクションはデータベースのある時点の状態に対して正しく処理される、というほぼ無意識の理解をおそらくほとんどの開発者が持っている。
多くの場合この理解は間違っていない。
それはなぜかというと DB 等のデータ処理フレームワークがある強さの分離レベルを提供しているからである。
いろいろな分離レベル ACID 特性のうちの1つ、分離性 (Isolation) の程度を表すのが分離レベル。
トランザクション中に行われる操作の過程が他の操作から隠蔽されることを指し、日本語では分離性、独立性または隔離性ともいう。より形式的には、独立性とはトランザクション履歴が直列化されていることと言える。この性質と性能はトレードオフの関係にあるため、一般的にはこの性質の一部を緩和して実装される場合が多い。 – Wikipedia ACID (コンピュータ科学)
分離レベルには名前のついたものがいくつかあり、分離性の保証の強さが異なる。
具体的にはトランザクションの並行性の問題への対応力が異なる。
名著「データ指向アプリケーションデザイン」の第7章で分離レベルについて詳しく述べられているので、以下ではそちらからの引用。
分離レベルを弱い順に並べる。
read uncommitted
このレベルではダーティライトは生じませんが、ダーティリードは妨げられません。
read committed
データベースからの読み取りを行った際に見えるデータは、コミットされたもののみであること（ダーティリードは生じない）。 データベースへの書き込みを行う場合、上書きするのはコミットされたデータのみであること（ダーティライトは生じない）。 snapshot isolation
スナップショット分離の考え方は、それぞれのトランザクションがデータベースの一貫性のあるスナップショットから読み取りを行うというものです。すなわち、トランザクションが読み取るデータは、すべてそのトランザクションの開始時点のデータベースにコミット済みのものだけということです。
serializability
この分離レベルはトランザクションが並行して実行されていても、最終的な答えはそれぞれが1つずつ順番に、並行ではなく実行された場合と同じになることを保証します。
日本語で「分離レベル」を検索すると snapshot isolation の代わりに repeatable read が出てくる事が多い。
しかし repeatable read の名前は実装によって意味が違っていたりして扱いが難しいらしい。
...</p></div><footer class=entry-footer><span title='2020-07-19 22:00:00 +0900 JST'>7月 19, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Spark DataFrame クエリの弱い分離レベル" href=https://soonraah.github.io/posts/weak_isolation_level_of_dataframe/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/logo/Apache_Spark_logo.svg alt="Apache Spark"></figure><header class=entry-header><h2 class=entry-hint-parent>Apache Spark 3.0.0 について調べた</h2></header><div class=entry-content><p>はじめに Apache Spark 3.0.0 がリリースされました。
Spark Release 3.0.0 release note を見て個人的に気になったところなど簡単に調べました。
書いてみると Databricks の記事へのリンクばっかになってしまった…
全体感 こちらの記事を読めば全体感は OK.
Introducing Apache Spark 3.0 公式の release note には
Python is now the most widely used language on Spark.
とあってそうなん？ってなったけど、こちらの記事だと
Python is now the most widely used language on Spark and, consequently, was a key focus area of Spark 3.0 development. 68% of notebook commands on Databricks are in Python.
と書いてありどうやら Databricks の notebook の話らしく、だったらまあそうかなという感じ。
プロダクトコードへの実装というよりは、アドホック分析や検証用途の話なんでしょう。
...</p></div><footer class=entry-footer><span title='2020-07-12 11:30:00 +0900 JST'>7月 12, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Spark 3.0.0 について調べた" href=https://soonraah.github.io/posts/study-spark-3-0-0/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://soonraah.github.io/posts/page/3/>«&nbsp;前へ&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://soonraah.github.io/>Froglog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>