<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Posts | Froglog</title>
<meta name=keywords content><meta name=description content="Posts - Froglog"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://soonraah.github.io/posts/index.xml><link rel=alternate hreflang=ja href=https://soonraah.github.io/posts/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://soonraah.github.io/posts/"><meta property="og:site_name" content="Froglog"><meta property="og:title" content="Posts"><meta property="og:description" content="blog"><meta property="og:locale" content="ja"><meta property="og:type" content="website"><meta property="og:image" content="https://soonraah.github.io/image/brand/soonraah_full.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/brand/soonraah_full.png"><meta name=twitter:title content="Posts"><meta name=twitter:description content="blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soonraah.github.io/posts/"}]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span class=active>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://soonraah.github.io/>ホーム</a></div><h1>Posts</h1></header><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/glenn-carstens-peters-RLw-UC03Gwc-unsplash.jpg alt=assessment></figure><header class=entry-header><h2 class=entry-hint-parent>読書メモ: DMBOK2 第15章 データマネジメント成熟度アセスメント</h2></header><div class=entry-content><p>このポストについて DMBOK2 を読み進めていくシリーズ。
今回は第15章「データマネジメント成熟度アセスメント」について。
データマネジメントの導入において重要な役割を果たしそうなので早めに確認しておきたかった。
以降、特に注釈のない引用は DMBOK2 第15章からの引用とする。
データマネジメント成熟度アセスメントとは データマネジメント成熟度アセスメント (DMMA: Data Management Maturity Assessment) はその名の通り、組織のデータマネジメントのレベルの評価に基づくプロセス改善の取り組みのこと。
能力成熟度アセスメント (CMA: Capability Maturity Assessment) というものがあり、それのデータマネジメント版が DMMA。
CMA では
成熟度モデルは進化の観点から定義され、それにはプロセスの特性を表すレベルが使用される。組織がプロセスの特性を理解すると、組織は成熟度を測り、その能力を向上させるための計画を立てることができる。(中略) 新しいレベルに上がる度にプロセスの実行はより一貫性を増し、予測可能な状態となり、信頼性が高くなる。
レベルは通常0~5の6段階で表される。
DMMA は
全体的なデータマネジメントを評価するために使用したり、単一の知識領域や、単一のプロセスに焦点を当てて使用したりできる。どのような点に焦点を当てたとしても、DMMA はデータマネジメント業務の健全性と有効性について、業務と IT の視点のギャップを埋めるために役立つ。
組織が DMMA を実施する理由は、規制への対応、データガバナンス、プロセス改善、etc.
DMMA の第一のゴールはデータマネジメント活動の現状を評価することであり、それにより改善計画を立てることができるようになる。
アセスメントレベル 以下はアセスメントレベルの概要。
データマネジメントの各知識領域 (ex. データガバナンス、メタデータ管理、etc.) ごとにレベルが評価される。
level 0: 能力が欠如した状態 データマネジメントの取り組みがない level 1: 初期／場当たり的な状態 限られたツールセットを用いた一般的なデータマネジメント ガバナンスは低レベル データ処理は一部の専門家に依存し、役割や責任は部門別に定義されている level 2: 反復可能な状態 組織は一元化された共通ツールを使い始める 役割は明確化されており、一部の専門家のみに依存しない level 3: 定義された状態 拡張可能なプロセスの導入と制度化 組織全体である程度統制されたデータの複製 データ品質全体の総体的な向上 組織的なポリシー定義と統制 level 4: 管理された状態 新しいプロジェクトやタスクから得られる結果が予測され、リスクの管理が始まる データマネジメントに成果に対する評価尺度が含まれる データマネジメント用の標準ツールが集中管理計画とガバナンス機能に組み合わされている level 5: 最適化された状態 活動の成果は十分予測可能に 組織は継続的な改善に重点を置く 十分理解された評価尺度を使ってデータ品質とプロセスが管理・測定される 次のように各知識領域ごとに可視化することができる。
現状ランクと求められるランクの乖離が大きいところが組織にとってのリスクとなる。
...</p></div><footer class=entry-footer><span title='2023-12-30 01:30:00 +0900 JST'>12月 30, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 読書メモ: DMBOK2 第15章 データマネジメント成熟度アセスメント" href=https://soonraah.github.io/posts/dmbok-chapter-15/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/huu-thong-z3vRZHah6tQ-unsplash.jpg alt=cake></figure><header class=entry-header><h2 class=entry-hint-parent>現実の CSV ファイルのデータを BigQuery に load する仕組みを作るという泥臭い作業を dlt でやってみる</h2></header><div class=entry-content><p>このポストについて 前回の記事 dlt 入門 - ELT の Extract と Load を担う data load tool では dlt の概要を説明した。
この記事ではそれを踏まえ、dlt を使って CSV ファイルを BigQuery に load するという一連の開発作業をやってみる。
現実の CSV はそのまま使えなかったりするので、BigQuery に入れるまでに泥臭い前処理のような作業があることが多い。
そのへんもまとめて dlt でやってみるとこんな感じ、というのが示せるとよい。
やりたいこと 個人で管理しているお金の情報を個人用の BigQuery に置きたい、という要件を想定。
データ概要 具体的には MoneyForward のデータを load していく。
個人では API を利用できないので、web UI から export できる CSV のデータで収入・支出詳細と資産推移月次を対象とする。
CSV の export 方法は以下を参照。
入出金履歴はダウンロードできますか – マネーフォワード MEサポートサイト データの内容は次のようになっている。
収入・支出詳細_2023-11-01_2023-11-30.csv "計算対象","日付","内容","金額（円）","保有金融機関","大項目","中項目","メモ","振替","ID" "1","2023/11/30","AMAZON.CO.JP","-2830","楽天カード","食費","食料品","","0","EPv92ZjQcOxgWQx_cLbhD1" "1","2023/11/24","東京ガス","-4321","楽天カード","水道・光熱費","ガス・灯油代","","0","r6wuQPfrIRS6aFpNYZE5Eh" "1","2023/11/24","給与 カ) フロッグログ","700000","みずほ銀行","収入","給与","","0","doettKpYyNp0Tml9KQQXm1" ヘッダーがあり、各列に名前が付いている。
encoding が CP932 であることに注意。
ID の列があるので、行の識別に使えそう。
...</p></div><footer class=entry-footer><span title='2023-12-20 09:30:00 +0900 JST'>12月 20, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 現実の CSV ファイルのデータを BigQuery に load する仕組みを作るという泥臭い作業を dlt でやってみる" href=https://soonraah.github.io/posts/load-csv-data-into-bq-by-dlt/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/todd-quackenbush-IClZBVw5W5A-unsplash.jpg alt=tools></figure><header class=entry-header><h2 class=entry-hint-parent>dlt 入門 - ELT の Extract と Load を担う data load tool</h2></header><div class=entry-content><p>このポストについて このポストは datatech-jp Advent Calendar 2023 の18日目の投稿です。
web の記事で見かけた dlt というツールが気になったので調べてみた。
dlt の概要について書いていく。
What is dlt? https://dlthub.com/
dlt とは “data load tool” の略。
雑に言うとデータパイプラインにおける ELT の Extract と Load を行う ものとなっている。
主にベルリンとニューヨークに拠点を持つ dltHub 社によって開発されており、OSS の Python ライブラリとして提供されている。
次のような特徴を持つ。
プラットフォームではなくあくまでライブラリであることが強調されている つまり Airflow, GitHub Actions, Google Cloud Functions, ローカル環境などどこでも動かすことができる スケールアウト可能な分散処理ではない extract と load にまつわる反復的で平凡な作業をなくすことを目指している schema 推論や schema evolution をサポート 宣言的なコードでメンテナンスを楽にする incremental loading をサポート 豊富な source GA, Salesforce, Kinesis などいろいろ例が挙げられている 要は API からの取得も含めて JSON-like な形式で Python で読めるものなら何でも 豊富な destination BigQuery, Snowflake など主要なクラウド DWH DuckDB はローカルでの動作確認に便利 Airflow, dbt などとの連携がある CLI の提供もある その他、Glossary を見ておくとドキュメントが読みやすくなる。
...</p></div><footer class=entry-footer><span title='2023-12-18 23:50:00 +0900 JST'>12月 18, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to dlt 入門 - ELT の Extract と Load を担う data load tool" href=https://soonraah.github.io/posts/what-is-dlt/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/matthew-feeney-Nwkh-n6l25w-unsplash.jpg alt=library></figure><header class=entry-header><h2 class=entry-hint-parent>読書メモ: DMBOK2 第12章 メタデータ管理</h2></header><div class=entry-content><p>このポストについて DMBOK2 を読み進めていくシリーズ。
今回は第12章「メタデータ管理」について。
仕事でメタデータを扱い始めたので読んでおきたかった。
以降、特に注釈のない引用は DMBOK2 第12章からの引用とする。
メタデータとは 一般的な説明としては「データに関するデータ」とよく言われている。
データに関するデータはすべてメタデータなので、メタデータはとても幅広い内容となっている。
DMBOK2 ではメタデータの説明として図書館の例を挙げている。
そこには数十万の書籍と雑誌があるのに、図書目録がない。図書目録がなければ、読者は特定の本や特定のトピックの検索を開始する方法さえ分からないかもしれない。図書目録は、必要な情報 (図書館が所有する本と資料、保管場所) を提供するだけでなく、利用者が様々な着眼点 (対象分野、著者、タイトル) から資料を見つけることを可能にする。 (中略) メタデータを持たない組織は、図書目録のない図書館のようなものである。
データという資産を管理するためにも、データを利用するためにも、リスクマネジメントのためにもメタデータは必要となる。
メタデータの種類 メタデータはビジネス、テクニカル、オペレーショナルの3つに分類することができる。
ビジネスメタデータ 主にデータの内容と状態に重点を置く。
IT からは独立している。
dataset, table, column の定義と説明 業務ルール、変換ルール、計算方法、導出方法 データモデル etc. テクニカルメタデータ 技術的詳細やシステムに関する情報。
主に IT に関連している。
物理 database の table, column の名称 column のプロパティ アクセス権 etc. オペレーショナルメタデータ データの処理とアクセスの詳細を示す。
運用で得られる情報とも言える。
バッチプログラムのジョブ実行ログ データの抽出とその結果などの履歴 運用スケジュールの以上 etc. 以上、各種のメタデータで例に挙げたのはあくまで一部であり、現実にはもっと多くのメタデータが存在する。
メタデータを管理する意義 図書館の例からもわかるとおり、メタデータなしではデータを管理することはできない。
信頼性が高く管理されたメタデータにより、次のようなことができるようになる。
データのコンテキストを提供し、それによりデータ品質を測定可能にして信頼性を向上させる 業務効率の向上、および古いデータや誤ったデータの利用防止 データ利用者とエンジニアの間のコミュニケーションの改善 法令遵守の支援 etc. メタデータの管理が不十分だと次のようなことが起こる。
一貫性のないデータ利用と誤った定義によるリスク メタデータは複製されて保管されることによる冗長性 利用者の信頼性低下 etc. メタデータアーキテクチャ メタデータの内容は幅広いがしたがってその取得元も幅広く、ビジネス用語集、BI ツール、モデリングツール、等々が挙げられる。
これらを何らかの方法で集約し、一箇所のメタデータポータルで閲覧できるようにする必要がある。
つまり「ここに来ればデータについてのことがわかる」という入り口を設けることになる。
そのためのアーキテクチャの構成が4つ挙げられている。
...</p></div><footer class=entry-footer><span title='2023-12-09 10:30:00 +0900 JST'>12月 9, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 読書メモ: DMBOK2 第12章 メタデータ管理" href=https://soonraah.github.io/posts/dmbok-chapter-12/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/christian-pfeifer-l6OraG-v0d8-unsplash.jpg alt=iceberg></figure><header class=entry-header><h2 class=entry-hint-parent>CDC + Apache Iceberg で Amazon Athena にデータを取り込む</h2></header><div class=entry-content><p>このポストについて このポストは Distributed computing Advent Calendar 2023 の3日目の記事になります。
1日目、2日目に続いて Apache Iceberg について書きますが、このポストでは Iceberg の実用例を書きます。
AWS DMS による CDC の結果を Apache Iceberg 形式にして Amazon Athena でクエリできるようにするという内容になります。
やっていることとしては Perform upserts in a data lake using Amazon Athena and Apache Iceberg | AWS Big Data Blog で紹介されている内容と近いですが、実務としての背景や工夫したところなどを書いていきます。
背景 私の所属する事業会社では日々プロダクトから様々なデータが発生しており、プロダクトの分析やレポーティング、ML など様々な用途で利用されている。
それを支える基盤としてデータ基盤が存在している。
データ基盤ではクエリエンジンとして Amazon Athena を使っている。
ストレージとしては S3 を使用しており、主に分析用として Parquet 形式でデータが置かれる。
ここに業務用の operational な database から日次でデータを取り込んでいる。
データソースは RDS (Aurora MySQL) であり、比較的大きなデータとなっている。
これまではこの RDS -> S3 のデータ取り込みには RDS の S3 snapshot export という機能を利用していた。
この機能では比較的簡単な設定により、バックアップ用のスナップショットの内容を S3 に export することができる。
ちなみに対象 database のスナップショットのサイズは数十 TB ある。
...</p></div><footer class=entry-footer><span title='2023-12-03 22:00:00 +0900 JST'>12月 3, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to CDC + Apache Iceberg で Amazon Athena にデータを取り込む" href=https://soonraah.github.io/posts/ingest-data-into-athena-by-cdc-and-iceberg/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/hansjorg-keller-p7av1ZhKGBQ-unsplash.jpg alt=council></figure><header class=entry-header><h2 class=entry-hint-parent>読書メモ: DMBOK2 第3章 データガバナンス</h2></header><div class=entry-content><p>このポストについて DMBOK2 を読み進めていくシリーズ。
今回は第3章「データガバナンス」について。
DAMA ホイール図において中心に置かれているので先に読んでおこうと思った次第。
以降、特に注釈のない引用は DMBOK2 第3章からの引用とする。
データガバナンスとは データガバナンス (DG) の定義は、データ資産の管理 (マネジメント) に対して職務権限を通し統制 (コントロール) することである。統制とは計画を立て、実行を監視し、徹底させることを指す。
この定義からデータガバナンスがなぜ DAMA ホイール図の中心に位置しているかがわかる。
データガバナンスにより周囲の各知識領域の計画や実施を統制するという建付けになる。
データガバナンス (DG) のゴールは組織がデータを資産として管理できるようにすることである。DG はデータを資産として管理するための原則、ポリシー、プロセス、フレームワーク、評価指標を提供し、組織の各階層レベルでデータマネジメントアクティビティを牽引する。
これを可能にするためにデータガバナンスは持続可能であり、業務プロセスに組み込まれており、測定可能になっている必要がある。
データガバナンス組織 次の組織構成が一般的なデータガバナンスモデルであるとのこと。
DMBOK2 データガバナンス組織構成
右側がデータマネジメントを実施するロールになっており、左側がデータガバナンスによりデータマネジメントさせるロールになっている。
データガバナンス運営委員会が組織のデータガバナンスの頂点となっており、最も権限が強い。
各部門にはデータガバナンス評議会 (DGC) が置かれており、これらがポリシー・評価指標の開発などのデータガバナンスの取り組みや課題、報告を管理する。
データガバナンスオフィス (DGO) はデータスチュワード (後述) などで構成され、企業レベルのデータ定義とデータマネジメントにフォーカスする。
大規模、かつデータマネジメントの意識が高い組織でないとこういった組織構成はなかなか作れないのではと思った。
ライト版の図も欲しいところ。
DMBOK2 データ問題の報告経路
ポリシーやステークホルダー利害の不一致、権限、データ品質などなど、データに関する問題は上記のような報告経路をたどる。
データスチュワード制 データスチュワード制はデータとプロセスの実行責任と結果責任を表す最も一般的な呼び名であり、データ資産の効率的な統制と利用を確かなものとする。
ちょっとこの説明ではイメージしにくいかもしれない。
データガバナンスの文脈において、データスチュワードは現場を含む組織の各レベルでデータガバナンスを効かせるための活動を行う実務者だと理解した。
データスチュワードという職務名があってもいいが、そうでなくてもよいらしい。
次のようなことをやる。
核となるメタデータの作成と管理 ルールと標準の文書化 データ品質の問題管理 データガバナンス運営アクティビティの実施 データスチュワードについては以下も参考。
参考: データスチュワードとは？役割やメリット、育成方法、選定基準について解説！ | trocco®(トロッコ) データポリシー データポリシーとは、データとインフォーメーションを生成し、取得し、健全性を保ち、セキュリティを守り、品質を維持し、利用することを統制する基本的なルールに、原則と管理糸を盛り込む指示である。
ポリシーはデータガバナンスの “What” を説明する。
通常はデータマネジメント・プロフェッショナルか業務ポリシー担当者が起草し、最終的に DGC により承認される。
...</p></div><footer class=entry-footer><span title='2023-11-19 17:30:00 +0900 JST'>11月 19, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 読書メモ: DMBOK2 第3章 データガバナンス" href=https://soonraah.github.io/posts/dmbok-chapter-3/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/nada-habashy-zruwsJh-lOI-unsplash.jpg alt=pyramid></figure><header class=entry-header><h2 class=entry-hint-parent>読書メモ: DMBOK2 第1章 データマネジメント</h2></header><div class=entry-content><p>このポストについて なんか個人的にデータマネジメントの機運が高まってきたので、ずっと積ん読していた DAMA-DMBOK を読んでいこうかなと。
で、せっかくなのでデータ関係の皆さんがよくやっているように自分としても読書メモをまとめてみようと思った。
内容を網羅するのではなく、現場のデータエンジニアとして活動した経験を踏まえて自分なりの観点でまとめてみたい。
今回は第1章「データマネジメント」で、それ以降は関心がある章をつまみ食い的に読んでいく。
DAMA-DMBOK とは DAMA とは DAta Management Association の略であり、
世界各地に80の支部を持ち、8,000名を越える会員を擁する全世界のデータ専門家のための国際的な非営利団体です。 特定のベンダーや技術、手法に依存しないことを前提として、データや情報、知識をエンタープライズの重要な資産として管理する必要性の理解を促し、この分野の成長を推進しております。
– 一般社団法人 データマネジメント協会 日本支部(DAMA Japan)
とのこと。
この DAMA が刊行しているのがデータマネジメント知識体系ガイド (The DAMA Guide to Data Management Body of Knowledge) であり、その略称が DMBOK である。
ＤＡＭＡ ＤＭＢＯＫは、データマネジメントプロフェッショナルにとって有益な資料かつ指針となることを目指し、データ管理のもっとも信頼できる入門書となるよう編集されています
– 一般社団法人 データマネジメント協会 日本支部(DAMA Japan)
IT 業界歴の長い人なら PMBOK というプロジェクトマネジメントについて書かれた本をご存知かもしれないが、あれのデータマネジメント版だと思っていい。
私としてはデータマネジメントの教科書的なものだと考えている。
...</p></div><footer class=entry-footer><span title='2023-11-13 22:30:00 +0900 JST'>11月 13, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 読書メモ: DMBOK2 第1章 データマネジメント" href=https://soonraah.github.io/posts/dmbok-chapter-1/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/annie-spratt-Tno1Zd3T6yY-unsplash.jpg alt=iceberg></figure><header class=entry-header><h2 class=entry-hint-parent>near real time で更新される Apache Iceberg の table のメンテナンス</h2></header><div class=entry-content><p>前回のポストでは merge on read で Apache Iceberg の table を near real time で更新するということを行った。
このポストではそのメンテナンスについて触れて、かつそれを実行してみる。
merge on read の課題 merge on read で table を更新する場合、copy on write の場合と違い table 全体を洗い替えする必要はなく差分のみを追記することになる。
したがって更新にかかる時間は copy on write よりも短くなる。
一方で merge on read の名のとおり読み出し時に積み重なった差分とベースを merge して最新の snapshot とするため、読み出しの速度は copy on write より遅くなる。
長時間更新され差分がたくさん存在しているとなおさら遅い。
なので
更新頻度が低く、参照頻度が高いユースケース -> copy on write 更新頻度が高く、参照頻度が低いユースケース -> merge on write という使い分けがよいとされている。
前回ポストの例では一晩更新を続けた後の merge on read の table に対して簡単な select 文を実行したところ、6分程度かかってしまった。
レコード数はたかだか128件程度であることを考えるとかなり遅いと言える。
このままでは使い物にならない。
...</p></div><footer class=entry-footer><span title='2023-05-28 09:00:00 +0900 JST'>5月 28, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to near real time で更新される Apache Iceberg の table のメンテナンス" href=https://soonraah.github.io/posts/maintain-iceberg-table-updated-in-near-real-time/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/danting-zhu-kWsT6p_S3cY-unsplash.jpg alt=iceberg></figure><header class=entry-header><h2 class=entry-hint-parent>Apache Iceberg の table を near real time で更新する</h2></header><div class=entry-content><p>Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。
Apache Iceberg とは Apache Iceberg (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。
特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。
これにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。
Apache Iceberg Iceberg Table Spec
詳しくは公式ドキュメントを参照のこと。
最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。
Flink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。
...</p></div><footer class=entry-footer><span title='2023-05-11 01:30:00 +0900 JST'>5月 11, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Iceberg の table を near real time で更新する" href=https://soonraah.github.io/posts/update-iceberg-table-in-near-real-time/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/sebastian-herrmann-NbtIDoFKGO8-unsplash.jpg alt=contract></figure><header class=entry-header><h2 class=entry-hint-parent>Data Contract について調べた</h2></header><div class=entry-content><p>データエンジニアリングの領域で少し前から目にするようになった “data contract” という言葉。
なんとなく今の業務で困っている課題の解決になりそうな気がしつつもよくわかっていなかったので調べてみた。
data contract について語られているいくつかのブログ記事などを参考にしている。
Data Contract とは データの schema というのはナマモノで、いろいろな理由で変更されることがある。
schema を変更する場合、その schema のデータ (table や log) が所属する単一のビジネス機能や application のドメインで行われることになる。
そのドメインの閉じた世界で考える分にはこれで問題ないのだが、DWH や data lake など組織レベルのデータ基盤でデータを流通していた場合はその先のことも考えないといけなくなる。
このようにチームを超える影響というのは、ビジネス機能に責任を持っているチームからは見えにくくなっていることが多い。
上流の application 側で schema を変更したら下流のデータ基盤の ETL 処理がぶっ壊れてしまった、というのはデータ基盤運用あるあるではないだろうか。
というところを解決して平和に過ごせるようにすることが data contract の主なモチベーションだと思われる。
“contract” は日本語で言うところの「契約」。
組織におけるデータ流通において、データの送り手である producer 側と受け手である consumer 側との間で合意した契約を遵守することにより、前述のような問題を避けることができるというのが data contract である。
組織内のデータの見通しがよくなったり、パイプラインを宣言的に開発することができるようになるというメリットもある。
エンジニアにとっては Datafold のブログ記事の例を読むとイメージしやすいかもしれない。
To provide another analogy, data contracts are what API is for the web services. Say we want to get data from Twitter. One way is to scrape it by downloading and parsing the HTML of Twitter’s webpage. This may work, but our scraper will likely break occasionally, if Twitter, for instance, changes a name of a CSS class or HTML structure. There is no contract between Twitter’s web page and our scraper. However, if we access the same data via Twitter’s API, we know exactly the structure of the response we’re going to get. An API has required inputs, predictable outputs, error codes, SLAs (service level agreements – e.g. uptime), and terms of use, and other important properties. Importantly, API is also versioned which helps ensure that changes to the API won’t break end user’s applications, and to take advantage of those changes users would graciously migrate to the new version.
...</p></div><footer class=entry-footer><span title='2023-04-08 17:00:00 +0900 JST'>4月 8, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Data Contract について調べた" href=https://soonraah.github.io/posts/looked-into-data-contracts/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://soonraah.github.io/posts/>«&nbsp;前へ&nbsp;
</a><a class=next href=https://soonraah.github.io/posts/page/3/>次へ&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://soonraah.github.io/>Froglog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>