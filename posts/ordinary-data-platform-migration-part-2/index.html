<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ふつうのデータ基盤移行 - Part 2. 技術選定編 | Froglog</title>
<meta name=keywords content="data platform,Databricks,技術選定"><meta name=description content="このポストについて
データ基盤移行について書いていくシリーズです。
前回は戦略策定 (実際は戦術) までのところを書きました。
今回はそれを踏まえた技術選定、およびその後の予算獲得について書いていきます。
また、こちらは Databricks Advent Calendar 2024 シリーズ 2 の16日目の記事にもなっています。
はいそうです、出落ちですが技術選定として Databricks を選ぶことになります。
スコープ
前回 Part 1. 戦略策定編では概ねのロードマップが決まり、まずはデータ基盤のリアーキテクチャをやっていくことになりました。
リアーキテクチャにおいてはどのような技術スタックを使っていくかが重要な選択になります。
データ基盤においてはデータ処理のためのストレージとコンピュートの選択がとても重要です。
以降ではこの2つをあわせた DWH 製品の選定について書いていきます。
「DHW 製品」という言葉は適切ではないかもしれませんが、ここではストレージ + コンピュートが組み合わさったものぐらいに考えてください。
もちろんデータ基盤には他の技術要素もあり、それらも軽くない選択ですがこのポストでは割愛します。
(気が向いたら別記事で書くかも)
技術選定の目的
まず何のために技術スタックの置き換え、ひいては技術選定をするかの目的を明確にしておく必要があります。
旧データ基盤では次のような技術スタックになっていました。

ストレージ: S3
コンピュート: Glue Job, Athena

この構成には次のような課題がありました。
主にこれらの課題を解決するために DWH 製品の乗り換えを検討することになりました。

dbt との親和性の低さ
一貫したガバナンスの欠如

dbt との親和性の低さ
前回作成したロードマップにおいて、dbt の導入が課題解決における重要なポイントになっています。
dbt の周辺エコシステムがデータ基盤の課題の解決に大きく貢献すると考えています。
また、データパイプラインの開発・運用の負荷も dbt 導入で軽減できそうです。
旧データ基盤では Glue Job と Athena クエリを組み合わせた複雑なパイプラインになっており、table を1つ追加するだけでもいろいろなコードに手をいれる必要があります。
ほぼ SQL で実装でき、かつ宣言的にパイプライン構築できる dbt は魅力的です。
仮に旧データ基盤に dbt を導入するとなると dbt-athena を使うことになります。
ただ dbt による Athena のサポートはやや弱く、dbt-athena はコミュニティ版から少し前に移管されたものですし、これを書いている2024年12月の時点で dbt Cloud の Athena のサポートはまだプレビューです。
反論がある方もいらっしゃるかもしれませんが、モダンなデータ基盤構築において Athena はやや影が薄い印象があり、dbt のサポートの弱さもこれが原因だと思います。
(ただし直近の re:Invent 2024 の内容からすると潮目が変わる可能性もありそうです)"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=ja href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/"><meta property="og:site_name" content="Froglog"><meta property="og:title" content="ふつうのデータ基盤移行 - Part 2. 技術選定編"><meta property="og:description" content="このポストについて データ基盤移行について書いていくシリーズです。
前回は戦略策定 (実際は戦術) までのところを書きました。
今回はそれを踏まえた技術選定、およびその後の予算獲得について書いていきます。
また、こちらは Databricks Advent Calendar 2024 シリーズ 2 の16日目の記事にもなっています。
はいそうです、出落ちですが技術選定として Databricks を選ぶことになります。
スコープ 前回 Part 1. 戦略策定編では概ねのロードマップが決まり、まずはデータ基盤のリアーキテクチャをやっていくことになりました。
リアーキテクチャにおいてはどのような技術スタックを使っていくかが重要な選択になります。
データ基盤においてはデータ処理のためのストレージとコンピュートの選択がとても重要です。
以降ではこの2つをあわせた DWH 製品の選定について書いていきます。
「DHW 製品」という言葉は適切ではないかもしれませんが、ここではストレージ + コンピュートが組み合わさったものぐらいに考えてください。
もちろんデータ基盤には他の技術要素もあり、それらも軽くない選択ですがこのポストでは割愛します。
(気が向いたら別記事で書くかも)
技術選定の目的 まず何のために技術スタックの置き換え、ひいては技術選定をするかの目的を明確にしておく必要があります。
旧データ基盤では次のような技術スタックになっていました。
ストレージ: S3 コンピュート: Glue Job, Athena この構成には次のような課題がありました。
主にこれらの課題を解決するために DWH 製品の乗り換えを検討することになりました。
dbt との親和性の低さ 一貫したガバナンスの欠如 dbt との親和性の低さ 前回作成したロードマップにおいて、dbt の導入が課題解決における重要なポイントになっています。
dbt の周辺エコシステムがデータ基盤の課題の解決に大きく貢献すると考えています。
また、データパイプラインの開発・運用の負荷も dbt 導入で軽減できそうです。
旧データ基盤では Glue Job と Athena クエリを組み合わせた複雑なパイプラインになっており、table を1つ追加するだけでもいろいろなコードに手をいれる必要があります。
ほぼ SQL で実装でき、かつ宣言的にパイプライン構築できる dbt は魅力的です。
仮に旧データ基盤に dbt を導入するとなると dbt-athena を使うことになります。
ただ dbt による Athena のサポートはやや弱く、dbt-athena はコミュニティ版から少し前に移管されたものですし、これを書いている2024年12月の時点で dbt Cloud の Athena のサポートはまだプレビューです。
反論がある方もいらっしゃるかもしれませんが、モダンなデータ基盤構築において Athena はやや影が薄い印象があり、dbt のサポートの弱さもこれが原因だと思います。
(ただし直近の re:Invent 2024 の内容からすると潮目が変わる可能性もありそうです)"><meta property="og:locale" content="ja"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-12-16T00:30:00+09:00"><meta property="article:modified_time" content="2024-12-16T00:30:00+09:00"><meta property="article:tag" content="Data Platform"><meta property="article:tag" content="Databricks"><meta property="article:tag" content="技術選定"><meta property="og:image" content="https://soonraah.github.io/image/ordinary-data-plagform-migration/technology-selection.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/ordinary-data-plagform-migration/technology-selection.jpg"><meta name=twitter:title content="ふつうのデータ基盤移行 - Part 2. 技術選定編"><meta name=twitter:description content="このポストについて
データ基盤移行について書いていくシリーズです。
前回は戦略策定 (実際は戦術) までのところを書きました。
今回はそれを踏まえた技術選定、およびその後の予算獲得について書いていきます。
また、こちらは Databricks Advent Calendar 2024 シリーズ 2 の16日目の記事にもなっています。
はいそうです、出落ちですが技術選定として Databricks を選ぶことになります。
スコープ
前回 Part 1. 戦略策定編では概ねのロードマップが決まり、まずはデータ基盤のリアーキテクチャをやっていくことになりました。
リアーキテクチャにおいてはどのような技術スタックを使っていくかが重要な選択になります。
データ基盤においてはデータ処理のためのストレージとコンピュートの選択がとても重要です。
以降ではこの2つをあわせた DWH 製品の選定について書いていきます。
「DHW 製品」という言葉は適切ではないかもしれませんが、ここではストレージ + コンピュートが組み合わさったものぐらいに考えてください。
もちろんデータ基盤には他の技術要素もあり、それらも軽くない選択ですがこのポストでは割愛します。
(気が向いたら別記事で書くかも)
技術選定の目的
まず何のために技術スタックの置き換え、ひいては技術選定をするかの目的を明確にしておく必要があります。
旧データ基盤では次のような技術スタックになっていました。

ストレージ: S3
コンピュート: Glue Job, Athena

この構成には次のような課題がありました。
主にこれらの課題を解決するために DWH 製品の乗り換えを検討することになりました。

dbt との親和性の低さ
一貫したガバナンスの欠如

dbt との親和性の低さ
前回作成したロードマップにおいて、dbt の導入が課題解決における重要なポイントになっています。
dbt の周辺エコシステムがデータ基盤の課題の解決に大きく貢献すると考えています。
また、データパイプラインの開発・運用の負荷も dbt 導入で軽減できそうです。
旧データ基盤では Glue Job と Athena クエリを組み合わせた複雑なパイプラインになっており、table を1つ追加するだけでもいろいろなコードに手をいれる必要があります。
ほぼ SQL で実装でき、かつ宣言的にパイプライン構築できる dbt は魅力的です。
仮に旧データ基盤に dbt を導入するとなると dbt-athena を使うことになります。
ただ dbt による Athena のサポートはやや弱く、dbt-athena はコミュニティ版から少し前に移管されたものですし、これを書いている2024年12月の時点で dbt Cloud の Athena のサポートはまだプレビューです。
反論がある方もいらっしゃるかもしれませんが、モダンなデータ基盤構築において Athena はやや影が薄い印象があり、dbt のサポートの弱さもこれが原因だと思います。
(ただし直近の re:Invent 2024 の内容からすると潮目が変わる可能性もありそうです)"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://soonraah.github.io/posts/"},{"@type":"ListItem","position":2,"name":"ふつうのデータ基盤移行 - Part 2. 技術選定編","item":"https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ふつうのデータ基盤移行 - Part 2. 技術選定編","name":"ふつうのデータ基盤移行 - Part 2. 技術選定編","description":"このポストについて データ基盤移行について書いていくシリーズです。\n前回は戦略策定 (実際は戦術) までのところを書きました。\n今回はそれを踏まえた技術選定、およびその後の予算獲得について書いていきます。\nまた、こちらは Databricks Advent Calendar 2024 シリーズ 2 の16日目の記事にもなっています。\nはいそうです、出落ちですが技術選定として Databricks を選ぶことになります。\nスコープ 前回 Part 1. 戦略策定編では概ねのロードマップが決まり、まずはデータ基盤のリアーキテクチャをやっていくことになりました。\nリアーキテクチャにおいてはどのような技術スタックを使っていくかが重要な選択になります。\nデータ基盤においてはデータ処理のためのストレージとコンピュートの選択がとても重要です。\n以降ではこの2つをあわせた DWH 製品の選定について書いていきます。\n「DHW 製品」という言葉は適切ではないかもしれませんが、ここではストレージ + コンピュートが組み合わさったものぐらいに考えてください。\nもちろんデータ基盤には他の技術要素もあり、それらも軽くない選択ですがこのポストでは割愛します。\n(気が向いたら別記事で書くかも)\n技術選定の目的 まず何のために技術スタックの置き換え、ひいては技術選定をするかの目的を明確にしておく必要があります。\n旧データ基盤では次のような技術スタックになっていました。\nストレージ: S3 コンピュート: Glue Job, Athena この構成には次のような課題がありました。\n主にこれらの課題を解決するために DWH 製品の乗り換えを検討することになりました。\ndbt との親和性の低さ 一貫したガバナンスの欠如 dbt との親和性の低さ 前回作成したロードマップにおいて、dbt の導入が課題解決における重要なポイントになっています。\ndbt の周辺エコシステムがデータ基盤の課題の解決に大きく貢献すると考えています。\nまた、データパイプラインの開発・運用の負荷も dbt 導入で軽減できそうです。\n旧データ基盤では Glue Job と Athena クエリを組み合わせた複雑なパイプラインになっており、table を1つ追加するだけでもいろいろなコードに手をいれる必要があります。\nほぼ SQL で実装でき、かつ宣言的にパイプライン構築できる dbt は魅力的です。\n仮に旧データ基盤に dbt を導入するとなると dbt-athena を使うことになります。\nただ dbt による Athena のサポートはやや弱く、dbt-athena はコミュニティ版から少し前に移管されたものですし、これを書いている2024年12月の時点で dbt Cloud の Athena のサポートはまだプレビューです。\n反論がある方もいらっしゃるかもしれませんが、モダンなデータ基盤構築において Athena はやや影が薄い印象があり、dbt のサポートの弱さもこれが原因だと思います。\n(ただし直近の re:Invent 2024 の内容からすると潮目が変わる可能性もありそうです)\n","keywords":["data platform","Databricks","技術選定"],"articleBody":"このポストについて データ基盤移行について書いていくシリーズです。\n前回は戦略策定 (実際は戦術) までのところを書きました。\n今回はそれを踏まえた技術選定、およびその後の予算獲得について書いていきます。\nまた、こちらは Databricks Advent Calendar 2024 シリーズ 2 の16日目の記事にもなっています。\nはいそうです、出落ちですが技術選定として Databricks を選ぶことになります。\nスコープ 前回 Part 1. 戦略策定編では概ねのロードマップが決まり、まずはデータ基盤のリアーキテクチャをやっていくことになりました。\nリアーキテクチャにおいてはどのような技術スタックを使っていくかが重要な選択になります。\nデータ基盤においてはデータ処理のためのストレージとコンピュートの選択がとても重要です。\n以降ではこの2つをあわせた DWH 製品の選定について書いていきます。\n「DHW 製品」という言葉は適切ではないかもしれませんが、ここではストレージ + コンピュートが組み合わさったものぐらいに考えてください。\nもちろんデータ基盤には他の技術要素もあり、それらも軽くない選択ですがこのポストでは割愛します。\n(気が向いたら別記事で書くかも)\n技術選定の目的 まず何のために技術スタックの置き換え、ひいては技術選定をするかの目的を明確にしておく必要があります。\n旧データ基盤では次のような技術スタックになっていました。\nストレージ: S3 コンピュート: Glue Job, Athena この構成には次のような課題がありました。\n主にこれらの課題を解決するために DWH 製品の乗り換えを検討することになりました。\ndbt との親和性の低さ 一貫したガバナンスの欠如 dbt との親和性の低さ 前回作成したロードマップにおいて、dbt の導入が課題解決における重要なポイントになっています。\ndbt の周辺エコシステムがデータ基盤の課題の解決に大きく貢献すると考えています。\nまた、データパイプラインの開発・運用の負荷も dbt 導入で軽減できそうです。\n旧データ基盤では Glue Job と Athena クエリを組み合わせた複雑なパイプラインになっており、table を1つ追加するだけでもいろいろなコードに手をいれる必要があります。\nほぼ SQL で実装でき、かつ宣言的にパイプライン構築できる dbt は魅力的です。\n仮に旧データ基盤に dbt を導入するとなると dbt-athena を使うことになります。\nただ dbt による Athena のサポートはやや弱く、dbt-athena はコミュニティ版から少し前に移管されたものですし、これを書いている2024年12月の時点で dbt Cloud の Athena のサポートはまだプレビューです。\n反論がある方もいらっしゃるかもしれませんが、モダンなデータ基盤構築において Athena はやや影が薄い印象があり、dbt のサポートの弱さもこれが原因だと思います。\n(ただし直近の re:Invent 2024 の内容からすると潮目が変わる可能性もありそうです)\nしたがってより存在感があり、エコシステムに受け入れられている DWH 製品にどこかのタイミングで乗り換えたいと以前から考えていました。\nつまりプロダクトレベルの data gravity にあやかりたい。\n一貫したガバナンスの欠如 旧データ基盤の技術スタックは寄せ集め感が強く、うまく表現できませんが全体として調和した上でガバナンスを持って開発・運用するのが難しいと感じていました。\n複数の AWS サービスを組み合わせて考える必要があり、また初期開発当時のチームの開発スキルの問題もあり、開発上も運用上も一貫したガバナンスを持つことが困難でした。\nモダンな DWH 製品ではこのあたりの配慮があります。\n技術選定で考慮したいこと 技術選定では上記の課題を解決できるように DWH 製品を選ぶわけですが、加えて一般的に DWH 製品に求められる観点も考慮する必要があります。\n次のような観点も見ていきます。\n人的・金銭的コスト (初期導入時／運用時) バックアップとリカバリ スケーラビリティ データ統合のしやすさ セキュリティ UI/UX エコシステム サポート 技術選定の実施 技術選定の流れ 全体としては次のような流れで技術選定を行いました。\nflowchart TD first[\"一次調査 (スクリーニング)\"] second[\"二次調査 (PoC)\"] decision[\"技術スタックの決定\"] first --\u003e second second --\u003e decision 一次調査 (スクリーニング) 一次調査では軽めの調査で広い候補から少数の候補へとスクリーニングを行います。\nここでは旧データ基盤の維持も含め、6つの候補が挙げられました。\n6つの候補は一般的によく利用されているものであり、データエンジニアの皆さんがぱっと想像できるようなアレとかアレとかです。\n一次調査は公式ドキュメントなどのカタログスペックでの調査が主となっており、前述の観点で候補を比較しました。\n結果として Databricks および製品 A に候補が絞られました。\n(ここで AI が作ったタイトル画像をもう一度見ていただきたいのですが、朱色のレンガは焼いて作るので火属性だし、水色の、あの、あれはもちろん氷属性ですね)\n二次調査 (PoC) 二次調査では一次調査の結果を受け、2つの候補でそれぞれ PoC を行い比較します。\nPoC では実際に DWH 製品を導入したことを想定し、DWH 上に dbt でデータパイプラインを構築します。\n業務で使う代表的なワークロードの一部を再現しました。\n特に処理のコストパフォーマンスはワークロード次第なので、組織でよく使うワークロードを想定して実際に動かしてみないとわかりません。\nまた UI/UX の使い勝手なども実際に使ってみないとわかりません。\n使い勝手的なところはアナリストにも評価していただきました。\nPoC の段階ではまだ IaC は導入せず、UI などから必要なリソースを用意しました。\nデータエンジニア2名でそれぞれ Databricks、製品 A で環境を構築し、2〜3週間ぐらいで検証しました。\nちなみにこのとき両製品で同じ dbt プロジェクトを使っていました。\nこのように dbt は比較的高い相互運用性があり、何かあったときの DWH の変更のハードルを下げてくれるということを実感しました。\n(クエリの書き方次第ではある)\n技術スタックの決定 さて、このようにして両製品を比較したわけですが、もともと想定していた観点ではそこまで大きな違いはありませんでした。\nとはいえ以下の点で優れていたことにより Databricks の採用を決めました。\nコストパフォーマンス 我々の代表的なワークロードでは Databricks の方が若干コストが安かった これはワークロードによっても変わると思われる オープン性 データ実体は Delta Lake という open table format また顧客 (=我々) 管理の S3 bucket に保存されるので透明性が高く、データの囲い込みがない OSS 志向も強い 製品 A も open table format を選択できるが、パフォーマンスで劣るとの話があった アナリストからの評価 これはちょっとタイミングの問題もあるのだが、調査時点では以下のような機能が Databricks のみにあってアナリストからの高評価となった SQL の Git 管理機能 Genie などの AI まわり もともと Redash を使っていたので親和性が高いというのもあったかも DatabricksがRedashを買収してデータサイエンティストのためのデータ視覚化を充実 (TechCrunch Japan) とまあ現場レベルではこれで行きましょうという合意ができたわけですが、Databricks を使えるようにするため今度は予算を獲得する必要があります。\n予算獲得 予算獲得までの流れ どのように予算を獲得するかは組織に大きく依存するでしょう。\nウチの場合は以下のような流れでした。\nflowchart TD estimate[\"費用見積\"] stakeholder[\"ステークホルダーへの説明\"] approval[\"承認会議\"] estimate --\u003e stakeholder stakeholder --\u003e approval 費用見積 技術スタックが決まったので費用を見積もります。\n厳密に見積もるのは難しいですが、ある程度の仮定をおいて計算します。\n通常のデータ基盤であればストレージとコンピュートの費用が中心になるでしょう。\n両者はともにデータ量に依存します。\n事業計画にもとづいてデータ量の変化を仮定し、それに対してストレージとコンピュートの費用の見積を出しました。\nまた、費用については新旧のデータ基盤の並行稼働のことも考慮する必要があります。\nバチッと一瞬で切り替えられるわけではなく、ある程度の期間は2つのデータ基盤を並行して運用することになります。\nその間は余分に費用がかかってしまいます。\nステークホルダーへの説明 次に社内のステークホルダーへの説明を行いました。\nまずは一次上長であるマネージャにやりたいことと費用見積の詳細について説明します。\nPart 1 でも少し触れていますが、マネージャはデータエンジニアリングの知見はあまりなかったため、それなりの説明コストがかかりました。\nとはいえちゃんと理解しようとしてくださっていたのでそこは感謝です。\n次にデータ基盤に対する社内のデータプロバイダー、コンシューマーについてやりたいことやその影響の説明をしました。\n3回ぐらい大きめのミーティングを開催して説明しました。\nここにも準備など含めそれなりの時間がかかっています。\n正直、当初はこのステップは本当に必要なのか？と考えていました。\n弊社ぐらいの小さい組織であれば、リーダーシップを持った人が責任と権限を持ち、スピード感を持って決めていく方がいいはずです。\nステークホルダーには決まった後に伝えればいいだろうと。\nただ後になってから、これは必要なステップだったと思うに至りました。\n承認会議 ここまでやってようやく本丸の承認会議です。\n決裁権を持つエライ人の前で説明して承認を得るという会議を開催しました。\n結論として、割とすんなりと承認を得ることができました。\n「たぶんやった方がいいんだろうけど」、その場でエライ人が言ったこの言葉が象徴的でした。\n弊社の場合決裁権を持つマネジメント層にデータまわりに詳しい人がいません。\nもちろん費用見積はちゃんと評価されるわけですが、その上で雰囲気で決まっていく感がありました。(JTC)\nその雰囲気を醸成するためにステークホルダーへの説明が必要だったわけです。\n組織にもよるのでしょうが、データエンジニアをやってるとこのような政治っぽいことを考えることになる場合もあるのだと理解しました。\nこのあたり前述のマネージャにかなり助けられました。\nここまでの課題と今後の対策 Part 1 とかぶりますが、やはりマネジメント層のデータまわりのリテラシーは組織としての課題です。\n外的要因により必要にかられるようなことがない限り、少しずつ啓蒙していくしかないかなと考えています。\nDatabricks について Advent Calendar の記事だということもあり Databricks についてもう少し触れておきます。\nこれを書いている時点では PoC のときよりは Databricks に触っており、その中で体感した良かったところを挙げておきます。\n(あくまである一社での例です)\nOSS ベースであることによる透明性 データ処理は Apache Spark 互換のエンジン Photon で実行される ベースは OSS の Spark なので、Spark の知見があれば実行計画を見るなどして処理のイメージがつきやすい 最適化のポイントもわかりやすい (と思っている) 一貫したガバナンス ML model 等の data product も table などの database object と同じように権限管理できる 同じ user でも workspace 単位でアクセス可能なリソースを制限できる PoC の時点でもカタログとしてわかっていたが、触ってみて実感したところがある AI まわり ChatGPT-like にデータについての問い合わせが行える Genie Nootebook でエラーを出したときに原因や修正案を示してくれる LLM の評価や開発の機能 手厚いサポート 弊社に対して担当がついており、Slack で質問に回答していただける A◯S のサポートと比べても回答のスピード・質ともに高い いつもお世話になってます 🙇‍♂️ とはいえまだすべての機能を確認できていないし、そもそも結構なペースで機能が増えています。\n個人的には Databricks LakeFlow のあたりに期待しています。\n次回予告 次回はまだ未定ですが、何か開発関連の話を書くつもりです。\n以上、現場からでした。\n","wordCount":"369","inLanguage":"ja","image":"https://soonraah.github.io/image/ordinary-data-plagform-migration/technology-selection.jpg","datePublished":"2024-12-16T00:30:00+09:00","dateModified":"2024-12-16T00:30:00+09:00","author":{"@type":"Person","name":"soonraah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/"},"publisher":{"@type":"Organization","name":"Froglog","logo":{"@type":"ImageObject","url":"https://soonraah.github.io/favicon2.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soonraah.github.io/>ホーム</a>&nbsp;»&nbsp;<a href=https://soonraah.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">ふつうのデータ基盤移行 - Part 2. 技術選定編</h1><div class=post-meta><span title='2024-12-16 00:30:00 +0900 JST'>12月 16, 2024</span>&nbsp;·&nbsp;soonraah</div></header><figure class=entry-cover><img loading=eager src=https://soonraah.github.io/image/ordinary-data-plagform-migration/technology-selection.jpg alt="technology selection"><figcaption>Image by OpenAI DALL·E</figcaption></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目次</span></summary><div class=inner><ul><li><a href=#%e3%81%93%e3%81%ae%e3%83%9d%e3%82%b9%e3%83%88%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6 aria-label=このポストについて>このポストについて</a></li><li><a href=#%e3%82%b9%e3%82%b3%e3%83%bc%e3%83%97 aria-label=スコープ>スコープ</a></li><li><a href=#%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e3%81%ae%e7%9b%ae%e7%9a%84 aria-label=技術選定の目的>技術選定の目的</a><ul><li><a href=#dbt-%e3%81%a8%e3%81%ae%e8%a6%aa%e5%92%8c%e6%80%a7%e3%81%ae%e4%bd%8e%e3%81%95 aria-label="dbt との親和性の低さ">dbt との親和性の低さ</a></li><li><a href=#%e4%b8%80%e8%b2%ab%e3%81%97%e3%81%9f%e3%82%ac%e3%83%90%e3%83%8a%e3%83%b3%e3%82%b9%e3%81%ae%e6%ac%a0%e5%a6%82 aria-label=一貫したガバナンスの欠如>一貫したガバナンスの欠如</a></li><li><a href=#%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e3%81%a7%e8%80%83%e6%85%ae%e3%81%97%e3%81%9f%e3%81%84%e3%81%93%e3%81%a8 aria-label=技術選定で考慮したいこと>技術選定で考慮したいこと</a></li></ul></li><li><a href=#%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e3%81%ae%e5%ae%9f%e6%96%bd aria-label=技術選定の実施>技術選定の実施</a><ul><li><a href=#%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e3%81%ae%e6%b5%81%e3%82%8c aria-label=技術選定の流れ>技術選定の流れ</a></li><li><a href=#%e4%b8%80%e6%ac%a1%e8%aa%bf%e6%9f%bb-%e3%82%b9%e3%82%af%e3%83%aa%e3%83%bc%e3%83%8b%e3%83%b3%e3%82%b0 aria-label="一次調査 (スクリーニング)">一次調査 (スクリーニング)</a></li><li><a href=#%e4%ba%8c%e6%ac%a1%e8%aa%bf%e6%9f%bb-poc aria-label="二次調査 (PoC)">二次調査 (PoC)</a></li><li><a href=#%e6%8a%80%e8%a1%93%e3%82%b9%e3%82%bf%e3%83%83%e3%82%af%e3%81%ae%e6%b1%ba%e5%ae%9a aria-label=技術スタックの決定>技術スタックの決定</a></li></ul></li><li><a href=#%e4%ba%88%e7%ae%97%e7%8d%b2%e5%be%97 aria-label=予算獲得>予算獲得</a><ul><li><a href=#%e4%ba%88%e7%ae%97%e7%8d%b2%e5%be%97%e3%81%be%e3%81%a7%e3%81%ae%e6%b5%81%e3%82%8c aria-label=予算獲得までの流れ>予算獲得までの流れ</a></li><li><a href=#%e8%b2%bb%e7%94%a8%e8%a6%8b%e7%a9%8d aria-label=費用見積>費用見積</a></li><li><a href=#%e3%82%b9%e3%83%86%e3%83%bc%e3%82%af%e3%83%9b%e3%83%ab%e3%83%80%e3%83%bc%e3%81%b8%e3%81%ae%e8%aa%ac%e6%98%8e aria-label=ステークホルダーへの説明>ステークホルダーへの説明</a></li><li><a href=#%e6%89%bf%e8%aa%8d%e4%bc%9a%e8%ad%b0 aria-label=承認会議>承認会議</a></li></ul></li><li><a href=#%e3%81%93%e3%81%93%e3%81%be%e3%81%a7%e3%81%ae%e8%aa%b2%e9%a1%8c%e3%81%a8%e4%bb%8a%e5%be%8c%e3%81%ae%e5%af%be%e7%ad%96 aria-label=ここまでの課題と今後の対策>ここまでの課題と今後の対策</a></li><li><a href=#databricks-%e3%81%ab%e3%81%a4%e3%81%84%e3%81%a6 aria-label="Databricks について">Databricks について</a></li><li><a href=#%e6%ac%a1%e5%9b%9e%e4%ba%88%e5%91%8a aria-label=次回予告>次回予告</a></li></ul></div></details></div><div class=post-content><h2 id=このポストについて>このポストについて<a hidden class=anchor aria-hidden=true href=#このポストについて>#</a></h2><p>データ基盤移行について書いていくシリーズです。<br>前回は戦略策定 (実際は戦術) までのところを書きました。<br>今回はそれを踏まえた技術選定、およびその後の予算獲得について書いていきます。</p><p>また、こちらは <a href=https://qiita.com/advent-calendar/2024/databricks>Databricks Advent Calendar 2024</a> シリーズ 2 の16日目の記事にもなっています。<br>はいそうです、出落ちですが技術選定として Databricks を選ぶことになります。</p><h2 id=スコープ>スコープ<a hidden class=anchor aria-hidden=true href=#スコープ>#</a></h2><p>前回 <a href=/posts/ordinary-data-platform-migration-part-1/>Part 1. 戦略策定編</a>では概ねのロードマップが決まり、まずはデータ基盤のリアーキテクチャをやっていくことになりました。<br>リアーキテクチャにおいてはどのような技術スタックを使っていくかが重要な選択になります。<br>データ基盤においてはデータ処理のためのストレージとコンピュートの選択がとても重要です。<br>以降ではこの2つをあわせた DWH 製品の選定について書いていきます。<br>「DHW 製品」という言葉は適切ではないかもしれませんが、ここではストレージ + コンピュートが組み合わさったものぐらいに考えてください。</p><p>もちろんデータ基盤には他の技術要素もあり、それらも軽くない選択ですがこのポストでは割愛します。<br>(気が向いたら別記事で書くかも)</p><h2 id=技術選定の目的>技術選定の目的<a hidden class=anchor aria-hidden=true href=#技術選定の目的>#</a></h2><p>まず何のために技術スタックの置き換え、ひいては技術選定をするかの目的を明確にしておく必要があります。<br>旧データ基盤では次のような技術スタックになっていました。</p><ul><li>ストレージ: S3</li><li>コンピュート: Glue Job, Athena</li></ul><p>この構成には次のような課題がありました。<br>主にこれらの課題を解決するために DWH 製品の乗り換えを検討することになりました。</p><ul><li>dbt との親和性の低さ</li><li>一貫したガバナンスの欠如</li></ul><h3 id=dbt-との親和性の低さ>dbt との親和性の低さ<a hidden class=anchor aria-hidden=true href=#dbt-との親和性の低さ>#</a></h3><p>前回作成した<a href=/posts/ordinary-data-platform-migration-part-1/#%e3%83%ad%e3%83%bc%e3%83%89%e3%83%9e%e3%83%83%e3%83%97%e4%bd%9c%e6%88%90>ロードマップ</a>において、dbt の導入が課題解決における重要なポイントになっています。<br>dbt の周辺エコシステムがデータ基盤の課題の解決に大きく貢献すると考えています。</p><p>また、データパイプラインの開発・運用の負荷も dbt 導入で軽減できそうです。<br>旧データ基盤では Glue Job と Athena クエリを組み合わせた複雑なパイプラインになっており、table を1つ追加するだけでもいろいろなコードに手をいれる必要があります。<br>ほぼ SQL で実装でき、かつ宣言的にパイプライン構築できる dbt は魅力的です。</p><p>仮に旧データ基盤に dbt を導入するとなると <a href=https://docs.getdbt.com/docs/core/connect-data-platform/athena-setup>dbt-athena</a> を使うことになります。<br>ただ dbt による Athena のサポートはやや弱く、dbt-athena はコミュニティ版から少し前に移管されたものですし、これを書いている2024年12月の時点で dbt Cloud の Athena のサポートはまだプレビューです。<br>反論がある方もいらっしゃるかもしれませんが、モダンなデータ基盤構築において Athena はやや影が薄い印象があり、dbt のサポートの弱さもこれが原因だと思います。<br>(ただし直近の re:Invent 2024 の内容からすると潮目が変わる可能性もありそうです)</p><p>したがってより存在感があり、エコシステムに受け入れられている DWH 製品にどこかのタイミングで乗り換えたいと以前から考えていました。<br>つまりプロダクトレベルの data gravity にあやかりたい。</p><h3 id=一貫したガバナンスの欠如>一貫したガバナンスの欠如<a hidden class=anchor aria-hidden=true href=#一貫したガバナンスの欠如>#</a></h3><p>旧データ基盤の技術スタックは寄せ集め感が強く、うまく表現できませんが全体として調和した上でガバナンスを持って開発・運用するのが難しいと感じていました。<br>複数の AWS サービスを組み合わせて考える必要があり、また初期開発当時のチームの開発スキルの問題もあり、開発上も運用上も一貫したガバナンスを持つことが困難でした。<br>モダンな DWH 製品ではこのあたりの配慮があります。</p><h3 id=技術選定で考慮したいこと>技術選定で考慮したいこと<a hidden class=anchor aria-hidden=true href=#技術選定で考慮したいこと>#</a></h3><p>技術選定では上記の課題を解決できるように DWH 製品を選ぶわけですが、加えて一般的に DWH 製品に求められる観点も考慮する必要があります。<br>次のような観点も見ていきます。</p><ul><li>人的・金銭的コスト (初期導入時／運用時)</li><li>バックアップとリカバリ</li><li>スケーラビリティ</li><li>データ統合のしやすさ</li><li>セキュリティ</li><li>UI/UX</li><li>エコシステム</li><li>サポート</li></ul><h2 id=技術選定の実施>技術選定の実施<a hidden class=anchor aria-hidden=true href=#技術選定の実施>#</a></h2><h3 id=技術選定の流れ>技術選定の流れ<a hidden class=anchor aria-hidden=true href=#技術選定の流れ>#</a></h3><p>全体としては次のような流れで技術選定を行いました。</p><pre class=mermaid>flowchart TD
    first["一次調査 (スクリーニング)"]
    second["二次調査 (PoC)"]
    decision["技術スタックの決定"]

    first --> second
    second --> decision
</pre><h3 id=一次調査-スクリーニング>一次調査 (スクリーニング)<a hidden class=anchor aria-hidden=true href=#一次調査-スクリーニング>#</a></h3><p>一次調査では軽めの調査で広い候補から少数の候補へとスクリーニングを行います。<br>ここでは旧データ基盤の維持も含め、6つの候補が挙げられました。<br>6つの候補は一般的によく利用されているものであり、データエンジニアの皆さんがぱっと想像できるようなアレとかアレとかです。</p><p>一次調査は公式ドキュメントなどのカタログスペックでの調査が主となっており、前述の観点で候補を比較しました。<br>結果として Databricks および製品 A に候補が絞られました。</p><p>(ここで AI が作ったタイトル画像をもう一度見ていただきたいのですが、朱色のレンガは焼いて作るので火属性だし、水色の、あの、あれはもちろん氷属性ですね)</p><h3 id=二次調査-poc>二次調査 (PoC)<a hidden class=anchor aria-hidden=true href=#二次調査-poc>#</a></h3><p>二次調査では一次調査の結果を受け、2つの候補でそれぞれ PoC を行い比較します。<br>PoC では実際に DWH 製品を導入したことを想定し、DWH 上に dbt でデータパイプラインを構築します。<br>業務で使う代表的なワークロードの一部を再現しました。</p><p>特に処理のコストパフォーマンスはワークロード次第なので、組織でよく使うワークロードを想定して実際に動かしてみないとわかりません。<br>また UI/UX の使い勝手なども実際に使ってみないとわかりません。<br>使い勝手的なところはアナリストにも評価していただきました。</p><p>PoC の段階ではまだ IaC は導入せず、UI などから必要なリソースを用意しました。<br>データエンジニア2名でそれぞれ Databricks、製品 A で環境を構築し、2〜3週間ぐらいで検証しました。</p><p>ちなみにこのとき両製品で同じ dbt プロジェクトを使っていました。<br>このように dbt は比較的高い相互運用性があり、何かあったときの DWH の変更のハードルを下げてくれるということを実感しました。<br>(クエリの書き方次第ではある)</p><h3 id=技術スタックの決定>技術スタックの決定<a hidden class=anchor aria-hidden=true href=#技術スタックの決定>#</a></h3><p>さて、このようにして両製品を比較したわけですが、もともと想定していた観点ではそこまで大きな違いはありませんでした。<br>とはいえ以下の点で優れていたことにより Databricks の採用を決めました。</p><ul><li>コストパフォーマンス<ul><li>我々の代表的なワークロードでは Databricks の方が若干コストが安かった</li><li>これはワークロードによっても変わると思われる</li></ul></li><li>オープン性<ul><li>データ実体は Delta Lake という open table format</li><li>また顧客 (=我々) 管理の S3 bucket に保存されるので透明性が高く、データの囲い込みがない</li><li>OSS 志向も強い</li><li>製品 A も open table format を選択できるが、パフォーマンスで劣るとの話があった</li></ul></li><li>アナリストからの評価<ul><li>これはちょっとタイミングの問題もあるのだが、調査時点では以下のような機能が Databricks のみにあってアナリストからの高評価となった<ul><li>SQL の Git 管理機能</li><li><a href=https://docs.databricks.com/ja/genie/index.html>Genie</a> などの AI まわり</li><li>もともと Redash を使っていたので親和性が高いというのもあったかも<ul><li><a href=https://newspicks.com/news/5031405/>DatabricksがRedashを買収してデータサイエンティストのためのデータ視覚化を充実 (TechCrunch Japan)</a></li></ul></li></ul></li></ul></li></ul><p>とまあ現場レベルではこれで行きましょうという合意ができたわけですが、Databricks を使えるようにするため今度は予算を獲得する必要があります。</p><h2 id=予算獲得>予算獲得<a hidden class=anchor aria-hidden=true href=#予算獲得>#</a></h2><h3 id=予算獲得までの流れ>予算獲得までの流れ<a hidden class=anchor aria-hidden=true href=#予算獲得までの流れ>#</a></h3><p>どのように予算を獲得するかは組織に大きく依存するでしょう。<br>ウチの場合は以下のような流れでした。</p><pre class=mermaid>flowchart TD
    estimate["費用見積"]
    stakeholder["ステークホルダーへの説明"]
    approval["承認会議"]

    estimate --> stakeholder
    stakeholder --> approval
</pre><h3 id=費用見積>費用見積<a hidden class=anchor aria-hidden=true href=#費用見積>#</a></h3><p>技術スタックが決まったので費用を見積もります。<br>厳密に見積もるのは難しいですが、ある程度の仮定をおいて計算します。</p><p>通常のデータ基盤であればストレージとコンピュートの費用が中心になるでしょう。<br>両者はともにデータ量に依存します。<br>事業計画にもとづいてデータ量の変化を仮定し、それに対してストレージとコンピュートの費用の見積を出しました。</p><p>また、費用については新旧のデータ基盤の並行稼働のことも考慮する必要があります。<br>バチッと一瞬で切り替えられるわけではなく、ある程度の期間は2つのデータ基盤を並行して運用することになります。<br>その間は余分に費用がかかってしまいます。</p><h3 id=ステークホルダーへの説明>ステークホルダーへの説明<a hidden class=anchor aria-hidden=true href=#ステークホルダーへの説明>#</a></h3><p>次に社内のステークホルダーへの説明を行いました。<br>まずは一次上長であるマネージャにやりたいことと費用見積の詳細について説明します。<br>Part 1 でも少し触れていますが、マネージャはデータエンジニアリングの知見はあまりなかったため、それなりの説明コストがかかりました。<br>とはいえちゃんと理解しようとしてくださっていたのでそこは感謝です。</p><p>次にデータ基盤に対する社内のデータプロバイダー、コンシューマーについてやりたいことやその影響の説明をしました。<br>3回ぐらい大きめのミーティングを開催して説明しました。<br>ここにも準備など含めそれなりの時間がかかっています。</p><p>正直、当初はこのステップは本当に必要なのか？と考えていました。<br>弊社ぐらいの小さい組織であれば、リーダーシップを持った人が責任と権限を持ち、スピード感を持って決めていく方がいいはずです。<br>ステークホルダーには決まった後に伝えればいいだろうと。<br>ただ後になってから、これは必要なステップだったと思うに至りました。</p><h3 id=承認会議>承認会議<a hidden class=anchor aria-hidden=true href=#承認会議>#</a></h3><p>ここまでやってようやく本丸の承認会議です。<br>決裁権を持つエライ人の前で説明して承認を得るという会議を開催しました。<br>結論として、割とすんなりと承認を得ることができました。</p><p>「たぶんやった方がいいんだろうけど」、その場でエライ人が言ったこの言葉が象徴的でした。<br>弊社の場合決裁権を持つマネジメント層にデータまわりに詳しい人がいません。<br>もちろん費用見積はちゃんと評価されるわけですが、その上で雰囲気で決まっていく感がありました。(JTC)<br>その雰囲気を醸成するためにステークホルダーへの説明が必要だったわけです。</p><p>組織にもよるのでしょうが、データエンジニアをやってるとこのような政治っぽいことを考えることになる場合もあるのだと理解しました。<br>このあたり前述のマネージャにかなり助けられました。</p><h2 id=ここまでの課題と今後の対策>ここまでの課題と今後の対策<a hidden class=anchor aria-hidden=true href=#ここまでの課題と今後の対策>#</a></h2><p>Part 1 とかぶりますが、やはりマネジメント層のデータまわりのリテラシーは組織としての課題です。<br>外的要因により必要にかられるようなことがない限り、少しずつ啓蒙していくしかないかなと考えています。</p><h2 id=databricks-について>Databricks について<a hidden class=anchor aria-hidden=true href=#databricks-について>#</a></h2><p>Advent Calendar の記事だということもあり Databricks についてもう少し触れておきます。<br>これを書いている時点では PoC のときよりは Databricks に触っており、その中で体感した良かったところを挙げておきます。<br>(あくまである一社での例です)</p><ul><li>OSS ベースであることによる透明性<ul><li>データ処理は Apache Spark 互換のエンジン Photon で実行される</li><li>ベースは OSS の Spark なので、Spark の知見があれば実行計画を見るなどして処理のイメージがつきやすい</li><li>最適化のポイントもわかりやすい (と思っている)</li></ul></li><li>一貫したガバナンス<ul><li>ML model 等の data product も table などの database object と同じように権限管理できる</li><li>同じ user でも workspace 単位でアクセス可能なリソースを制限できる</li><li>PoC の時点でもカタログとしてわかっていたが、触ってみて実感したところがある</li></ul></li><li>AI まわり<ul><li>ChatGPT-like にデータについての問い合わせが行える Genie</li><li>Nootebook でエラーを出したときに原因や修正案を示してくれる</li><li>LLM の評価や開発の機能</li></ul></li><li>手厚いサポート<ul><li>弊社に対して担当がついており、Slack で質問に回答していただける</li><li>A◯S のサポートと比べても回答のスピード・質ともに高い</li><li>いつもお世話になってます 🙇‍♂️</li></ul></li></ul><p>とはいえまだすべての機能を確認できていないし、そもそも結構なペースで機能が増えています。<br>個人的には <a href=https://www.databricks.com/blog/introducing-databricks-lakeflow>Databricks LakeFlow</a> のあたりに期待しています。</p><h2 id=次回予告>次回予告<a hidden class=anchor aria-hidden=true href=#次回予告>#</a></h2><p>次回はまだ未定ですが、何か開発関連の話を書くつもりです。</p><p>以上、現場からでした。</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://soonraah.github.io/tags/data-platform/>Data Platform</a></li><li><a href=https://soonraah.github.io/tags/databricks/>Databricks</a></li><li><a href=https://soonraah.github.io/tags/%E6%8A%80%E8%A1%93%E9%81%B8%E5%AE%9A/>技術選定</a></li></ul><nav class=paginav><a class=prev href=https://soonraah.github.io/posts/reading-note-agent-book/><span class=title>« 前へ</span><br><span>読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門</span>
</a><a class=next href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-1/><span class=title>次へ »</span><br><span>ふつうのデータ基盤移行 - Part 1. 戦略策定編</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share ふつうのデータ基盤移行 - Part 2. 技術選定編 on x" href="https://x.com/intent/tweet/?text=%e3%81%b5%e3%81%a4%e3%81%86%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e5%9f%ba%e7%9b%a4%e7%a7%bb%e8%a1%8c%20-%20Part%202.%20%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e7%b7%a8&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fordinary-data-platform-migration-part-2%2f&amp;hashtags=dataplatform%2cDatabricks%2c%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ふつうのデータ基盤移行 - Part 2. 技術選定編 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fordinary-data-platform-migration-part-2%2f&amp;title=%e3%81%b5%e3%81%a4%e3%81%86%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e5%9f%ba%e7%9b%a4%e7%a7%bb%e8%a1%8c%20-%20Part%202.%20%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e7%b7%a8&amp;summary=%e3%81%b5%e3%81%a4%e3%81%86%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e5%9f%ba%e7%9b%a4%e7%a7%bb%e8%a1%8c%20-%20Part%202.%20%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e7%b7%a8&amp;source=https%3a%2f%2fsoonraah.github.io%2fposts%2fordinary-data-platform-migration-part-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ふつうのデータ基盤移行 - Part 2. 技術選定編 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoonraah.github.io%2fposts%2fordinary-data-platform-migration-part-2%2f&title=%e3%81%b5%e3%81%a4%e3%81%86%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e5%9f%ba%e7%9b%a4%e7%a7%bb%e8%a1%8c%20-%20Part%202.%20%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e7%b7%a8"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ふつうのデータ基盤移行 - Part 2. 技術選定編 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoonraah.github.io%2fposts%2fordinary-data-platform-migration-part-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ふつうのデータ基盤移行 - Part 2. 技術選定編 on whatsapp" href="https://api.whatsapp.com/send?text=%e3%81%b5%e3%81%a4%e3%81%86%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e5%9f%ba%e7%9b%a4%e7%a7%bb%e8%a1%8c%20-%20Part%202.%20%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e7%b7%a8%20-%20https%3a%2f%2fsoonraah.github.io%2fposts%2fordinary-data-platform-migration-part-2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ふつうのデータ基盤移行 - Part 2. 技術選定編 on telegram" href="https://telegram.me/share/url?text=%e3%81%b5%e3%81%a4%e3%81%86%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e5%9f%ba%e7%9b%a4%e7%a7%bb%e8%a1%8c%20-%20Part%202.%20%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e7%b7%a8&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fordinary-data-platform-migration-part-2%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share ふつうのデータ基盤移行 - Part 2. 技術選定編 on ycombinator" href="https://news.ycombinator.com/submitlink?t=%e3%81%b5%e3%81%a4%e3%81%86%e3%81%ae%e3%83%87%e3%83%bc%e3%82%bf%e5%9f%ba%e7%9b%a4%e7%a7%bb%e8%a1%8c%20-%20Part%202.%20%e6%8a%80%e8%a1%93%e9%81%b8%e5%ae%9a%e7%b7%a8&u=https%3a%2f%2fsoonraah.github.io%2fposts%2fordinary-data-platform-migration-part-2%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://soonraah.github.io/>Froglog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="コピー";function s(){t.innerHTML="コピーされました!",setTimeout(()=>{t.innerHTML="コピー"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script><script type=module>
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
  </script></body></html>