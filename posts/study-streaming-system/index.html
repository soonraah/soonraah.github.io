<!doctype html><html lang=ja dir=auto><head><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと | Froglog</title>
<meta name=keywords content="Apache Spark,Apache Flink,stream processing"><meta name=description content="ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。
それにあたって独学で調べたことなどまとめておく。
ストリーム処理とは そもそも &ldquo;ストリーム処理&rdquo; とは何を指しているのか。
以下の引用が簡潔に示している。
a type of data processing engine that is designed with infinite data sets in mind. Nothing more.
&ndash; Streaming 101: The world beyond batch
こちらは &ldquo;streaming system&rdquo; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。
例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。
web サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。
これに対して &ldquo;1日分のユーザ行動ログ&rdquo; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。
ストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。
この後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。
なぜストリーム処理なのか なぜストリーム処理なのか。
ひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。
迅速なフィードバックがビジネス上のメリットとなることは自明だ。
SNS の配信 カーシェアリングにおける配車や料金設定 クレジットカードや広告クリックなどの不正検知 もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。
まあ待っていられない。
一般的なストリーム処理の構成 モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。
producer broker consumer producer は最初にレコードを生成する、ストリームデータの発生源となるものである。
例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/posts/study-streaming-system/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5cfc680b1eeaeef9efbced92d46c2a9e876b72ee14fba85846afc4cff9e6e6f8.css integrity="sha256-XPxoCx7q7vnvvO2S1Gwqnodrcu4U+6hYRq/Ez/nm5vg=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-73329599-2","auto"),ga("send","pageview"))</script><meta property="og:title" content="バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと"><meta property="og:description" content="ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。
それにあたって独学で調べたことなどまとめておく。
ストリーム処理とは そもそも &ldquo;ストリーム処理&rdquo; とは何を指しているのか。
以下の引用が簡潔に示している。
a type of data processing engine that is designed with infinite data sets in mind. Nothing more.
&ndash; Streaming 101: The world beyond batch
こちらは &ldquo;streaming system&rdquo; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。
例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。
web サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。
これに対して &ldquo;1日分のユーザ行動ログ&rdquo; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。
ストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。
この後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。
なぜストリーム処理なのか なぜストリーム処理なのか。
ひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。
迅速なフィードバックがビジネス上のメリットとなることは自明だ。
SNS の配信 カーシェアリングにおける配車や料金設定 クレジットカードや広告クリックなどの不正検知 もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。
まあ待っていられない。
一般的なストリーム処理の構成 モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。
producer broker consumer producer は最初にレコードを生成する、ストリームデータの発生源となるものである。
例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。"><meta property="og:type" content="article"><meta property="og:url" content="https://soonraah.github.io/posts/study-streaming-system/"><meta property="og:image" content="https://soonraah.github.io/image/photo/jon-flobrant-rB7-LCa_diU-unsplash.jpg"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-09-06T16:30:00+09:00"><meta property="article:modified_time" content="2020-09-06T16:30:00+09:00"><meta property="og:site_name" content="Froglog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/photo/jon-flobrant-rB7-LCa_diU-unsplash.jpg"><meta name=twitter:title content="バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと"><meta name=twitter:description content="ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。
それにあたって独学で調べたことなどまとめておく。
ストリーム処理とは そもそも &ldquo;ストリーム処理&rdquo; とは何を指しているのか。
以下の引用が簡潔に示している。
a type of data processing engine that is designed with infinite data sets in mind. Nothing more.
&ndash; Streaming 101: The world beyond batch
こちらは &ldquo;streaming system&rdquo; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。
例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。
web サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。
これに対して &ldquo;1日分のユーザ行動ログ&rdquo; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。
ストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。
この後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。
なぜストリーム処理なのか なぜストリーム処理なのか。
ひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。
迅速なフィードバックがビジネス上のメリットとなることは自明だ。
SNS の配信 カーシェアリングにおける配車や料金設定 クレジットカードや広告クリックなどの不正検知 もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。
まあ待っていられない。
一般的なストリーム処理の構成 モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。
producer broker consumer producer は最初にレコードを生成する、ストリームデータの発生源となるものである。
例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"https://soonraah.github.io/posts/"},{"@type":"ListItem","position":3,"name":"バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと","item":"https://soonraah.github.io/posts/study-streaming-system/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと","name":"バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと","description":"ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。\nそれにあたって独学で調べたことなどまとめておく。\nストリーム処理とは そもそも \u0026ldquo;ストリーム処理\u0026rdquo; とは何を指しているのか。\n以下の引用が簡潔に示している。\na type of data processing engine that is designed with infinite data sets in mind. Nothing more.\n\u0026ndash; Streaming 101: The world beyond batch\nこちらは \u0026ldquo;streaming system\u0026rdquo; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。\n例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。\nweb サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。\nこれに対して \u0026ldquo;1日分のユーザ行動ログ\u0026rdquo; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。\nストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。\nこの後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。\nなぜストリーム処理なのか なぜストリーム処理なのか。\nひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。\n迅速なフィードバックがビジネス上のメリットとなることは自明だ。\nSNS の配信 カーシェアリングにおける配車や料金設定 クレジットカードや広告クリックなどの不正検知 もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。\nまあ待っていられない。\n一般的なストリーム処理の構成 モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。\nproducer broker consumer producer は最初にレコードを生成する、ストリームデータの発生源となるものである。\n例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。","keywords":["Apache Spark","Apache Flink","stream processing"],"articleBody":"ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。\nそれにあたって独学で調べたことなどまとめておく。\nストリーム処理とは そもそも “ストリーム処理” とは何を指しているのか。\n以下の引用が簡潔に示している。\na type of data processing engine that is designed with infinite data sets in mind. Nothing more.\n– Streaming 101: The world beyond batch\nこちらは “streaming system” について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。\n例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。\nweb サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。\nこれに対して “1日分のユーザ行動ログ” 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。\nストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。\nこの後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。\nなぜストリーム処理なのか なぜストリーム処理なのか。\nひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。\n迅速なフィードバックがビジネス上のメリットとなることは自明だ。\nSNS の配信 カーシェアリングにおける配車や料金設定 クレジットカードや広告クリックなどの不正検知 もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。\nまあ待っていられない。\n一般的なストリーム処理の構成 モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。\nproducer broker consumer producer は最初にレコードを生成する、ストリームデータの発生源となるものである。\n例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。\nproducer は絶え間なくログを生成し、それを broker へと送る。\nbroker は producer から送られたログを格納し、任意のタイミングで取り出せるようにするものである。\n誤解を恐れずに言うとメッセージキューに近いイメージだ。\nApache Kafka クラスタや Amazon Kinesis Data Streams 等がこれに該当する。\nconsumer は broker からログを取り出し、それに対し何かしらの処理を行うものだ。\ntime window 集計であったりログからの異常検知であったり、処理した結果として何かビジネス上意味があるものを得るのである。\nこれを行うフレームワークとしては Spark Streaming や Apache Flink 等がメジャーなのだろうか。\nproducer と consumer の間に broker を挟むメリットとしては次のようなことが挙げられる。\nproducer が M 個、consumer が N 個の場合に M * N の関係になるところを broker を挟めば M + N にできる producer, consumer に多数のシステムがあったとしても各自は broker との接続だけを考えればよい 任意のタイミングでデータを読み出せる producer または consumer に問題が発生してもデータロスが起こりにくくできる その分 broker には高い可用性が求められる Kafka はクラスタで冗長構成 Kinesis Data Streams は複数 AZ でレプリケーション 時間の概念 ストリーム処理では時間の概念がいくつかあり、集計などの処理をどの時間をベースにして実行するのか、意識する必要がある。\nevent time producer 側でログイベントが発生した時間 ingestion time broker にそのログイベントのレコードが挿入された時間 processing time consumer 側でレコードを処理した時間 processing time を使うのが一番簡単なのだが、おそらく分析系の処理であれば window 集計等では event time を使うことが多いのではないだろうか。\ningestion time はおそらく実際のプロダクトではあまり使われないのではと思われる。\n(ネットワークのパフォーマンスを見るぐらい？)\nWindowing ストリーム処理の中で sum, count などを伴う集計処理を行う場合、通常は時間方向の window で切って処理するということになるのではないだろうか。\nwindow で切らずに完全なデータセットがそろうまで待つことはできないし、データが来るたびに逐次的に全体の結果を更新するしていくというのも割に合わない。\nwindow の切り方もいくつかある。\ntumbling window 固定長でオーバーラップしない sliding window 固定長でオーバーラップを含む session window いわゆる web の session のように、ある種のイベントがある期間発生しないことにより window が区切られる これらについては Flink のドキュメントが図もあってわかりやすい。\n個人的な感想だが、この time window の集計がない単なる map 的なストリーム処理であれば traditional なアーキテクチャでも難しくはない。\nしかし time window 集計が必要となった場合は Spark Streaming 等のモダンなフレームワークが威力を発揮してくる。\nWatermark 時間で window を切るときは、前述のどの時間の定義を用いるかを考えなければいけない。\nprocessing time を用いる場合は簡単だが event time はやや難しい。\nconsumer 側では event のレコードがどれくらい遅れてやってくるかわからないためだ。\nネットワークその他の影響により、event のレコードが producer -\u003e broker -\u003e consumer という経路で consumer に届くまでの時間というのは一定にはならない。\nまた、古い event が新しい event より後に届くというように順番が前後することも起こりうる。\nここで “watermark” という考え方が必要になってくる。\nA watermark with a value of time X makes the statement: \"all input data with event times less than X have been observed.\"\n– Streaming 102: The world beyond batch\nある processing time において「event time X より前のレコードはすべて到着したよ」というのが watermark である。\n別の言い方をすると watermark により event のレコードがどの程度遅延してもよいかが定義される。\nevent time X より前のレコードが真の意味ですべて到着した、というのは難しい。\n実際には heuristic にどの程度遅れていいかを決め、それより遅れた場合はある event time 期間における window 処理には含めないということになる。\nwatermark の決め方はフレームワーク次第だろうか。\n例えば Spark Structured Streaming の例だと図もあって比較的わかりやすい。\nSchema Evolution 何らかの業務システムや web システム等をある程度運用したことがある人ならわかると思うが、データの schema というのはナマモノだ。\n一度決めたら終わりというわけではなくプロダクトやビジネスの変化に応じて変化していく。\nカラムが増えたり、削除されたり、名前や型が変わったり…\nこのようにデータの構造が変化していくこと、またはそれを扱うことを “schema evolution” という。\nバッチ処理において schema の変更に追従することを考えるのはそれほど難しくない。\nhourly のバッチ処理であったとしても、バッチ処理とバッチ処理の間の時間で application を更新すればいいだけだ。\n(が、実際に行うのは困難が伴うことも多い)\nではストリーム処理ではどうだろうか。\nいわゆるストリーム処理においては処理と処理の間というものがなく、application がずっと稼働しっぱなしということになる。\nバッチ処理のような更新はできない。\nもっと言うと producer で生まれた新しい schema のレコードがいつ届くかもわからない。\nおそらくこの問題には2つの対応方法がある。\n1つめは consumer 側のシステムで前方互換性を保つという方法である。\nこの場合、新しいフィールドは必ず末尾に追加される等、producer 側での schema 更新についてある程度のルールが必要となるだろう。\nproducer 側で生成されるレコードの schema の変更が必ず事前にわかるというのであれば後方互換性でもいいが、多くの場合は難しい。\nところで前方互換と後方互換、どっちがどっちなのか覚えられません。\n2つめの方法として schema 情報をレコード自体に入れ込んでしまうという方法もある。\nApach Avro のような serialization の方法を取っているとレコード自体に schema の情報を付与することができる。\nおそらく最もエレガントにこれをやるのが Confluent の Schema Registry という機能だ。\nproducer から送出されるレコードには schema ID を付与する。\nschema の実体は Schema Registry という broker とは別の場所で管理されており、consumer 側では受け取ったレコードに付与されている schema ID と Schema Registry に登録されている shcema の実体を参照してレコードを deserialize することができる。\nDeploy ストリーム処理を行うシステムは終わりのないデータを処理するためのものであり、ずっと動き続けることが期待されている。\nしかし通常システムは一度立ち上げれば終わりということではなく、運用されている中で更新していく必要がある。\nずっと動かしながらどのように deploy, release するのか。\nこの問題は主に consumer 側のシステムで配慮が必要になると思われる。\n正直これについてはちゃんと調べられていないが、2点ほど述べておきたい。\nまず1点目、application を中断・更新・再開するのにどの程度の時間がかかるのかを知っておく必要があるということ。\nアーキテクチャやフレームワーク、処理の内容や checkpoint (後述) を使うか等によりこの時間は変わってくる。\n一例だが、AWS 環境において\nAWS Glue + Spark Structured Streaming Amazon Kinesis Data Analytics + Flink の比較をしたことがある。\n前者は再開に数分かかったのに対し、後者は1分未満で再開できた。\n再開までの時間が十分に短いと判断できるのであればそのまま deploy, release してしまっていいだろう。\n一方そうでない場合はどうすべきかという話が2点目。\n再開までの時間が長く、システム要件的に許容できないというのであれば、release 時は二重で動かすというような措置が必要かもしれない。\nおそらく Blue-Green Deployment のようなことを考えることになるだろう。\nCheckpoint 前述のとおり、ストリーム処理を行うシステムはずっと動き続けることが期待されている。\nしかし予定された application の更新や不測のエラー等、何らかの理由で一時的に中断されるということが実際の運用中には起こる。\n中断されたとき速やかに復帰する仕組みとして “checkpoint” というものがいくつかの consumer 側のフレームワークで提供されている。\n雑に説明すると、処理のある時点における進捗や内部状態などをディスク等に永続化し、そこから処理を再開できるようにするものである。\nRecovering from Failures with Checkpointing - Apache Spark Checkpointing - Apache Flink 上記は Spark Structured Streaming と Flink の例だ。\ncheckpoint には次のようなメリットがあり、運用上有用だと言える。\n内部の状態を保持しているため、速やかに復帰できる 中断した位置から再開できるので出力に穴が開かない 一方で落とし穴もある。\ncheckpoint では内部の状態が永続化されるわけだが、内部の状態というのは当然 application の実装が決めているものである。\napplication のコードを変更したとき、変更の内容によっては永続化された checkpoint と application が合わなくなることがあるのだ。\n未定義の挙動となることもあるので、checkpoint の運用には十分に配慮する必要がある。\nどのような変更なら checkpoint が安全に利用できるのかはフレームワークのドキュメントに記載があるので確認しておきたい。\nRDB の世界との折り合い みんな大好きな RDB の世界では table を操作してデータの処理を行う。\n基本的には table というものはある時点における完全なデータセットを表すものである。 (ex. isolation)\n他方、ストリーム処理はやってきたデータを逐次的に処理するものである (mini-batch の場合もあるが)。\n直感的にこの2つは相性が悪そうに見える。\nしかし Spark や Flink では table ベースの操作でストリーム処理を行うための API が提供されている。\nおそらく\nストリーム処理の周辺のデータソースとして RDB が存在する RDB 的な table 操作があまりにも浸透している というところが API が必要である理由なのだろう。\nストリームデータを table 的に扱うというのが、やや直感的な理解をしにくいものとなっている。\nフレームワークのドキュメントを確認しておきたい。\n例えば Spark Structured Streaming であれば処理の出力のための3つの output mode が示されている。\nAppend mode: 追加された行だけ出力 Complete mode: table 全体を出力 Update mode: 更新された行だけ出力 どれを選ぶかにより必要とする内部メモリの大きさも影響される。\nまとめ 思ったより長文になってしまった。\n結局ストリーム処理の難しさは以下の2点に尽きるだろう。\n複数の時間の概念 常時稼働のシステム 独学なので抜け漏れがあったり、話が新しくなかったりすることもあると思われる。\n参考 Streaming 101: The world beyond batch Apache Beam PMC によるストリーム処理の解説ポスト。必読 Streaming 102: The world beyond batch 上の続きであり watermark について触れている Analytics Lens - AWS Well-Architected Framework AWS の資料。ストリーム処理のシステムの全体感がつかめる Structured Streaming Programming Guide - Apache Spark Spark Structured Streaming のドキュメント。consumer の気持ちがわかる Flink DataStream API Programming Guide - Apache Flink Flink のドキュメントの方がより詳しい。DataStream API の解説を中心に読むとよい ","wordCount":"605","inLanguage":"ja","image":"https://soonraah.github.io/image/photo/jon-flobrant-rB7-LCa_diU-unsplash.jpg","datePublished":"2020-09-06T16:30:00+09:00","dateModified":"2020-09-06T16:30:00+09:00","author":{"@type":"Person","name":"soonraah"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://soonraah.github.io/posts/study-streaming-system/"},"publisher":{"@type":"Organization","name":"Froglog","logo":{"@type":"ImageObject","url":"https://soonraah.github.io/favicon2.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://soonraah.github.io>ホーム</a>&nbsp;»&nbsp;<a href=https://soonraah.github.io/posts/>Posts</a></div><h1 class=post-title>バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと</h1><div class=post-meta><span title='2020-09-06 16:30:00 +0900 JST'>9月 6, 2020</span>&nbsp;·&nbsp;soonraah</div></header><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/jon-flobrant-rB7-LCa_diU-unsplash.jpg alt=Stream><p><a href=https://unsplash.com/photos/rB7-LCa_diU>Photo by Jon Flobrant on Unsplash</a></p></figure><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目次</span></summary><div class=inner><ul><li><a href=#%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%a8%e3%81%af aria-label=ストリーム処理とは>ストリーム処理とは</a></li><li><a href=#%e3%81%aa%e3%81%9c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%aa%e3%81%ae%e3%81%8b aria-label=なぜストリーム処理なのか>なぜストリーム処理なのか</a></li><li><a href=#%e4%b8%80%e8%88%ac%e7%9a%84%e3%81%aa%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e6%a7%8b%e6%88%90 aria-label=一般的なストリーム処理の構成>一般的なストリーム処理の構成</a></li><li><a href=#%e6%99%82%e9%96%93%e3%81%ae%e6%a6%82%e5%bf%b5 aria-label=時間の概念>時間の概念</a></li><li><a href=#windowing aria-label=Windowing>Windowing</a></li><li><a href=#watermark aria-label=Watermark>Watermark</a></li><li><a href=#schema-evolution aria-label="Schema Evolution">Schema Evolution</a></li><li><a href=#deploy aria-label=Deploy>Deploy</a></li><li><a href=#checkpoint aria-label=Checkpoint>Checkpoint</a></li><li><a href=#rdb-%e3%81%ae%e4%b8%96%e7%95%8c%e3%81%a8%e3%81%ae%e6%8a%98%e3%82%8a%e5%90%88%e3%81%84 aria-label="RDB の世界との折り合い">RDB の世界との折り合い</a></li><li><a href=#%e3%81%be%e3%81%a8%e3%82%81 aria-label=まとめ>まとめ</a></li><li><a href=#%e5%8f%82%e8%80%83 aria-label=参考>参考</a></li></ul></div></details></div><div class=post-content><p>ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。<br>それにあたって独学で調べたことなどまとめておく。</p><h2 id=ストリーム処理とは>ストリーム処理とは<a hidden class=anchor aria-hidden=true href=#ストリーム処理とは>#</a></h2><p>そもそも &ldquo;ストリーム処理&rdquo; とは何を指しているのか。<br>以下の引用が簡潔に示している。</p><blockquote><p>a type of data processing engine that is designed with infinite data sets in mind. Nothing more.<br>&ndash; <a href=https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/>Streaming 101: The world beyond batch</a></p></blockquote><p>こちらは &ldquo;streaming system&rdquo; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。</p><p>例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。<br>web サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。</p><p>これに対して &ldquo;1日分のユーザ行動ログ&rdquo; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。<br>ストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。<br>この後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。</p><h2 id=なぜストリーム処理なのか>なぜストリーム処理なのか<a hidden class=anchor aria-hidden=true href=#なぜストリーム処理なのか>#</a></h2><p>なぜストリーム処理なのか。<br>ひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。<br>迅速なフィードバックがビジネス上のメリットとなることは自明だ。</p><ul><li>SNS の配信</li><li>カーシェアリングにおける配車や料金設定</li><li>クレジットカードや広告クリックなどの不正検知</li></ul><p>もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。<br>まあ待っていられない。</p><h2 id=一般的なストリーム処理の構成>一般的なストリーム処理の構成<a hidden class=anchor aria-hidden=true href=#一般的なストリーム処理の構成>#</a></h2><p>モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。</p><ul><li>producer</li><li>broker</li><li>consumer</li></ul><p>producer は最初にレコードを生成する、ストリームデータの発生源となるものである。<br>例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。<br>producer は絶え間なくログを生成し、それを broker へと送る。</p><p>broker は producer から送られたログを格納し、任意のタイミングで取り出せるようにするものである。<br>誤解を恐れずに言うとメッセージキューに近いイメージだ。<br>Apache Kafka クラスタや Amazon Kinesis Data Streams 等がこれに該当する。</p><p>consumer は broker からログを取り出し、それに対し何かしらの処理を行うものだ。<br>time window 集計であったりログからの異常検知であったり、処理した結果として何かビジネス上意味があるものを得るのである。<br>これを行うフレームワークとしては Spark Streaming や Apache Flink 等がメジャーなのだろうか。</p><p>producer と consumer の間に broker を挟むメリットとしては次のようなことが挙げられる。</p><ul><li>producer が M 個、consumer が N 個の場合に M * N の関係になるところを broker を挟めば M + N にできる<ul><li>producer, consumer に多数のシステムがあったとしても各自は broker との接続だけを考えればよい</li></ul></li><li>任意のタイミングでデータを読み出せる</li><li>producer または consumer に問題が発生してもデータロスが起こりにくくできる<ul><li>その分 broker には高い可用性が求められる<ul><li>Kafka はクラスタで冗長構成</li><li>Kinesis Data Streams は複数 AZ でレプリケーション</li></ul></li></ul></li></ul><h2 id=時間の概念>時間の概念<a hidden class=anchor aria-hidden=true href=#時間の概念>#</a></h2><p>ストリーム処理では時間の概念がいくつかあり、集計などの処理をどの時間をベースにして実行するのか、意識する必要がある。</p><ul><li>event time<ul><li>producer 側でログイベントが発生した時間</li></ul></li><li>ingestion time<ul><li>broker にそのログイベントのレコードが挿入された時間</li></ul></li><li>processing time<ul><li>consumer 側でレコードを処理した時間</li></ul></li></ul><p>processing time を使うのが一番簡単なのだが、おそらく分析系の処理であれば window 集計等では event time を使うことが多いのではないだろうか。</p><p>ingestion time はおそらく実際のプロダクトではあまり使われないのではと思われる。<br>(ネットワークのパフォーマンスを見るぐらい？)</p><h2 id=windowing>Windowing<a hidden class=anchor aria-hidden=true href=#windowing>#</a></h2><p>ストリーム処理の中で <code>sum</code>, <code>count</code> などを伴う集計処理を行う場合、通常は時間方向の window で切って処理するということになるのではないだろうか。<br>window で切らずに完全なデータセットがそろうまで待つことはできないし、データが来るたびに逐次的に全体の結果を更新するしていくというのも割に合わない。</p><p>window の切り方もいくつかある。</p><ul><li>tumbling window<ul><li>固定長でオーバーラップしない</li></ul></li><li>sliding window<ul><li>固定長でオーバーラップを含む</li></ul></li><li>session window<ul><li>いわゆる web の session のように、ある種のイベントがある期間発生しないことにより window が区切られる</li></ul></li></ul><p>これらについては <a href=https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html>Flink のドキュメント</a>が図もあってわかりやすい。</p><p>個人的な感想だが、この time window の集計がない単なる <code>map</code> 的なストリーム処理であれば traditional なアーキテクチャでも難しくはない。<br>しかし time window 集計が必要となった場合は Spark Streaming 等のモダンなフレームワークが威力を発揮してくる。</p><h2 id=watermark>Watermark<a hidden class=anchor aria-hidden=true href=#watermark>#</a></h2><p>時間で window を切るときは、前述のどの時間の定義を用いるかを考えなければいけない。<br>processing time を用いる場合は簡単だが event time はやや難しい。<br>consumer 側では event のレコードがどれくらい遅れてやってくるかわからないためだ。</p><p>ネットワークその他の影響により、event のレコードが producer -> broker -> consumer という経路で consumer に届くまでの時間というのは一定にはならない。<br>また、古い event が新しい event より後に届くというように順番が前後することも起こりうる。<br>ここで &ldquo;watermark&rdquo; という考え方が必要になってくる。</p><blockquote><p>A watermark with a value of time X makes the statement: "all input data with event times less than X have been observed."<br>&ndash; <a href=https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/>Streaming 102: The world beyond batch</a></p></blockquote><p>ある processing time において「event time X より前のレコードはすべて到着したよ」というのが watermark である。<br>別の言い方をすると watermark により event のレコードがどの程度遅延してもよいかが定義される。</p><p>event time X より前のレコードが真の意味ですべて到着した、というのは難しい。<br>実際には heuristic にどの程度遅れていいかを決め、それより遅れた場合はある event time 期間における window 処理には含めないということになる。</p><p>watermark の決め方はフレームワーク次第だろうか。<br>例えば <a href=https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#handling-late-data-and-watermarking>Spark Structured Streaming</a> の例だと図もあって比較的わかりやすい。</p><h2 id=schema-evolution>Schema Evolution<a hidden class=anchor aria-hidden=true href=#schema-evolution>#</a></h2><p>何らかの業務システムや web システム等をある程度運用したことがある人ならわかると思うが、データの schema というのはナマモノだ。<br>一度決めたら終わりというわけではなくプロダクトやビジネスの変化に応じて変化していく。<br>カラムが増えたり、削除されたり、名前や型が変わったり…<br>このようにデータの構造が変化していくこと、またはそれを扱うことを &ldquo;schema evolution&rdquo; という。</p><p>バッチ処理において schema の変更に追従することを考えるのはそれほど難しくない。<br>hourly のバッチ処理であったとしても、バッチ処理とバッチ処理の間の時間で application を更新すればいいだけだ。<br>(が、実際に行うのは困難が伴うことも多い)</p><p>ではストリーム処理ではどうだろうか。<br>いわゆるストリーム処理においては処理と処理の間というものがなく、application がずっと稼働しっぱなしということになる。<br>バッチ処理のような更新はできない。<br>もっと言うと producer で生まれた新しい schema のレコードがいつ届くかもわからない。</p><p>おそらくこの問題には2つの対応方法がある。<br>1つめは consumer 側のシステムで前方互換性を保つという方法である。<br>この場合、新しいフィールドは必ず末尾に追加される等、producer 側での schema 更新についてある程度のルールが必要となるだろう。<br>producer 側で生成されるレコードの schema の変更が必ず事前にわかるというのであれば後方互換性でもいいが、多くの場合は難しい。<br>ところで<a href=https://ja.wikipedia.org/wiki/%E4%BA%92%E6%8F%9B%E6%80%A7>前方互換と後方互換</a>、どっちがどっちなのか覚えられません。</p><p>2つめの方法として schema 情報をレコード自体に入れ込んでしまうという方法もある。<br><a href=https://avro.apache.org/>Apach Avro</a> のような serialization の方法を取っているとレコード自体に schema の情報を付与することができる。</p><p>おそらく最もエレガントにこれをやるのが Confluent の <a href=https://docs.confluent.io/current/schema-registry/index.html>Schema Registry</a> という機能だ。<br>producer から送出されるレコードには schema ID を付与する。<br>schema の実体は Schema Registry という broker とは別の場所で管理されており、consumer 側では受け取ったレコードに付与されている schema ID と Schema Registry に登録されている shcema の実体を参照してレコードを deserialize することができる。</p><h2 id=deploy>Deploy<a hidden class=anchor aria-hidden=true href=#deploy>#</a></h2><p>ストリーム処理を行うシステムは終わりのないデータを処理するためのものであり、ずっと動き続けることが期待されている。<br>しかし通常システムは一度立ち上げれば終わりということではなく、運用されている中で更新していく必要がある。</p><p>ずっと動かしながらどのように deploy, release するのか。<br>この問題は主に consumer 側のシステムで配慮が必要になると思われる。<br>正直これについてはちゃんと調べられていないが、2点ほど述べておきたい。</p><p>まず1点目、application を中断・更新・再開するのにどの程度の時間がかかるのかを知っておく必要があるということ。<br>アーキテクチャやフレームワーク、処理の内容や checkpoint (後述) を使うか等によりこの時間は変わってくる。<br>一例だが、AWS 環境において</p><ul><li>AWS Glue + Spark Structured Streaming</li><li>Amazon Kinesis Data Analytics + Flink</li></ul><p>の比較をしたことがある。<br>前者は再開に数分かかったのに対し、後者は1分未満で再開できた。<br>再開までの時間が十分に短いと判断できるのであればそのまま deploy, release してしまっていいだろう。</p><p>一方そうでない場合はどうすべきかという話が2点目。<br>再開までの時間が長く、システム要件的に許容できないというのであれば、release 時は二重で動かすというような措置が必要かもしれない。<br>おそらく <a href=https://www.publickey1.jp/blog/14/blue-green_deployment.html>Blue-Green Deployment</a> のようなことを考えることになるだろう。</p><h2 id=checkpoint>Checkpoint<a hidden class=anchor aria-hidden=true href=#checkpoint>#</a></h2><p>前述のとおり、ストリーム処理を行うシステムはずっと動き続けることが期待されている。<br>しかし予定された application の更新や不測のエラー等、何らかの理由で一時的に中断されるということが実際の運用中には起こる。</p><p>中断されたとき速やかに復帰する仕組みとして &ldquo;checkpoint&rdquo; というものがいくつかの consumer 側のフレームワークで提供されている。<br>雑に説明すると、処理のある時点における進捗や内部状態などをディスク等に永続化し、そこから処理を再開できるようにするものである。</p><ul><li><a href=https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#recovering-from-failures-with-checkpointing>Recovering from Failures with Checkpointing - Apache Spark</a></li><li><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html#checkpointing>Checkpointing - Apache Flink</a></li></ul><p>上記は Spark Structured Streaming と Flink の例だ。<br>checkpoint には次のようなメリットがあり、運用上有用だと言える。</p><ul><li>内部の状態を保持しているため、速やかに復帰できる</li><li>中断した位置から再開できるので出力に穴が開かない</li></ul><p>一方で落とし穴もある。<br>checkpoint では内部の状態が永続化されるわけだが、内部の状態というのは当然 application の実装が決めているものである。<br>application のコードを変更したとき、変更の内容によっては永続化された checkpoint と application が合わなくなることがあるのだ。<br>未定義の挙動となることもあるので、checkpoint の運用には十分に配慮する必要がある。<br>どのような変更なら checkpoint が安全に利用できるのかはフレームワークのドキュメントに記載があるので確認しておきたい。</p><h2 id=rdb-の世界との折り合い>RDB の世界との折り合い<a hidden class=anchor aria-hidden=true href=#rdb-の世界との折り合い>#</a></h2><p>みんな大好きな RDB の世界では table を操作してデータの処理を行う。<br>基本的には table というものはある時点における完全なデータセットを表すものである。 (ex. isolation)<br>他方、ストリーム処理はやってきたデータを逐次的に処理するものである (mini-batch の場合もあるが)。</p><p>直感的にこの2つは相性が悪そうに見える。<br>しかし Spark や Flink では table ベースの操作でストリーム処理を行うための API が提供されている。<br>おそらく</p><ul><li>ストリーム処理の周辺のデータソースとして RDB が存在する</li><li>RDB 的な table 操作があまりにも浸透している</li></ul><p>というところが API が必要である理由なのだろう。</p><p>ストリームデータを table 的に扱うというのが、やや直感的な理解をしにくいものとなっている。<br>フレームワークのドキュメントを確認しておきたい。</p><p>例えば Spark Structured Streaming であれば処理の出力のための3つの <a href=https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#output-modes>output mode</a> が示されている。</p><ul><li>Append mode: 追加された行だけ出力</li><li>Complete mode: table 全体を出力</li><li>Update mode: 更新された行だけ出力</li></ul><p>どれを選ぶかにより必要とする内部メモリの大きさも影響される。</p><h2 id=まとめ>まとめ<a hidden class=anchor aria-hidden=true href=#まとめ>#</a></h2><p>思ったより長文になってしまった。<br>結局ストリーム処理の難しさは以下の2点に尽きるだろう。</p><ul><li>複数の時間の概念</li><li>常時稼働のシステム</li></ul><p>独学なので抜け漏れがあったり、話が新しくなかったりすることもあると思われる。</p><h2 id=参考>参考<a hidden class=anchor aria-hidden=true href=#参考>#</a></h2><ul><li><a href=https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/>Streaming 101: The world beyond batch</a><ul><li>Apache Beam PMC によるストリーム処理の解説ポスト。必読</li></ul></li><li><a href=https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/>Streaming 102: The world beyond batch</a><ul><li>上の続きであり watermark について触れている</li></ul></li><li><a href=https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Analytics-Lens.pdf>Analytics Lens - AWS Well-Architected Framework</a><ul><li>AWS の資料。ストリーム処理のシステムの全体感がつかめる</li></ul></li><li><a href=https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html>Structured Streaming Programming Guide - Apache Spark</a><ul><li>Spark Structured Streaming のドキュメント。consumer の気持ちがわかる</li></ul></li><li><a href=https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html>Flink DataStream API Programming Guide - Apache Flink</a><ul><li>Flink のドキュメントの方がより詳しい。DataStream API の解説を中心に読むとよい</li></ul></li></ul></div><footer class=post-footer><ul class=post-tags><li><a href=https://soonraah.github.io/tags/apache-spark/>Apache Spark</a></li><li><a href=https://soonraah.github.io/tags/apache-flink/>Apache Flink</a></li><li><a href=https://soonraah.github.io/tags/stream-processing/>stream processing</a></li></ul><nav class=paginav><a class=prev href=https://soonraah.github.io/posts/functionality-of-streaming-system/><span class=title>« 前へ</span><br><span>ストリーム処理システムに求められる機能性、および Apache Flink におけるその対応</span>
</a><a class=next href=https://soonraah.github.io/posts/heavy-ab-testing-operation/><span class=title>次へ »</span><br><span>A/B テストの運用が重くてつらいという話</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと on x" href="https://x.com/intent/tweet/?text=%e3%83%90%e3%83%83%e3%83%81%e5%87%a6%e7%90%86%e3%81%8a%e3%81%98%e3%81%95%e3%82%93%e3%81%8c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%82%92%e9%96%8b%e7%99%ba%e3%81%99%e3%82%8b%e3%81%ab%e3%81%82%e3%81%9f%e3%81%a3%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%e3%81%93%e3%81%a8&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-streaming-system%2f&amp;hashtags=ApacheSpark%2cApacheFlink%2cstreamprocessing"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-streaming-system%2f&amp;title=%e3%83%90%e3%83%83%e3%83%81%e5%87%a6%e7%90%86%e3%81%8a%e3%81%98%e3%81%95%e3%82%93%e3%81%8c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%82%92%e9%96%8b%e7%99%ba%e3%81%99%e3%82%8b%e3%81%ab%e3%81%82%e3%81%9f%e3%81%a3%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%e3%81%93%e3%81%a8&amp;summary=%e3%83%90%e3%83%83%e3%83%81%e5%87%a6%e7%90%86%e3%81%8a%e3%81%98%e3%81%95%e3%82%93%e3%81%8c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%82%92%e9%96%8b%e7%99%ba%e3%81%99%e3%82%8b%e3%81%ab%e3%81%82%e3%81%9f%e3%81%a3%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%e3%81%93%e3%81%a8&amp;source=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-streaming-system%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-streaming-system%2f&title=%e3%83%90%e3%83%83%e3%83%81%e5%87%a6%e7%90%86%e3%81%8a%e3%81%98%e3%81%95%e3%82%93%e3%81%8c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%82%92%e9%96%8b%e7%99%ba%e3%81%99%e3%82%8b%e3%81%ab%e3%81%82%e3%81%9f%e3%81%a3%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%e3%81%93%e3%81%a8"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-streaming-system%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと on whatsapp" href="https://api.whatsapp.com/send?text=%e3%83%90%e3%83%83%e3%83%81%e5%87%a6%e7%90%86%e3%81%8a%e3%81%98%e3%81%95%e3%82%93%e3%81%8c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%82%92%e9%96%8b%e7%99%ba%e3%81%99%e3%82%8b%e3%81%ab%e3%81%82%e3%81%9f%e3%81%a3%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%e3%81%93%e3%81%a8%20-%20https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-streaming-system%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと on telegram" href="https://telegram.me/share/url?text=%e3%83%90%e3%83%83%e3%83%81%e5%87%a6%e7%90%86%e3%81%8a%e3%81%98%e3%81%95%e3%82%93%e3%81%8c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%82%92%e9%96%8b%e7%99%ba%e3%81%99%e3%82%8b%e3%81%ab%e3%81%82%e3%81%9f%e3%81%a3%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%e3%81%93%e3%81%a8&amp;url=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-streaming-system%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと on ycombinator" href="https://news.ycombinator.com/submitlink?t=%e3%83%90%e3%83%83%e3%83%81%e5%87%a6%e7%90%86%e3%81%8a%e3%81%98%e3%81%95%e3%82%93%e3%81%8c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%82%92%e9%96%8b%e7%99%ba%e3%81%99%e3%82%8b%e3%81%ab%e3%81%82%e3%81%9f%e3%81%a3%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%e3%81%93%e3%81%a8&u=https%3a%2f%2fsoonraah.github.io%2fposts%2fstudy-streaming-system%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2023 <a href=https://soonraah.github.io>Froglog</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="コピー";function s(){t.innerHTML="コピーされました!",setTimeout(()=>{t.innerHTML="コピー"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>