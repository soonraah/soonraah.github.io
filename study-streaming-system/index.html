<!doctype html>
<html lang="jp">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name="hugo-theme" content=" 0.7.1">



  <link rel="icon" type="image/png" sizes="32x32" href="/image/brand/favicon.png">
  <link rel="icon" type="image/x-icon" href="/favicon.ico">
  <link rel="apple-touch-icon" href="/">
  <link rel="canonical" href="https://soonraah.github.io/study-streaming-system/">
<link rel="preload" as="style" href="/bundle.css?v=1599378569" media="all">
<link rel="stylesheet" href="/bundle.css?v=1599378569" media="all">
<style>.cdata pre{color:#edf2f7;background-color:#2d3748}.cdata :not(pre)>code{color:#805ad5;background-color:#f7fafc}.chroma .err{color:#fed7d7;background-color:#9b2c2c}.chroma .hl{background-color:#4a5568}.chroma .ln{color:#a0aec0}.chroma .k,.chroma .kc,.chroma .kd,.chroma .kn,.chroma .kp,.chroma .kr{color:#63b3ed}.chroma .kt{color:#b794f4}.chroma .na{color:#f6e05e}.chroma .nb{color:#f6ad55}.chroma .nc{color:#fc8181}.chroma .no{color:#68d391}.chroma .nd{color:#fc8181}.chroma .ne{color:#fc8181}.chroma .nf{color:#f6ad55}.chroma .nt{color:#fc8181}.chroma .l{color:#b794f4}.chroma .dl,.chroma .ld,.chroma .s,.chroma .s2,.chroma .sa,.chroma .sb,.chroma .sc,.chroma .sd{color:#68d391}.chroma .se{color:#a0aec0}.chroma .s1,.chroma .sh,.chroma .si,.chroma .sr,.chroma .ss,.chroma .sx{color:#68d391}.chroma .il,.chroma .m,.chroma .mb,.chroma .mf,.chroma .mh,.chroma .mi,.chroma .mo{color:#b794f4}.chroma .o,.chroma .ow{color:#90cdf4}.chroma .p{color:#cbd5e0}.chroma .c,.chroma .c1,.chroma .ch,.chroma .cm,.chroma .cp,.chroma .cpf,.chroma .cs{color:#a0aec0}.chroma .ge{font-style:italic}.chroma .gs{font-weight:700}</style>



<title>バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと : Froglog</title>

<meta property="og:title" content="バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと">
<meta property="og:site_name" content="Froglog">
<meta property="og:url" content="https://soonraah.github.io/study-streaming-system/">
<link rel="image_src" href="https://soonraah.github.io/">
<meta property="og:image" content="https://soonraah.github.io/">
<meta property="og:image:width" content="2048">
<meta property="og:image:height" content="1024">
<meta property="og:type" content="article">
<meta property="og:locale" content="jp">
<meta property="og:description" content="Photo by Jon Flobrant on Unsplash   ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。 それにあたって独学で調べたことなどまとめておく。 ストリーム処理とは そもそも &amp;quot;ストリーム処理&amp;quot; とは何を指しているのか。 以下の引用が簡潔に示している。  a type of data processing engine that is designed with infinite data sets in mind. Nothing more. — Tyler Akidau Streaming 101: The world beyond batch  こちらは &amp;quot;streaming system&amp;quot; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。">
<meta name="description" content="Photo by Jon Flobrant on Unsplash   ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。 それにあたって独学で調べたことなどまとめておく。 ストリーム処理とは そもそも &amp;quot;ストリーム処理&amp;quot; とは何を指しているのか。 以下の引用が簡潔に示している。  a type of data processing engine that is designed with infinite data sets in mind. Nothing more. — Tyler Akidau Streaming 101: The world beyond batch  こちらは &amp;quot;streaming system&amp;quot; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。">
<meta property="og:updated_time" content="2020-09-06T07:30:00Z">
<meta property="fb:app_id" content="">
<meta name="author" content="soonraah">
<meta property="article:author" content="https://soonraah.github.io/">
<meta property="article:published_time" content="2020-09-06T07:30:00Z">
<meta property="article:modified_time" content="2020-09-06T07:30:00Z">
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "headline": "バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと",
  "alternativeHeadline": "Photo by Jon Flobrant on Unsplash   ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。 それにあたって独学で調べたことなどまとめておく。 ストリーム処理とは そもそも \u0026quot;ストリーム処理\u0026quot; とは何を指しているのか。 以下の引用が簡潔に示している。  a type of data processing engine that is designed with infinite data sets in mind. Nothing more. — Tyler Akidau Streaming 101: The world beyond batch  こちらは \u0026quot;streaming system\u0026quot; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。",
  "url": "https://soonraah.github.io/study-streaming-system/",
  "image": "https://soonraah.github.io/",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://soonraah.github.io/study-streaming-system/"
  },
  "description": "Photo by Jon Flobrant on Unsplash   ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。 それにあたって独学で調べたことなどまとめておく。 ストリーム処理とは そもそも \u0026quot;ストリーム処理\u0026quot; とは何を指しているのか。 以下の引用が簡潔に示している。  a type of data processing engine that is designed with infinite data sets in mind. Nothing more. — Tyler Akidau Streaming 101: The world beyond batch  こちらは \u0026quot;streaming system\u0026quot; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。",
  "author": {
    "@type": "Person",
    "name": "soonraah"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Froglog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://soonraah.github.io/"
    }
  },
  "datePublished": "2020-09-06T07:30:00Z",
  "dateModified": "2020-09-06T07:30:00Z",
  "articleBody": "\n\n\u003cfigure class=\"center\"\u003e\n\u003cimg\nclass=\"mb-2 mx-auto leading-none shadow-xl\"\nsrc=\"/image/photo/jon-flobrant-rB7-LCa_diU-unsplash.jpg\"\nalt=\"Photo by Jon Flobrant on\"\u003e\n\u003cfigcaption class=\"text-sm text-right text-raven-500\"\u003e\n\u003cp\u003ePhoto by Jon Flobrant on \u003ca href=\"https://unsplash.com/photos/rB7-LCa_diU\"\u003eUnsplash\u003c/a\u003e\u003c/p\u003e\n\u003c/figcaption\u003e\n\u003c/figure\u003e\n\n\u003cp\u003eほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。\u003cbr\u003e\nそれにあたって独学で調べたことなどまとめておく。\u003c/p\u003e\n\u003ch2 id=\"ストリーム処理とは\"\u003eストリーム処理とは\u003c/h2\u003e\n\u003cp\u003eそもそも \u0026quot;ストリーム処理\u0026quot; とは何を指しているのか。\u003cbr\u003e\n以下の引用が簡潔に示している。\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003ea type of data processing engine that is designed with infinite data sets in mind. Nothing more.\u003c/p\u003e\n  \u003cfooter\u003e\u0026#8212; Tyler Akidau \u003ccite title=\"Streaming 101: The world beyond batch\"\u003e\u003ca rel=\"noopener nofollow\" href=\"https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/\"\u003eStreaming 101: The world beyond batch\u003c/a\u003e\u003c/cite\u003e\u003c/footer\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eこちらは \u0026quot;streaming system\u0026quot; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。\u003c/p\u003e\n\u003cp\u003e例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。\u003cbr\u003e\nweb サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。\u003c/p\u003e\n\u003cp\u003eこれに対して \u0026quot;1日分のユーザ行動ログ\u0026quot; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。\u003cbr\u003e\nストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。\u003cbr\u003e\nこの後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。\u003c/p\u003e\n\u003ch2 id=\"なぜストリーム処理なのか\"\u003eなぜストリーム処理なのか\u003c/h2\u003e\n\u003cp\u003eなぜストリーム処理なのか。\u003cbr\u003e\nひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。\u003cbr\u003e\n迅速なフィードバックがビジネス上のメリットとなることは自明だ。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSNS の配信\u003c/li\u003e\n\u003cli\u003eカーシェアリングにおける配車や料金設定\u003c/li\u003e\n\u003cli\u003eクレジットカードや広告クリックなどの不正検知\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eもしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。\u003cbr\u003e\nまあ待っていられない。\u003c/p\u003e\n\u003ch2 id=\"一般的なストリーム処理の構成\"\u003e一般的なストリーム処理の構成\u003c/h2\u003e\n\u003cp\u003eモダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eproducer\u003c/li\u003e\n\u003cli\u003ebroker\u003c/li\u003e\n\u003cli\u003econsumer\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eproducer は最初にレコードを生成する、ストリームデータの発生源となるものである。\u003cbr\u003e\n例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。\u003cbr\u003e\nproducer は絶え間なくログを生成し、それを broker へと送る。\u003c/p\u003e\n\u003cp\u003ebroker は producer から送られたログを格納し、任意のタイミングで取り出せるようにするものである。\u003cbr\u003e\n誤解を恐れずに言うとメッセージキューに近いイメージだ。\u003cbr\u003e\nApache Kafka クラスタや Amazon Kinesis Data Streams 等がこれに該当する。\u003c/p\u003e\n\u003cp\u003econsumer は broker からログを取り出し、それに対し何かしらの処理を行うものだ。\u003cbr\u003e\ntime window 集計であったりログからの異常検知であったり、処理した結果として何かビジネス上意味があるものを得るのである。\u003cbr\u003e\nこれを行うフレームワークとしては Spark Streaming や Apache Flink 等がメジャーなのだろうか。\u003c/p\u003e\n\u003cp\u003eproducer と consumer の間に broker を挟むメリットとしては次のようなことが挙げられる。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eproducer が M 個、consumer が N 個の場合に M * N の関係になるところを broker を挟めば M + N にできる\n\u003cul\u003e\n\u003cli\u003eproducer, consumer に多数のシステムがあったとしても各自は broker との接続だけを考えればよい\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e任意のタイミングでデータを読み出せる\u003c/li\u003e\n\u003cli\u003eproducer または consumer に問題が発生してもデータロスが起こりにくくできる\n\u003cul\u003e\n\u003cli\u003eその分 broker には高い可用性が求められる\n\u003cul\u003e\n\u003cli\u003eKafka はクラスタで冗長構成\u003c/li\u003e\n\u003cli\u003eKinesis Data Streams は複数 AZ でレプリケーション\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"時間の概念\"\u003e時間の概念\u003c/h2\u003e\n\u003cp\u003eストリーム処理では時間の概念がいくつかあり、集計などの処理をどの時間をベースにして実行するのか、意識する必要がある。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eevent time\n\u003cul\u003e\n\u003cli\u003eproducer 側でログイベントが発生した時間\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eingestion time\n\u003cul\u003e\n\u003cli\u003ebroker にそのログイベントのレコードが挿入された時間\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eprocessing time\n\u003cul\u003e\n\u003cli\u003econsumer 側でレコードを処理した時間\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eprocessing time を使うのが一番簡単なのだが、おそらく分析系の処理であれば window 集計等では event time を使うことが多いのではないだろうか。\u003c/p\u003e\n\u003cp\u003eingestion time はおそらく実際のプロダクトではあまり使われないのではと思われる。\u003cbr\u003e\n(ネットワークのパフォーマンスを見るぐらい？)\u003c/p\u003e\n\u003ch2 id=\"windowing\"\u003eWindowing\u003c/h2\u003e\n\u003cp\u003eストリーム処理の中で \u003ccode\u003esum\u003c/code\u003e, \u003ccode\u003ecount\u003c/code\u003e などを伴う集計処理を行う場合、通常は時間方向の window で切って処理するということになるのではないだろうか。\u003cbr\u003e\nwindow で切らずに完全なデータセットがそろうまで待つことはできないし、データが来るたびに逐次的に全体の結果を更新するしていくというのも割に合わない。\u003c/p\u003e\n\u003cp\u003ewindow の切り方もいくつかある。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003etumbling window\n\u003cul\u003e\n\u003cli\u003e固定長でオーバーラップしない\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003esliding window\n\u003cul\u003e\n\u003cli\u003e固定長でオーバーラップを含む\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003esession window\n\u003cul\u003e\n\u003cli\u003eいわゆる web の session のように、ある種のイベントがある期間発生しないことにより window が区切られる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eこれらについては \u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html\"\u003eFlink のドキュメント\u003c/a\u003eが図もあってわかりやすい。\u003c/p\u003e\n\u003cp\u003e個人的な感想だが、この time window の集計がない単なる \u003ccode\u003emap\u003c/code\u003e 的なストリーム処理であれば traditional なアーキテクチャでも難しくはない。\u003cbr\u003e\nしかし time window 集計が必要となった場合は Spark Streaming 等のモダンなフレームワークが威力を発揮してくる。\u003c/p\u003e\n\u003ch2 id=\"watermark\"\u003eWatermark\u003c/h2\u003e\n\u003cp\u003e時間で window を切るときは、前述のどの時間の定義を用いるかを考えなければいけない。\u003cbr\u003e\nprocessing time を用いる場合は簡単だが event time はやや難しい。\u003cbr\u003e\nconsumer 側では event のレコードがどれくらい遅れてやってくるかわからないためだ。\u003c/p\u003e\n\u003cp\u003eネットワークその他の影響により、event のレコードが producer -\u0026gt; broker -\u0026gt; consumer という経路で consumer に届くまでの時間というのは一定にはならない。\u003cbr\u003e\nまた、古い event が新しい event より後に届くというように順番が前後することも起こりうる。\u003cbr\u003e\nここで \u0026quot;watermark\u0026quot; という考え方が必要になってくる。\u003c/p\u003e\n\n\u003cblockquote\u003e\n  \u003cp\u003eA watermark with a value of time X makes the statement: \u0026#34;all input data with event times less than X have been observed.\u0026#34;\u003c/p\u003e\n  \u003cfooter\u003e\u0026#8212; Tyler Akidau \u003ccite title=\"Streaming 102: The world beyond batch\"\u003e\u003ca rel=\"noopener nofollow\" href=\"https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/\"\u003eStreaming 102: The world beyond batch\u003c/a\u003e\u003c/cite\u003e\u003c/footer\u003e\n\u003c/blockquote\u003e\n\n\u003cp\u003eある processing time において「event time X より前のレコードはすべて到着したよ」というのが watermark である。\u003cbr\u003e\n別の言い方をすると watermark により event のレコードがどの程度遅延してもよいかが定義される。\u003c/p\u003e\n\u003cp\u003eevent time X より前のレコードが真の意味ですべて到着した、というのは難しい。\u003cbr\u003e\n実際には heuristic にどの程度遅れていいかを決め、それより遅れた場合はある event time 期間における window 処理には含めないということになる。\u003c/p\u003e\n\u003cp\u003ewatermark の決め方はフレームワーク次第だろうか。\u003cbr\u003e\n例えば \u003ca href=\"https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#handling-late-data-and-watermarking\"\u003eSpark Structured Streaming\u003c/a\u003e の例だと図もあって比較的わかりやすい。\u003c/p\u003e\n\u003ch2 id=\"schema-evolution\"\u003eSchema Evolution\u003c/h2\u003e\n\u003cp\u003e何らかの業務システムや web システム等をある程度運用したことがある人ならわかると思うが、データの schema というのはナマモノだ。\u003cbr\u003e\n一度決めたら終わりというわけではなくプロダクトやビジネスの変化に応じて変化していく。\u003cbr\u003e\nカラムが増えたり、削除されたり、名前や型が変わったり…\u003cbr\u003e\nこのようにデータの構造が変化していくこと、またはそれを扱うことを \u0026quot;schema evolution\u0026quot; という。\u003c/p\u003e\n\u003cp\u003eバッチ処理において schema の変更に追従することを考えるのはそれほど難しくない。\u003cbr\u003e\nhourly のバッチ処理であったとしても、バッチ処理とバッチ処理の間の時間で application を更新すればいいだけだ。\u003cbr\u003e\n(が、実際に行うのは困難が伴うことも多い)\u003c/p\u003e\n\u003cp\u003eではストリーム処理ではどうだろうか。\u003cbr\u003e\nいわゆるストリーム処理においては処理と処理の間というものがなく、application がずっと稼働しっぱなしということになる。\u003cbr\u003e\nバッチ処理のような更新はできない。\u003cbr\u003e\nもっと言うと producer で生まれた新しい schema のレコードがいつ届くかもわからない。\u003c/p\u003e\n\u003cp\u003eおそらくこの問題には2つの対応方法がある。\u003cbr\u003e\n1つめは consumer 側のシステムで前方互換性を保つという方法である。\u003cbr\u003e\nこの場合、新しいフィールドは必ず末尾に追加される等、producer 側での schema 更新についてある程度のルールが必要となるだろう。\u003cbr\u003e\nproducer 側で生成されるレコードの schema の変更が必ず事前にわかるというのであれば後方互換性でもいいが、多くの場合は難しい。\u003cbr\u003e\nところで\u003ca href=\"https://ja.wikipedia.org/wiki/%E4%BA%92%E6%8F%9B%E6%80%A7\"\u003e前方互換と後方互換\u003c/a\u003e、どっちがどっちなのか覚えられません。\u003c/p\u003e\n\u003cp\u003e2つめの方法として schema 情報をレコード自体に入れ込んでしまうという方法もある。\u003cbr\u003e\n\u003ca href=\"https://avro.apache.org/\"\u003eApach Avro\u003c/a\u003e のような serialization の方法を取っているとレコード自体に schema の情報を付与することができる。\u003c/p\u003e\n\u003cp\u003eおそらく最もエレガントにこれをやるのが Confluent の \u003ca href=\"https://docs.confluent.io/current/schema-registry/index.html\"\u003eSchema Registry\u003c/a\u003e という機能だ。\u003cbr\u003e\nproducer から送出されるレコードには schema ID を付与する。\u003cbr\u003e\nschema の実体は Schema Registry という broker とは別の場所で管理されており、consumer 側では受け取ったレコードに付与されている schema ID と Schema Registry に登録されている shcema の実体を参照してレコードを deserialize することができる。\u003c/p\u003e\n\u003ch2 id=\"deploy\"\u003eDeploy\u003c/h2\u003e\n\u003cp\u003eストリーム処理を行うシステムは終わりのないデータを処理するためのものであり、ずっと動き続けることが期待されている。\u003cbr\u003e\nしかし通常システムは一度立ち上げれば終わりということではなく、運用されている中で更新していく必要がある。\u003c/p\u003e\n\u003cp\u003eずっと動かしながらどのように deploy, release するのか。\u003cbr\u003e\nこの問題は主に consumer 側のシステムで配慮が必要になると思われる。\u003cbr\u003e\n正直これについてはちゃんと調べられていないが、2点ほど述べておきたい。\u003c/p\u003e\n\u003cp\u003eまず1点目、application を中断・更新・再開するのにどの程度の時間がかかるのかを知っておく必要があるということ。\u003cbr\u003e\nアーキテクチャやフレームワーク、処理の内容や checkpoint (後述) を使うか等によりこの時間は変わってくる。\u003cbr\u003e\n一例だが、AWS 環境において\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAWS Glue + Spark Structured Streaming\u003c/li\u003e\n\u003cli\u003eAmazon Kinesis Data Analytics + Flink\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eの比較をしたことがある。\u003cbr\u003e\n前者は再開に数分かかったのに対し、後者は1分未満で再開できた。\u003cbr\u003e\n再開までの時間が十分に短いと判断できるのであればそのまま deploy, release してしまっていいだろう。\u003c/p\u003e\n\u003cp\u003e一方そうでない場合はどうすべきかという話が2点目。\u003cbr\u003e\n再開までの時間が長く、システム要件的に許容できないというのであれば、release 時は二重で動かすというような措置が必要かもしれない。\u003cbr\u003e\nおそらく \u003ca href=\"https://www.publickey1.jp/blog/14/blue-green_deployment.html\"\u003eBlue-Green Deployment\u003c/a\u003e のようなことを考えることになるだろう。\u003c/p\u003e\n\u003ch2 id=\"checkpoint\"\u003eCheckpoint\u003c/h2\u003e\n\u003cp\u003e前述のとおり、ストリーム処理を行うシステムはずっと動き続けることが期待されている。\u003cbr\u003e\nしかし予定された application の更新や不測のエラー等、何らかの理由で一時的に中断されるということが実際の運用中には起こる。\u003c/p\u003e\n\u003cp\u003e中断されたとき速やかに復帰する仕組みとして \u0026quot;checkpoint\u0026quot; というものがいくつかの consumer 側のフレームワークで提供されている。\u003cbr\u003e\n雑に説明すると、処理のある時点における進捗や内部状態などをディスク等に永続化し、そこから処理を再開できるようにするものである。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#recovering-from-failures-with-checkpointing\"\u003eRecovering from Failures with Checkpointing - Apache Spark\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html#checkpointing\"\u003eCheckpointing - Apache Flink\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e上記は Spark Structured Streaming と Flink の例だ。\u003cbr\u003e\ncheckpoint には次のようなメリットがあり、運用上有用だと言える。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e内部の状態を保持しているため、速やかに復帰できる\u003c/li\u003e\n\u003cli\u003e中断した位置から再開できるので出力に穴が開かない\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e一方で落とし穴もある。\u003cbr\u003e\ncheckpoint では内部の状態が永続化されるわけだが、内部の状態というのは当然 application の実装が決めているものである。\u003cbr\u003e\napplication のコードを変更したとき、変更の内容によっては永続化された checkpoint と application が合わなくなることがあるのだ。\u003cbr\u003e\n未定義の挙動となることもあるので、checkpoint の運用には十分に配慮する必要がある。\u003cbr\u003e\nどのような変更なら checkpoint が安全に利用できるのかはフレームワークのドキュメントに記載があるので確認しておきたい。\u003c/p\u003e\n\u003ch2 id=\"rdb-の世界との折り合い\"\u003eRDB の世界との折り合い\u003c/h2\u003e\n\u003cp\u003eみんな大好きな RDB の世界では table を操作してデータの処理を行う。\u003cbr\u003e\n基本的には table というものはある時点における完全なデータセットを表すものである。 (ex. isolation)\u003cbr\u003e\n他方、ストリーム処理はやってきたデータを逐次的に処理するものである (mini-batch の場合もあるが)。\u003c/p\u003e\n\u003cp\u003e直感的にこの2つは相性が悪そうに見える。\u003cbr\u003e\nしかし Spark や Flink では table ベースの操作でストリーム処理を行うための API が提供されている。\u003cbr\u003e\nおそらく\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eストリーム処理の周辺のデータソースとして RDB が存在する\u003c/li\u003e\n\u003cli\u003eRDB 的な table 操作があまりにも浸透している\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eというところが API が必要である理由なのだろう。\u003c/p\u003e\n\u003cp\u003eストリームデータを table 的に扱うというのが、やや直感的な理解をしにくいものとなっている。\u003cbr\u003e\nフレームワークのドキュメントを確認しておきたい。\u003c/p\u003e\n\u003cp\u003e例えば Spark Structured Streaming であれば処理の出力のための3つの \u003ca href=\"https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#output-modes\"\u003eoutput mode\u003c/a\u003e が示されている。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAppend mode: 追加された行だけ出力\u003c/li\u003e\n\u003cli\u003eComplete mode: table 全体を出力\u003c/li\u003e\n\u003cli\u003eUpdate mode: 更新された行だけ出力\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eどれを選ぶかにより必要とする内部メモリの大きさも影響される。\u003c/p\u003e\n\u003ch2 id=\"まとめ\"\u003eまとめ\u003c/h2\u003e\n\u003cp\u003e思ったより長文になってしまった。\u003cbr\u003e\n結局ストリーム処理の難しさは以下の2点に尽きるだろう。\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e複数の時間の概念\u003c/li\u003e\n\u003cli\u003e常時稼働のシステム\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e独学なので抜け漏れがあったり、話が新しくなかったりすることもあると思われる。\u003c/p\u003e\n\u003ch2 id=\"参考\"\u003e参考\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/\"\u003eStreaming 101: The world beyond batch\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eApache Beam PMC によるストリーム処理の解説ポスト。必読\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/\"\u003eStreaming 102: The world beyond batch\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e上の続きであり watermark について触れている\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Analytics-Lens.pdf\"\u003eAnalytics Lens - AWS Well-Architected Framework\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eAWS の資料。ストリーム処理のシステムの全体感がつかめる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html\"\u003eStructured Streaming Programming Guide - Apache Spark\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eSpark Structured Streaming のドキュメント。consumer の気持ちがわかる\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html\"\u003eFlink DataStream API Programming Guide - Apache Flink\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003eFlink のドキュメントの方がより詳しい。DataStream API の解説を中心に読むとよい\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e"
}
</script>

<link rel="preload" as="script" href="/bundle.js?v=1599378569">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://stats.g.doubleclick.net">
<link rel="preconnect" href="https://www.googleadservices.com">
<link rel="preload" as="script" href="https://www.googletagmanager.com/gtag/js?id=UA-73329599-2">
<script src="https://www.googletagmanager.com/gtag/js?id=UA-73329599-2"></script>
<script>
  window.dataLayer=window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js',new Date());
  gtag('config','UA-73329599-2');
</script>

</head>
<body>

  <header id="nav" class="header">
  <div class="ax-l-i max-w-6xl">
    <div class="ax-logo">
      <a class="block" href="/" title="Froglog"><span class="font-semibold text-raven-900">Froglog</span></a>
    </div>
    <div class="ax-user">
      <a class="p-2 w-8 h-8 block text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" target="_blank" rel="noopener nofollow" href="https://www.google.com/search?q=site:soonraah.github.io" title="">
        <svg class="fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M2.67 12.804c0-5.6 4.544-10.134 10.133-10.134s10.134 4.544 10.134 10.134-4.544 10.133-10.134 10.133S2.67 18.393 2.67 12.804zm28.943 16.923l-8.868-8.868c4.287-5.3 3.68-13.012-1.378-17.57S8.564-1.066 3.75 3.75s-5.017 12.558-.46 17.618 12.28 5.665 17.57 1.378l8.868 8.868a1.33 1.33 0 0 0 2.231-.597c.123-.46-.008-.952-.345-1.29h0z"/></svg>

      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/posts/">
        Posts
      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/tags/">
        Tags
      </a>
      <a class="p-2 block text-base leading-none text-raven-500 hover:text-gray-800 focus:text-gray-800 focus:outline-none" href="/about/">
        About
      </a>
    </div>
  </div>

  
</header>

  <main>
<div class="default-single">
  <div class="ax-title ax-l-o">
    <div class="ax-l-i max-w-680">
      <h1 class="post-title font-content-title font-normal leading-tight tracking-default text-40">バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと</h1>

      <div class="ax-meta flex items-center mt-5">
        <div class="flex-grow min-w-0">
          <div class="flex items-center">
  <div class="flex-shrink-0">
    <img
    class="w-12 h-12 sm:w-14 sm:h-14 object-cover p-3px rounded-full border border-blue-300"
    src="/image/author/soonraah.png"
    alt="soonraah">
  </div>
  <div class="flex-shrink-0 ml-2 leading-tight font-content-sans">
    <a class="block text-sm text-raven-800 hover:text-raven-900 hover:underline focus:underline" target="_blank" rel="noopener nofollow" title="soonraah" href="https://soonraah.github.io/">soonraah</a>
    <time class="text-sm text-raven-500" datetime="2020-09-06T07:30:00Z">2020-09-06 16:30</time>
  </div>
</div>

        </div>
        <div>
          <div class="flex items-center">
  <a class="flex-shrink-0 block text-raven-800 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="" href="https://twitter.com/intent/tweet?text=%e3%83%90%e3%83%83%e3%83%81%e5%87%a6%e7%90%86%e3%81%8a%e3%81%98%e3%81%95%e3%82%93%e3%81%8c%e3%82%b9%e3%83%88%e3%83%aa%e3%83%bc%e3%83%a0%e5%87%a6%e7%90%86%e3%81%ae%e3%82%b7%e3%82%b9%e3%83%86%e3%83%a0%e3%82%92%e9%96%8b%e7%99%ba%e3%81%99%e3%82%8b%e3%81%ab%e3%81%82%e3%81%9f%e3%81%a3%e3%81%a6%e8%aa%bf%e3%81%b9%e3%81%9f%e3%81%93%e3%81%a8%20by%20%40soonraah%20https%3a%2f%2fsoonraah.github.io%2fstudy-streaming-system%2f"><svg class="w-6 h-6 fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M32 6.078c-1.2.522-2.458.868-3.78 1.036 1.36-.812 2.398-2.088 2.886-3.626a13.11 13.11 0 0 1-4.16 1.588C25.742 3.794 24.026 3 22.154 3a6.56 6.56 0 0 0-6.556 6.562c0 .52.044 1.02.152 1.496-5.454-.266-10.28-2.88-13.522-6.862-.566.982-.898 2.106-.898 3.316a6.57 6.57 0 0 0 2.914 5.452 6.48 6.48 0 0 1-2.964-.808v.072c0 3.188 2.274 5.836 5.256 6.446-.534.146-1.116.216-1.72.216-.42 0-.844-.024-1.242-.112.85 2.598 3.262 4.508 6.13 4.57a13.18 13.18 0 0 1-8.134 2.798c-.538 0-1.054-.024-1.57-.1C2.906 27.93 6.35 29 10.064 29c12.072 0 18.672-10 18.672-18.668 0-.3-.01-.57-.024-.848C30.014 8.56 31.108 7.406 32 6.078z"/></svg>
</a>
  <a class="ml-3 flex-shrink-0 block text-raven-800 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="" href="https://www.facebook.com/dialog/share?app_id=&display=page&href=https%3a%2f%2fsoonraah.github.io%2fstudy-streaming-system%2f"><svg class="w-6 h-6 fill-current" viewBox="-7 -3.5 39 39" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M30.234 0H1.765C.8.001 0 .79 0 1.766v28.47C.001 31.2.79 32 1.766 32h15.328V19.625h-4.156V14.78h4.156v-3.564c0-4.134 2.523-6.384 6.21-6.384 1.766 0 3.284.13 3.726.2v4.32h-2.543c-2.006 0-2.394.953-2.394 2.352v3.085h4.797l-.625 4.844h-4.172V32h8.14C31.21 32 32 31.2 32 30.234V1.765C32 .8 31.21 0 30.234 0z"/></svg>
</a>
</div>

        </div>
      </div>
    </div>
  </div><div class="ax-content ax-l-o">
    <div class="ax-l-i max-w-680">
      <article class="cdata">


<figure class="center">
<img
class="mb-2 mx-auto leading-none shadow-xl"
src="/image/photo/jon-flobrant-rB7-LCa_diU-unsplash.jpg"
alt="Photo by Jon Flobrant on">
<figcaption class="text-sm text-right text-raven-500">
<p>Photo by Jon Flobrant on <a href="https://unsplash.com/photos/rB7-LCa_diU">Unsplash</a></p>
</figcaption>
</figure>

<p>ほとんどバッチ処理しか書いたことのない者だがストリーム処理のシステムを開発することになった。<br>
それにあたって独学で調べたことなどまとめておく。</p>
<h2 id="ストリーム処理とは">ストリーム処理とは</h2>
<p>そもそも &quot;ストリーム処理&quot; とは何を指しているのか。<br>
以下の引用が簡潔に示している。</p>

<blockquote>
  <p>a type of data processing engine that is designed with infinite data sets in mind. Nothing more.</p>
  <footer>&#8212; Tyler Akidau <cite title="Streaming 101: The world beyond batch"><a rel="noopener nofollow" href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/">Streaming 101: The world beyond batch</a></cite></footer>
</blockquote>

<p>こちらは &quot;streaming system&quot; について述べたものだが、つまり終わりのないデータを扱うのがストリーム処理ということである。</p>
<p>例えば web サービスから生まれ続けるユーザ行動ログを逐次的に処理するというのがストリーム処理。<br>
web サービスが終了しないかぎりはユーザ行動ログの生成には終わりがない。</p>
<p>これに対して &quot;1日分のユーザ行動ログ&quot; 等のように有限の量のデータを切り出して処理する場合、これはバッチ処理となる。<br>
ストリーム処理とバッチ処理の違いは扱うデータが無限なのか有限なのかということだ。<br>
この後触れていくが、この終わりのないデータを継続的に処理し続けるというところにバッチ処理にはない難しさがある。</p>
<h2 id="なぜストリーム処理なのか">なぜストリーム処理なのか</h2>
<p>なぜストリーム処理なのか。<br>
ひとえに逐次的な入力データに対する迅速なフィードバックが求められているからと言えるだろう。<br>
迅速なフィードバックがビジネス上のメリットとなることは自明だ。</p>
<ul>
<li>SNS の配信</li>
<li>カーシェアリングにおける配車や料金設定</li>
<li>クレジットカードや広告クリックなどの不正検知</li>
</ul>
<p>もしこれらの application が例えば hourly のバッチ処理で実装されていたらどうだろうか。<br>
まあ待っていられない。</p>
<h2 id="一般的なストリーム処理の構成">一般的なストリーム処理の構成</h2>
<p>モダンな…と言っていいのかわからないが、ストリーム処理を行うための一般的なシステムは次の3つの要素で構成される。</p>
<ul>
<li>producer</li>
<li>broker</li>
<li>consumer</li>
</ul>
<p>producer は最初にレコードを生成する、ストリームデータの発生源となるものである。<br>
例えばログを生成する web application であったり、何らかのセンサーを持つ IoT 機器であったりがこれに該当する。<br>
producer は絶え間なくログを生成し、それを broker へと送る。</p>
<p>broker は producer から送られたログを格納し、任意のタイミングで取り出せるようにするものである。<br>
誤解を恐れずに言うとメッセージキューに近いイメージだ。<br>
Apache Kafka クラスタや Amazon Kinesis Data Streams 等がこれに該当する。</p>
<p>consumer は broker からログを取り出し、それに対し何かしらの処理を行うものだ。<br>
time window 集計であったりログからの異常検知であったり、処理した結果として何かビジネス上意味があるものを得るのである。<br>
これを行うフレームワークとしては Spark Streaming や Apache Flink 等がメジャーなのだろうか。</p>
<p>producer と consumer の間に broker を挟むメリットとしては次のようなことが挙げられる。</p>
<ul>
<li>producer が M 個、consumer が N 個の場合に M * N の関係になるところを broker を挟めば M + N にできる
<ul>
<li>producer, consumer に多数のシステムがあったとしても各自は broker との接続だけを考えればよい</li>
</ul>
</li>
<li>任意のタイミングでデータを読み出せる</li>
<li>producer または consumer に問題が発生してもデータロスが起こりにくくできる
<ul>
<li>その分 broker には高い可用性が求められる
<ul>
<li>Kafka はクラスタで冗長構成</li>
<li>Kinesis Data Streams は複数 AZ でレプリケーション</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="時間の概念">時間の概念</h2>
<p>ストリーム処理では時間の概念がいくつかあり、集計などの処理をどの時間をベースにして実行するのか、意識する必要がある。</p>
<ul>
<li>event time
<ul>
<li>producer 側でログイベントが発生した時間</li>
</ul>
</li>
<li>ingestion time
<ul>
<li>broker にそのログイベントのレコードが挿入された時間</li>
</ul>
</li>
<li>processing time
<ul>
<li>consumer 側でレコードを処理した時間</li>
</ul>
</li>
</ul>
<p>processing time を使うのが一番簡単なのだが、おそらく分析系の処理であれば window 集計等では event time を使うことが多いのではないだろうか。</p>
<p>ingestion time はおそらく実際のプロダクトではあまり使われないのではと思われる。<br>
(ネットワークのパフォーマンスを見るぐらい？)</p>
<h2 id="windowing">Windowing</h2>
<p>ストリーム処理の中で <code>sum</code>, <code>count</code> などを伴う集計処理を行う場合、通常は時間方向の window で切って処理するということになるのではないだろうか。<br>
window で切らずに完全なデータセットがそろうまで待つことはできないし、データが来るたびに逐次的に全体の結果を更新するしていくというのも割に合わない。</p>
<p>window の切り方もいくつかある。</p>
<ul>
<li>tumbling window
<ul>
<li>固定長でオーバーラップしない</li>
</ul>
</li>
<li>sliding window
<ul>
<li>固定長でオーバーラップを含む</li>
</ul>
</li>
<li>session window
<ul>
<li>いわゆる web の session のように、ある種のイベントがある期間発生しないことにより window が区切られる</li>
</ul>
</li>
</ul>
<p>これらについては <a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/operators/windows.html">Flink のドキュメント</a>が図もあってわかりやすい。</p>
<p>個人的な感想だが、この time window の集計がない単なる <code>map</code> 的なストリーム処理であれば traditional なアーキテクチャでも難しくはない。<br>
しかし time window 集計が必要となった場合は Spark Streaming 等のモダンなフレームワークが威力を発揮してくる。</p>
<h2 id="watermark">Watermark</h2>
<p>時間で window を切るときは、前述のどの時間の定義を用いるかを考えなければいけない。<br>
processing time を用いる場合は簡単だが event time はやや難しい。<br>
consumer 側では event のレコードがどれくらい遅れてやってくるかわからないためだ。</p>
<p>ネットワークその他の影響により、event のレコードが producer -&gt; broker -&gt; consumer という経路で consumer に届くまでの時間というのは一定にはならない。<br>
また、古い event が新しい event より後に届くというように順番が前後することも起こりうる。<br>
ここで &quot;watermark&quot; という考え方が必要になってくる。</p>

<blockquote>
  <p>A watermark with a value of time X makes the statement: &#34;all input data with event times less than X have been observed.&#34;</p>
  <footer>&#8212; Tyler Akidau <cite title="Streaming 102: The world beyond batch"><a rel="noopener nofollow" href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/">Streaming 102: The world beyond batch</a></cite></footer>
</blockquote>

<p>ある processing time において「event time X より前のレコードはすべて到着したよ」というのが watermark である。<br>
別の言い方をすると watermark により event のレコードがどの程度遅延してもよいかが定義される。</p>
<p>event time X より前のレコードが真の意味ですべて到着した、というのは難しい。<br>
実際には heuristic にどの程度遅れていいかを決め、それより遅れた場合はある event time 期間における window 処理には含めないということになる。</p>
<p>watermark の決め方はフレームワーク次第だろうか。<br>
例えば <a href="https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#handling-late-data-and-watermarking">Spark Structured Streaming</a> の例だと図もあって比較的わかりやすい。</p>
<h2 id="schema-evolution">Schema Evolution</h2>
<p>何らかの業務システムや web システム等をある程度運用したことがある人ならわかると思うが、データの schema というのはナマモノだ。<br>
一度決めたら終わりというわけではなくプロダクトやビジネスの変化に応じて変化していく。<br>
カラムが増えたり、削除されたり、名前や型が変わったり…<br>
このようにデータの構造が変化していくこと、またはそれを扱うことを &quot;schema evolution&quot; という。</p>
<p>バッチ処理において schema の変更に追従することを考えるのはそれほど難しくない。<br>
hourly のバッチ処理であったとしても、バッチ処理とバッチ処理の間の時間で application を更新すればいいだけだ。<br>
(が、実際に行うのは困難が伴うことも多い)</p>
<p>ではストリーム処理ではどうだろうか。<br>
いわゆるストリーム処理においては処理と処理の間というものがなく、application がずっと稼働しっぱなしということになる。<br>
バッチ処理のような更新はできない。<br>
もっと言うと producer で生まれた新しい schema のレコードがいつ届くかもわからない。</p>
<p>おそらくこの問題には2つの対応方法がある。<br>
1つめは consumer 側のシステムで前方互換性を保つという方法である。<br>
この場合、新しいフィールドは必ず末尾に追加される等、producer 側での schema 更新についてある程度のルールが必要となるだろう。<br>
producer 側で生成されるレコードの schema の変更が必ず事前にわかるというのであれば後方互換性でもいいが、多くの場合は難しい。<br>
ところで<a href="https://ja.wikipedia.org/wiki/%E4%BA%92%E6%8F%9B%E6%80%A7">前方互換と後方互換</a>、どっちがどっちなのか覚えられません。</p>
<p>2つめの方法として schema 情報をレコード自体に入れ込んでしまうという方法もある。<br>
<a href="https://avro.apache.org/">Apach Avro</a> のような serialization の方法を取っているとレコード自体に schema の情報を付与することができる。</p>
<p>おそらく最もエレガントにこれをやるのが Confluent の <a href="https://docs.confluent.io/current/schema-registry/index.html">Schema Registry</a> という機能だ。<br>
producer から送出されるレコードには schema ID を付与する。<br>
schema の実体は Schema Registry という broker とは別の場所で管理されており、consumer 側では受け取ったレコードに付与されている schema ID と Schema Registry に登録されている shcema の実体を参照してレコードを deserialize することができる。</p>
<h2 id="deploy">Deploy</h2>
<p>ストリーム処理を行うシステムは終わりのないデータを処理するためのものであり、ずっと動き続けることが期待されている。<br>
しかし通常システムは一度立ち上げれば終わりということではなく、運用されている中で更新していく必要がある。</p>
<p>ずっと動かしながらどのように deploy, release するのか。<br>
この問題は主に consumer 側のシステムで配慮が必要になると思われる。<br>
正直これについてはちゃんと調べられていないが、2点ほど述べておきたい。</p>
<p>まず1点目、application を中断・更新・再開するのにどの程度の時間がかかるのかを知っておく必要があるということ。<br>
アーキテクチャやフレームワーク、処理の内容や checkpoint (後述) を使うか等によりこの時間は変わってくる。<br>
一例だが、AWS 環境において</p>
<ul>
<li>AWS Glue + Spark Structured Streaming</li>
<li>Amazon Kinesis Data Analytics + Flink</li>
</ul>
<p>の比較をしたことがある。<br>
前者は再開に数分かかったのに対し、後者は1分未満で再開できた。<br>
再開までの時間が十分に短いと判断できるのであればそのまま deploy, release してしまっていいだろう。</p>
<p>一方そうでない場合はどうすべきかという話が2点目。<br>
再開までの時間が長く、システム要件的に許容できないというのであれば、release 時は二重で動かすというような措置が必要かもしれない。<br>
おそらく <a href="https://www.publickey1.jp/blog/14/blue-green_deployment.html">Blue-Green Deployment</a> のようなことを考えることになるだろう。</p>
<h2 id="checkpoint">Checkpoint</h2>
<p>前述のとおり、ストリーム処理を行うシステムはずっと動き続けることが期待されている。<br>
しかし予定された application の更新や不測のエラー等、何らかの理由で一時的に中断されるということが実際の運用中には起こる。</p>
<p>中断されたとき速やかに復帰する仕組みとして &quot;checkpoint&quot; というものがいくつかの consumer 側のフレームワークで提供されている。<br>
雑に説明すると、処理のある時点における進捗や内部状態などをディスク等に永続化し、そこから処理を再開できるようにするものである。</p>
<ul>
<li><a href="https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#recovering-from-failures-with-checkpointing">Recovering from Failures with Checkpointing - Apache Spark</a></li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/stream/state/checkpointing.html#checkpointing">Checkpointing - Apache Flink</a></li>
</ul>
<p>上記は Spark Structured Streaming と Flink の例だ。<br>
checkpoint には次のようなメリットがあり、運用上有用だと言える。</p>
<ul>
<li>内部の状態を保持しているため、速やかに復帰できる</li>
<li>中断した位置から再開できるので出力に穴が開かない</li>
</ul>
<p>一方で落とし穴もある。<br>
checkpoint では内部の状態が永続化されるわけだが、内部の状態というのは当然 application の実装が決めているものである。<br>
application のコードを変更したとき、変更の内容によっては永続化された checkpoint と application が合わなくなることがあるのだ。<br>
未定義の挙動となることもあるので、checkpoint の運用には十分に配慮する必要がある。<br>
どのような変更なら checkpoint が安全に利用できるのかはフレームワークのドキュメントに記載があるので確認しておきたい。</p>
<h2 id="rdb-の世界との折り合い">RDB の世界との折り合い</h2>
<p>みんな大好きな RDB の世界では table を操作してデータの処理を行う。<br>
基本的には table というものはある時点における完全なデータセットを表すものである。 (ex. isolation)<br>
他方、ストリーム処理はやってきたデータを逐次的に処理するものである (mini-batch の場合もあるが)。</p>
<p>直感的にこの2つは相性が悪そうに見える。<br>
しかし Spark や Flink では table ベースの操作でストリーム処理を行うための API が提供されている。<br>
おそらく</p>
<ul>
<li>ストリーム処理の周辺のデータソースとして RDB が存在する</li>
<li>RDB 的な table 操作があまりにも浸透している</li>
</ul>
<p>というところが API が必要である理由なのだろう。</p>
<p>ストリームデータを table 的に扱うというのが、やや直感的な理解をしにくいものとなっている。<br>
フレームワークのドキュメントを確認しておきたい。</p>
<p>例えば Spark Structured Streaming であれば処理の出力のための3つの <a href="https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html#output-modes">output mode</a> が示されている。</p>
<ul>
<li>Append mode: 追加された行だけ出力</li>
<li>Complete mode: table 全体を出力</li>
<li>Update mode: 更新された行だけ出力</li>
</ul>
<p>どれを選ぶかにより必要とする内部メモリの大きさも影響される。</p>
<h2 id="まとめ">まとめ</h2>
<p>思ったより長文になってしまった。<br>
結局ストリーム処理の難しさは以下の2点に尽きるだろう。</p>
<ul>
<li>複数の時間の概念</li>
<li>常時稼働のシステム</li>
</ul>
<p>独学なので抜け漏れがあったり、話が新しくなかったりすることもあると思われる。</p>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/">Streaming 101: The world beyond batch</a>
<ul>
<li>Apache Beam PMC によるストリーム処理の解説ポスト。必読</li>
</ul>
</li>
<li><a href="https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/">Streaming 102: The world beyond batch</a>
<ul>
<li>上の続きであり watermark について触れている</li>
</ul>
</li>
<li><a href="https://d1.awsstatic.com/whitepapers/architecture/wellarchitected-Analytics-Lens.pdf">Analytics Lens - AWS Well-Architected Framework</a>
<ul>
<li>AWS の資料。ストリーム処理のシステムの全体感がつかめる</li>
</ul>
</li>
<li><a href="https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html">Structured Streaming Programming Guide - Apache Spark</a>
<ul>
<li>Spark Structured Streaming のドキュメント。consumer の気持ちがわかる</li>
</ul>
</li>
<li><a href="https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/datastream_api.html">Flink DataStream API Programming Guide - Apache Flink</a>
<ul>
<li>Flink のドキュメントの方がより詳しい。DataStream API の解説を中心に読むとよい</li>
</ul>
</li>
</ul>

      </article>
      

      

    </div>
  </div>
</div>

  </main>
  <footer class="footer">
  <div class="ax-l-i max-w-6xl">
    <nav class="flex items-center justify-center">
      <a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href="/posts/">Posts</a>
      <a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href="/tags/">Tags</a>
      <a class="ml-3 first:ml-0 text-sm text-gray-600 hover:text-gray-800" href="/about/">About</a>
    </nav>
    <div class="footer-social flex items-center justify-center mt-4">
      <a class="block mx-3 w-6 h-6 text-raven-700 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="" href="https://twitter.com/soonraah"><svg class="fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M32 6.078c-1.2.522-2.458.868-3.78 1.036 1.36-.812 2.398-2.088 2.886-3.626a13.11 13.11 0 0 1-4.16 1.588C25.742 3.794 24.026 3 22.154 3a6.56 6.56 0 0 0-6.556 6.562c0 .52.044 1.02.152 1.496-5.454-.266-10.28-2.88-13.522-6.862-.566.982-.898 2.106-.898 3.316a6.57 6.57 0 0 0 2.914 5.452 6.48 6.48 0 0 1-2.964-.808v.072c0 3.188 2.274 5.836 5.256 6.446-.534.146-1.116.216-1.72.216-.42 0-.844-.024-1.242-.112.85 2.598 3.262 4.508 6.13 4.57a13.18 13.18 0 0 1-8.134 2.798c-.538 0-1.054-.024-1.57-.1C2.906 27.93 6.35 29 10.064 29c12.072 0 18.672-10 18.672-18.668 0-.3-.01-.57-.024-.848C30.014 8.56 31.108 7.406 32 6.078z"/></svg></a>
      <a class="block mx-3 w-6 h-6 text-raven-700 hover:text-raven-900" target="_blank" rel="noopener nofollow" title="" href="https://github.com/soonraah"><svg class="fill-current" viewBox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M15.998 0C7.164 0 0 7.35 0 16.417 0 23.67 4.584 29.82 10.944 31.994c.8.15 1.092-.356 1.092-.79l-.022-2.792c-4.45.99-5.4-2.202-5.4-2.202-.726-1.896-1.776-2.4-1.776-2.4-1.454-1.018.108-.998.108-.998 1.606.117 2.45 1.693 2.45 1.693 1.428 2.507 3.746 1.784 4.658 1.363.144-1.06.558-1.784 1.016-2.195-3.552-.415-7.288-1.823-7.288-8.113 0-1.792.624-3.258 1.648-4.406-.166-.415-.714-2.085.156-4.344 0 0 1.344-.44 4.4 1.683 1.276-.364 2.644-.546 4.006-.552a14.98 14.98 0 0 1 4.006.554C23.062 6.37 24.404 6.8 24.404 6.8c.872 2.26.324 3.93.16 4.344 1.026 1.148 1.644 2.614 1.644 4.406 0 6.306-3.74 7.694-7.304 8.1.574.507 1.086 1.51 1.086 3.04l-.02 4.503c0 .44.288.95 1.1.788C27.42 29.817 32 23.667 32 16.417 32 7.35 24.836 0 15.998 0z"/></svg></a>
    </div>

    <div class="footer-copyright text-sm text-center text-gray-500 mt-4">
      &#169; 2020-2020 Froglog
    </div>
    <div class="text-sm sm:text-xs text-center text-gray-500 mt-2">
       <a href="https://www.axiomtheme.com/?utm_source=theme-footer&utm_medium=website&utm_campaign=referral"></a>
    </div>
  </div>
</footer>

<script src="/bundle.js?v=1599378569"></script>


</body>
</html>
