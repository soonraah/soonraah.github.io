<!doctype html><html lang=ja dir=auto><head><meta name=generator content="Hugo 0.147.3"><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Froglog</title>
<meta name=description content="blog"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://soonraah.github.io/index.xml><link rel=alternate type=application/json href=https://soonraah.github.io/index.json><link rel=alternate hreflang=ja href=https://soonraah.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://soonraah.github.io/"><meta property="og:site_name" content="Froglog"><meta property="og:title" content="Froglog"><meta property="og:description" content="blog"><meta property="og:locale" content="ja"><meta property="og:type" content="website"><meta property="og:image" content="https://soonraah.github.io/image/brand/soonraah_full.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/brand/soonraah_full.png"><meta name=twitter:title content="Froglog"><meta name=twitter:description content="blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Froglog","url":"https://soonraah.github.io/","description":"blog","logo":"https://soonraah.github.io/favicon2.ico","sameAs":["https://twitter.com/soonraah","https://github.com/soonraah"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h1>Froglog</h1></header><div class=entry-content>大規模データ処理とか機械学習とかデータ基盤とか 🐸</div><footer class=entry-footer><div class=social-icons><a href=https://twitter.com/soonraah target=_blank rel="noopener noreferrer me" title=Twitter><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg>
</a><a href=https://github.com/soonraah target=_blank rel="noopener noreferrer me" title=Github><svg viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77 5.44 5.44.0 003.5 8.55c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></div></footer></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/ordinary-data-plagform-migration/infra-and-delivery.jpg alt="infra and delivery"></figure><header class=entry-header><h2 class=entry-hint-parent>ふつうのデータ基盤移行 - Part 5. IaC と CI/CD 編</h2></header><div class=entry-content><p>このポストについて データ基盤移行について書いていくシリーズです。
シリーズ一覧はこちらから。
前回 Part 4. AI ワークフローで移行作業効率化編では移行するための苦労と効率化について書きました。
今回はがらっと変わって IaC と CI/CD について書きます。
スコープ 今回は開発寄りの話です。
データ基盤の構築にあたり Terraform を使って IaC (Infrastructure as Code) を実現し、さらにそれに基づいて GitHub Actions による CI/CD (Continuous Integration & Continuous Derivery) 環境を作ったという話をしていきます。
IaC で作りたいアーキテクチャは AWS 上の Databricks 環境とその周辺です。
アーキテクチャについて詳しくは Part 3. アーキテクチャ編などをご参照ください。
だいたい以下の図のような話です。
お気持ち表明 こんにちは、初手で絶対に CI/CD 環境を構築するマンです。
初手で絶対に CI/CD 環境を構築するマンは、初手で絶対に CI/CD 環境を構築するぞ！という強い気持ちを持っています。
Databricks 上にデータ基盤を構築するにあたり、他社事例でインフラ構築を自動化していないケースを見たこともあります。
しかし我々のチームでは PoC 終了後の構築最初期から IaC としてインフラをコード化し、それを CI/CD の仕組みで自動でデプロイすることを決めていました。
次のような理由からです。
リリースの数だけ自動化のリターンがあるので、最初から自動化しておくのが最もリターンが大きい チームにはジュニアなメンバーもおり、手動の運用はオペミスや production, staging などの環境差発生のリスクが大きい 社内で Terraform や GitHub Actions などがよく使われており、導入できる下地があった まだ Databricks にそこまで慣れていない導入初期にこれらの仕組みを入れるのはそれなりにたいへんです。
しかしそのたいへんさ以上のメリットがあると判断しました。
...</p></div><footer class=entry-footer><span title='2025-09-18 07:30:00 +0900 JST'>9月 18, 2025</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to ふつうのデータ基盤移行 - Part 5. IaC と CI/CD 編" href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-5/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/finops/finops.jpg alt=finops></figure><header class=entry-header><h2 class=entry-hint-parent>データエンジニアから見るクラウド FinOps</h2></header><div class=entry-content><p>このポストについて 書籍『クラウドFinOps 第2版』を読んだところ、FinOps にデータマネジメントやデータエンジニアリングに深く関連する内容があるということがわかったのでまとめてみる。
書籍について J.R. Storment; Mike Fulle. クラウドFinOps 第2版 協調的でリアルタイムなクラウド価値の意思決定 O’Reilly Japan. 2025年3月に出版。
ちなみに原著の初版は2019年、第2版は2023年。
タイトルのとおり FinOps (後述) について書かれた書籍となっている。
著者は両名とも FinOps Foundation の関係者であり、本文中にも随所に FinOps Foundation についての記載が出てくる。
私はデータエンジニア、ソフトウェアエンジニアとして日々 AWS その他のクラウドサービスを利用している。
クラウドサービス上に例えばデータ基盤等を構築し、ビジネス上の価値を提供している。
その一方でクラウドを使うということは料金的な意味でのコストがかかるということでもある。
もちろん支払うコストは少ない方がいい。
それは分かるのだが、それ以上のクラウドコストについての体系的な考え方を持ち合わせていなかった。
毎日それなりの額を使ってるのにね。
というのが本書を読もうと思った理由だった。
FinOps とは 定義 これを書いている2025年8月現在における FinOps Foundation での定義は以下のようになっている。1
“FinOps is an operational framework and cultural practice which maximizes the business value of cloud and technology, enables timely data-driven decision making, and creates financial accountability through collaboration between engineering, finance, and business teams.”
...</p></div><footer class=entry-footer><span title='2025-08-12 07:00:00 +0900 JST'>8月 12, 2025</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to データエンジニアから見るクラウド FinOps" href=https://soonraah.github.io/posts/cloud-finops-for-data-engineer/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/ordinary-data-plagform-migration/workflow.jpg alt=workflow></figure><header class=entry-header><h2 class=entry-hint-parent>ふつうのデータ基盤移行 - Part 4. AI ワークフローで移行作業効率化編</h2></header><div class=entry-content><p>このポストについて データ基盤移行について書いていくシリーズです。
シリーズ一覧はこちらから。
前回 Part 3. アーキテクチャ編ではどういったシステム構成にしたかを書きました。
今回はその技術スタックへと移行するための苦労と効率化について書きます。
(次は CI/CD の話をすると書きましたが…スマンありゃウソだった)
スコープ 今回はやや小さいスコープの話です。
データ基盤における ETL (ELT) 処理の移行作業を対象としています。
移行作業における工数的な課題を AI ワークフローを作って効率化して軽減したという話になります。
ETL 以外の移行作業は今回はスコープ外となります。
課題 旧データ基盤から新データ基盤へと table およびそれを更新するための処理を移行するにあたり工数面での課題が2つあります。
技術スタックの移行 column 命名などの標準化 これらについて述べます。
技術スタックの移行 データ基盤の移行において、新旧の環境で技術スタックは次のようになっています。
旧データ基盤 ETL: Glue Job 新データ基盤 ELT: dbt-databricks つまり Glue Job の Python コードを dbt model、つまり SQL に翻訳する必要があり、それなりに手間がかかります。
さらにこの Python コードは次のような問題もあり、移行のハードルを上げます。
UDF を実装して特殊な処理を行っているケースがある Spark の API だけでなく Glue の API をふんだんに使っている (なるべく Spark に寄せればいいものを…) (ここ数年の業務で見た中で一番というぐらいに) コード品質が低い column 命名などの標準化 旧データ基盤は利用者への配慮があまりない状態で table の schema が作られており、利用者にとって使いにくいものとなっていました。
それを改善するため、新データ基盤では次のようなルールを導入しました。
...</p></div><footer class=entry-footer><span title='2025-06-18 07:30:00 +0900 JST'>6月 18, 2025</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to ふつうのデータ基盤移行 - Part 4. AI ワークフローで移行作業効率化編" href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-4/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/ordinary-data-plagform-migration/medalists.jpg alt="medallion architecture"></figure><header class=entry-header><h2 class=entry-hint-parent>ふつうのデータ基盤移行 - Part 3. アーキテクチャ編</h2></header><div class=entry-content><p>このポストについて データ基盤移行について書いていくシリーズです。
シリーズ一覧はこちらから。
前回 Part 2. 技術選定編では技術選定について書きました。
今回はそれを踏まえた結果としてどのようなアーキテクチャになったかを書きます。
スコープ 前回の記事ではプラットフォームとして Databricks を選定したことやその経緯について記載しました。
一方、それより詳細な技術スタックを含むシステムアーキテクチャについては示していませんでした。
例えばデータ基盤では通常次のような技術スタックについて考える必要があります。
データ取込 workflow orchestration ELT (or ETL) storage これらについて述べ、またデータ基盤の階層構造についても説明します。
システムアーキテクチャ データ基盤のシステム・アーキテクチャです。
よく混同されがちですが、データアーキテクチャではありません。
AWS + Databricks の構成をベースとして構築されています。
概要図 データ取込 現時点ではデータソースとしては S3 に置かれた半構造化データ (JSON)、RDS がメインとなっています。
これら2つの取込方法について述べます。
まず、S3 のデータは SQL の copy into 文により取り込んでいます。
Get started using COPY INTO to load data | Databricks Documentation Auto Loader を使う方が Databricks 的でありそれも検討したのですが、schema evolution や冪等性など検討した結果として copy into を採用しました。
RDS からのデータ取込は foreign catalog 経由で行います。
...</p></div><footer class=entry-footer><span title='2025-06-11 08:30:00 +0900 JST'>6月 11, 2025</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to ふつうのデータ基盤移行 - Part 3. アーキテクチャ編" href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-3/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/reading-note/ai_frog_graph_network_with_parrot.jpg alt="AI frog graph network with parrot"></figure><header class=entry-header><h2 class=entry-hint-parent>読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門</h2></header><div class=entry-content><p>書籍について 西見 公宏; 吉田 真吾; 大嶋 勇樹. LangChainとLangGraphによるRAG・AIエージェント［実践］入門 エンジニア選書. 株式会社技術評論社. タイトルのとおりで RAG や AI エージェントについて書かれた本。
出版は2024年11月。
LangChain や LangGraph を使ったサンプルコードが豊富に載っている。
著者の方は3名ともジェネラティブエージェンツ社の方で、AI エージェントを扱う会社らしい。
前作として『ChatGPT/LangChainによるチャットシステム構築［実践］入門』という本もあり、本書の何章かは前作の内容を引き継いでアップデートしているとのこと。
個人的にはこれまで LLM や LangChain など追えていなかったので勉強になったし、自分でコードを写経して動かしてみるのがとても面白かった。
AI エージェントまわりの技術を実感したい人におすすめ。
ちなみにサンプルコードを動かすためには OpenAI をはじめとする様々なサービスに登録する必要があり、料金が発生するものも含まれている。
このポストについて 書籍「LangChainとLangGraphによるRAG・AIエージェント［実践］入門」を読んで、面白かったので内容をまとめる。
各章ごとに内容を挙げていってもいいのだが、ここではそうはせず、本書に登場する言葉や概念をまとめていくことにする。
ちなみにこの記事で紹介するプロンプト等は書籍そのままではなく、少し変更している。
実際のプロンプトを知りたい場合は書籍を読んでください。
プロンプトエンジニアリング これは知っている人も多いだろう。
プロンプトとは主に自然言語で記述される、LLM に与える命令のこと。
LLM をアプリケーションに組み込む場合はプロンプトはテンプレート化し、入力データをそれに差し込む形となる。
LLM は必ずしも人間の出す命令に対して望ましい回答を出力してくれるわけではない。
望ましい回答を出力してもらえるよう、プロンプトを工夫するテクニックがプロンプトエンジニアリングである。
本書ではプロンプトエンジニアリングの具体的な手法として次の3つが紹介されていた。
ちなみにここで例として示している出力は実際に OpenAI の LLM gpt-4o-mini で出力したものである。
Zero-shot プロンプティング 簡単なタスクであれば、特に追加の情報がなくとも (=Zero-shot) 望ましい回答を得ることができる。
system: 次の日本酒のレビューをポジティブ・ネガティブ・中立のどれかに分類してください。 user: ふくよかで芳醇な香り 出力
ポジティブ Few-shot プロンプティング より複雑なタスクになった場合、デモンストレーションを与えることで回答の精度を高めることができる。
いくつかのデモンストレーションを示すため、Zero-shot ではなく Few-shot である。
...</p></div><footer class=entry-footer><span title='2025-03-02 23:45:00 +0900 JST'>3月 2, 2025</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 読書メモ: LangChainとLangGraphによるRAG・AIエージェント［実践］入門" href=https://soonraah.github.io/posts/reading-note-agent-book/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/ordinary-data-plagform-migration/technology-selection.jpg alt="technology selection"></figure><header class=entry-header><h2 class=entry-hint-parent>ふつうのデータ基盤移行 - Part 2. 技術選定編</h2></header><div class=entry-content><p>このポストについて データ基盤移行について書いていくシリーズです。
シリーズ一覧はこちらから。
前回は戦略策定 (実際は戦術) までのところを書きました。
今回はそれを踏まえた技術選定、およびその後の予算獲得について書いていきます。
また、こちらは Databricks Advent Calendar 2024 シリーズ 2 の16日目の記事にもなっています。
はいそうです、出落ちですが技術選定として Databricks を選ぶことになります。
スコープ 前回 Part 1. 戦略策定編では概ねのロードマップが決まり、まずはデータ基盤のリアーキテクチャをやっていくことになりました。
リアーキテクチャにおいてはどのような技術スタックを使っていくかが重要な選択になります。
データ基盤においてはデータ処理のためのストレージとコンピュートの選択がとても重要です。
以降ではこの2つをあわせた DWH 製品の選定について書いていきます。
「DHW 製品」という言葉は適切ではないかもしれませんが、ここではストレージ + コンピュートが組み合わさったものぐらいに考えてください。
もちろんデータ基盤には他の技術要素もあり、それらも軽くない選択ですがこのポストでは割愛します。
(気が向いたら別記事で書くかも)
技術選定の目的 まず何のために技術スタックの置き換え、ひいては技術選定をするかの目的を明確にしておく必要があります。
旧データ基盤では次のような技術スタックになっていました。
ストレージ: S3 コンピュート: Glue Job, Athena この構成には次のような課題がありました。
主にこれらの課題を解決するために DWH 製品の乗り換えを検討することになりました。
dbt との親和性の低さ 一貫したガバナンスの欠如 dbt との親和性の低さ 前回作成したロードマップにおいて、dbt の導入が課題解決における重要なポイントになっています。
dbt の周辺エコシステムがデータ基盤の課題の解決に大きく貢献すると考えています。
また、データパイプラインの開発・運用の負荷も dbt 導入で軽減できそうです。
旧データ基盤では Glue Job と Athena クエリを組み合わせた複雑なパイプラインになっており、table を1つ追加するだけでもいろいろなコードに手をいれる必要があります。
ほぼ SQL で実装でき、かつ宣言的にパイプライン構築できる dbt は魅力的です。
仮に旧データ基盤に dbt を導入するとなると dbt-athena を使うことになります。
ただ dbt による Athena のサポートはやや弱く、dbt-athena はコミュニティ版から少し前に移管されたものですし、これを書いている2024年12月の時点で dbt Cloud の Athena のサポートはまだプレビューです。
反論がある方もいらっしゃるかもしれませんが、モダンなデータ基盤構築において Athena はやや影が薄い印象があり、dbt のサポートの弱さもこれが原因だと思います。
(ただし直近の re:Invent 2024 の内容からすると潮目が変わる可能性もありそうです)
...</p></div><footer class=entry-footer><span title='2024-12-16 00:30:00 +0900 JST'>12月 16, 2024</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to ふつうのデータ基盤移行 - Part 2. 技術選定編" href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-2/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/ordinary-data-plagform-migration/stragist-frog.jpg alt="data strategy"></figure><header class=entry-header><h2 class=entry-hint-parent>ふつうのデータ基盤移行 - Part 1. 戦略策定編</h2></header><div class=entry-content><p>このポストについて データ基盤移行について書かれた各社の技術ブログなど見かけることがありますが、割とさらっと書かれていることが多いように思います。
本当はいろんな面で苦労があり、記事に表れていない辛さや工夫などがあるはず。
ということで今自分が経験している普通の会社の普通のデータ基盤移行について、詳しく記事にしてみようと考えました。
何回かに分けてデータ基盤移行のいろいろな側面を、うまくいったこともいかなかったことも含めて書いていきます。
とはいえ現在進行形なので、全編書き終わるのはかなり先になりそうです。
データ基盤移行のシリーズ一覧はこちらから。
移行の背景 組織 まずイメージしやすいよう、どういった組織におけるデータ基盤移行なのかについて軽く触れておきます。
社員規模: 〜100名 web 系の B2C ビジネス データチームの構成 マネージャ: 1名 (データエンジニアリングの経験はほぼない) データエンジニア: 2 -> 3名 (途中で採用) 中小のベンチャー？企業ではありますが、意思決定プロセスは JTC 感があります。
私はデータエンジニアのポジションとなっており、その視点からの話であることにご留意ください。
小さい組織ということで私は移行の計画から設計、開発その他のあらゆるフェーズに中心的に関わっています。
どこもそうだと思いますが、人員的にはまあまあきびしい。
よくある中小 IT 企業のよくあるデータ基盤移行の話だと思っていただきたく。
大企業ではないのでそこまでちゃんとはしていません。
(ちなみに自分のブログで本件を記事にしていいかは上長に確認の上、OK をもらっています)
旧データ基盤 一連のポストでは移行前のデータ基盤のことを「旧データ基盤」と表記するものとします。
旧データ基盤は AWS 上で構築されており、アーキテクチャについて簡単に挙げると
storage: S3 ETL: Glue Job, Athena SQL engine: Athena workflow orchestration: MWAA のようになっていました。
旧データ基盤の開発・運用側 (データエンジニア) としても、また社内の利用者側としてもいろいろと問題が挙がってきてはいました。
しかしそれをうまく集約・言語化できていないという状況でした。
そんな中でエライ人の鶴の一声で移行しようぜ！ということになり、データ基盤の移行を検討することに相成りました。
移行計画を考えるにあたり まず考えたこと データ基盤の移行は組織におけるデータマネジメントにおいて重要な位置づけとなるはず。
したがって単なる技術スタックの置き換えというスコープで考えるのはもったいないです。
組織のデータマネジメントの未来を想定して、戦略を持って開発・運用を進めるべきであると考えました。
そのためにはイシューを明確化しないといけません。
でもどの抽象度レベルで？
ボトムアップの戦術策定 まずは現場感覚、ボトムアップでの課題を明らかにすることを考えました。
本来は後述する戦略レベルから先に考えるべきですが、実際に目に見えている課題があり、取り組みやすかったというところで戦術のレベルから考え始めています。(良し悪しはある)
現状のアーキテクチャと運用では戦略策定への対応が難しいため、せめてそのための地ならしとして今見えている課題に対応できる状態にしたいというのもありました。
...</p></div><footer class=entry-footer><span title='2024-12-01 22:30:00 +0900 JST'>12月 1, 2024</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to ふつうのデータ基盤移行 - Part 1. 戦略策定編" href=https://soonraah.github.io/posts/ordinary-data-platform-migration-part-1/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/dmbok/data_quality.jpg alt="data quality"></figure><header class=entry-header><h2 class=entry-hint-parent>読書メモ: DMBOK2 第13章 データ品質</h2></header><div class=entry-content><p>このポストについて ​
DMBOK2 を読み進めていくシリーズ。
今回は第13章「データ品質」について。
これまで業務で「データ品質」という言葉が使われることがあったが、意味が限定的だったり人によって定義が違ったりしていた。
そのあたりクリアにできるとよい。
​
内容紹介 ​
データ品質の定義 ​
データ品質の簡潔な定義は「目的に適合している」。
データ品質管理の定義は「データを収集し扱うための技法を適用し、企業や地域のデータ利用者の、ニーズや利用に適したデータとすることを保証する活動を計画し、実施し、管理する」。
​
データ基盤担当の仕事柄、データ品質というとどちらかというと上流であるデータソース側の定義が重要だと思っていたが、そうではなく下流であるデータ利用においての観点が起点になるというのが気づきだった。(でも考えてみれば当たり前)
​
ビジネス上の意義 ​
ステークホルダーの体験と組織の評判を高める ex. データが正しいことを顧客が信頼し、組織との取引に自信を持てる 組織がより有効な成果を出せるようにする ex. ビジネスチャンスの特定と効果的な請求により売上を獲得できる 低品質なデータによるリスクとコストを削減する ex. データが正しいかどうかをスタッフが見極める時間が減る ex. 誤ったデータによる誤った意思決定 組織の効率と生産性を向上する ex. カスタマーサービスにかかってくる電話が減り、問い合わせを解決できるようになる
​ 重要なデータ ​
データ品質管理における第一の原則は、組織とその顧客にとって最も重要なデータに改善努力を集中させること。
​
ex. 顧客のメールアドレス欄のデータが不完全であれば、顧客にメールで商品情報を送ることができず、潜在的な売上を失う 1通のメールを送るごとに100円の収益が得られることが知られている → データ品質の改善に明確な価値があると言える
​ 重要なデータは組織や業界によって異なるが、以下のような用途で使用されることが多い。
​
規制、財務、経営報告 事業運営上のニーズ 製品の品質と顧客満足度の測定 事業戦略、特に競争上の差別化への取り組み
​ データ品質評価軸 ​
データ品質評価軸は、測定可能なデータの特徴または特性。
一般的な評価軸は次のとおり。
​
No. 評価軸 説明 例 1 有効性Validity データの値が定義された領域の値と一致しているかどうか。 - 数値、日付などのデータ範囲- 電話番号などの書式 2 完全性Completeness 必要なデータがすべて存在するかどうか。カラム, レコード, データセットのレベルがある。 - カラム: 必須カラムにデータが入っているか？- データセット: 都道府県マスタに47都道府県の情報はあるか？ 3 一貫性Consistency データ値が同じアプローチ、評価、価値基準を用いてコード化されていることを保証すること。レコード内、レコード間、経時的な一貫性などがある。 - すべての顧客企業の住所は本社住所となっているか？- 生徒の成績評価は時を経ても同じか？ 4 整合性Integrity データに非一貫性や破綻した関係性がないこと。 - 顧客住所の国がカナダの場合、州としてカナダの州が記載されているか？ 5 適時性Timeliness データの取得または更新後、ユーザーがデータにアクセスできるようになるまでの時間を指す。 - 電力会社は電力需要データを数秒以内に利用して需給調整する必要がある- 政府機関が四半期末の2ヶ月後に GDP 報告書を作成 6 最新性Currency データが最後に更新されてから現在までの期間と、それがまだ正しいという可能性。データセットによって期待される最新性は異なる。 - 国コードは比較的静的- 銀行口座残高は変動的 7 妥当性Reasonableness データパターンが期待に合致しているかどうか。 - 先週のクリック数と比較して今日のクリック数は普通か否か？ 8 一意性/重複排除Uniqueness/Deduplication 現実世界の実体がデータセット内に2つ以上存在しないこと。 - ユーザー ID は重複していないか？- ユーザー ID は異なるが、同一の人物を表していないか？ 9 正確性Accuracy データが「現実の」実体を正しく表している程度。 - ユーザー名は現実世界の個人の名前なのか？- 顧客は実際にそのメールアドレスを使用しているのか？ ​
ここでようやく「データ品質」が具体的なものとして見えてきた。
測定が比較的容易なものもあれば困難なものもある。
​
...</p></div><footer class=entry-footer><span title='2024-11-18 20:30:00 +0900 JST'>11月 18, 2024</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 読書メモ: DMBOK2 第13章 データ品質" href=https://soonraah.github.io/posts/dmbok-chapter-13/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/dalle/data_contracts.jpg alt="data contracts"></figure><header class=entry-header><h2 class=entry-hint-parent>Data Contract CLI から考える Data Contracts ファーストのデータパイプラインの未来</h2></header><div class=entry-content><p>このポストについて Data Contract CLI を触ってみたところ、面白かったのとこれからのデータパイプライン開発について思うところがあったので書いてみる。
Data Contract CLI とは？ datacontract/datacontract-cli
Data Contract CLI は data contracts を運用するためのオープンソースのコマンドラインツールである。
data contracts の概念については以前の記事で詳しく書いているのでそちらをご参考いただければと。
ただしこちらの記事は1年前のものであり、今回取り上げる Data Contract CLI の登場などを含めて現在では data contracts を取り巻く状況も変わっている可能性があることに注意。
Data Contract CLI は Python で開発されており、pip でインストールすることができる。
この記事を書いている時点では v0.10.3 が最新であり、この記事の内容はこのバージョンに基づいている。
Data Contract CLI で扱う data contracts は YAML で定義される前提となっており、その仕様は datacontract/datacontract-specification で決められている。
この data contracts に対して Data Contract CLI では次のようなことが行える。
lint によるフォーマットチェック データソースに接続した上での schema やデータ品質のテスト data contracts の破壊的な変更の検出 JSON Schema や dbt など、他の形式からの／へのインポートとエクスポート 以下の図がイメージしやすい。
...</p></div><footer class=entry-footer><span title='2024-05-09 22:30:00 +0900 JST'>5月 9, 2024</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Data Contract CLI から考える Data Contracts ファーストのデータパイプラインの未来" href=https://soonraah.github.io/posts/data-contract-cli/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/dmbok/data_integration_and_interoperability.jpg alt="data integration and interoperability"></figure><header class=entry-header><h2 class=entry-hint-parent>読書メモ: DMBOK2 第8章 データ統合と相互運用性</h2></header><div class=entry-content><p>このポストについて DMBOK2 を読み進めていくシリーズ。
今回は第8章「データ統合と相互運用性」について。
業務で扱っているデータ基盤はデータ統合が不完全であるため、なんとかしたいと考えている。
以降、特に注釈のない引用は DMBOK2 第8章からの引用とする。
データストレージと相互運用性とは データ統合と相互運用性 (DII: Data Integration and Interoperability) は次のように定義されている。
アプリケーションや組織内および相互間におけるデータの移動と統合を管理する
データの移動を効率的に管理することがそのビジネス上の意義となる。
ほとんどの組織には数多くのデータストアがあり、組織内・組織間でデータを移動させることは IT 組織の重要な任務となっている。
複雑さとそれに伴うコストを管理するために、全社的な視点からデータ統合を設計しなければならない。
データウェアハウスなどのデータハブによりアプリケーション間のインターフェースの数を削減することができる。
DII のゴールは以下
法令を遵守しながら、必要とするフォーマットと時間枠でデータを安全に提供する。 共有のモデルとインターフェースを開発することでソリューションを管理するコストと複雑さを軽減する。 重要なイベントを特定し、アラートとアクションを自動的に起動する。 ビジネスインテリジェンス、アナリティクス、マスターデータ管理、業務効率化の取り組みをサポートする。 概念・用語など 抽出、変換、取込 DII の中心にあるのが、抽出 (Extract)、変換 (Transform)、取込 (Load) のいわゆる ETL という基本プロセス。
抽出 ソースから必要なデータを選択し、抽出する 抽出されたデータはディスク上やメモリ上にステージングされる 業務システムで実行される場合は、少ないリソースを利用するように設計する 変換 ソースデータを変換してターゲットデータストアの構造と互換性を持つようにする フォーマット変更、構造の変更、意味的変換、重複排除、並べ替えなどがある 取込 ターゲットシステムに物理的に格納されるか、提供される ELT ターゲットシステムにより多くの変化機能がある場合は、プロセスの順序を ELT にすることができる データレイクへの取込を行うビッグデータ環境では一般的 レイテンシ ソースシステムでデータが生成されてから、ターゲットシステムでそのデータが利用可能になるまでの時間差。
アプローチによってレイテンシの高低が異なる。
バッチ 利用者や自動的な要求に応えて、定期的にアプリケーションや組織間を一定量まとまって移動させる レイテンシは高いが大量データを処理するときのパフォーマンスがいい 低レイテンシを実現するためのマイクロバッチもある 変更データキャプチャ データの変更 (挿入・変更・削除) のデータセットを監視し、その差分をターゲットのシステムに渡す DBMS のアクティビティログをコピーし、処理する形で行われることもある 準リアルタイムとイベント駆動 設定された予定により1日を通して分割された少量のデータセットで処理されたり、データ更新などのイベントが発生したときに処理されたりする 一般的にエンタープライズ・サービス・バスを利用して実装される 非同期 データ提供側は受信側の更新確認を待たずに処理を続行する リアルタイム、同期 次のトランザクションを実行する前に、他のアプリケーションからの確認を受け取るまで実行プロセスが待機する 非同期と比べて状態管理の負担が少ないが、他のトランザクションをブロックしたり遅延させたりすることもある 低レイテンシまたはストリーミング イベントが発生したときにシステムからリアルタイムで連続して流れる リプリケーション 分析やクエリによるパフォーマンス低下を防ぐために、トランザクション処理環境にリプリケーション (複製) を使用することがある。
多くの DBMS にはリプリケーションを作るためのユーティリティ機能がある。
...</p></div><footer class=entry-footer><span title='2024-04-04 06:30:00 +0900 JST'>4月 4, 2024</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 読書メモ: DMBOK2 第8章 データ統合と相互運用性" href=https://soonraah.github.io/posts/dmbok-chapter-8/></a></article><footer class=page-footer><nav class=pagination><a class=next href=https://soonraah.github.io/page/2/>次へ&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://soonraah.github.io/>Froglog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>