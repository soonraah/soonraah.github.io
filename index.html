<!doctype html><html lang=ja dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><title>Froglog</title><meta name=keywords content><meta name=description content="blog"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/><meta name=google-site-verification content="XYZabc"><link href=https://soonraah.github.io/assets/css/stylesheet.min.595f5ecef354f9eb94e43d831cd360dcf8b7727542e731c55a7875c9e94a9577.css integrity="sha256-WV9ezvNU+euU5D2DHNNg3Pi3cnVC5zHFWnh1yelKlXc=" rel="preload stylesheet" as=style><link rel=manifest href=https://soonraah.github.io/site.webmanifest><link rel=icon href=https://soonraah.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.78.1"><link rel=alternate type=application/rss+xml href=https://soonraah.github.io/index.xml><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-73329599-2','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="Froglog"><meta property="og:description" content="blog"><meta property="og:type" content="website"><meta property="og:url" content="https://soonraah.github.io/"><meta property="og:image" content="https://soonraah.github.io/47"><meta property="og:updated_time" content="2021-02-28T21:00:00+09:00"><meta property="og:site_name" content="Froglog"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/47"><meta name=twitter:title content="Froglog"><meta name=twitter:description content="blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Froglog","url":"https://soonraah.github.io","description":"blog","thumbnailUrl":"https://soonraah.github.io/favicon.ico","sameAs":["https://twitter.com/soonraah","https://github.com/soonraah"]}</script></head><body class="list home dark" id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else{document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io accesskey=h><img src=/image/brand/favicon.png alt=logo aria-label=logo height=35>Home</a>
<span class=logo-switches><span class=theme-toggle><a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span></span></div><ul class=menu id=menu onscroll=menu_on_scroll()><li><a href=https://soonraah.github.io/about/><span>About</span></a></li><li><a href=https://soonraah.github.io/archives/><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/><span>Tags</span></a></li></ul></nav></header><main class=main><article class="first-entry home-info"><header class=entry-header><h2>Froglog</h2></header><section class=entry-content><p>大規模データ処理とか機械学習とか 🐸</p></section><footer class=entry-footer><div class=social-icons><a href=https://twitter.com/soonraah target=_blank rel="noopener noreferrer me" title=Twitter><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M23 3a10.9 10.9.0 01-3.14 1.53 4.48 4.48.0 00-7.86 3v1A10.66 10.66.0 013 4s-4 9 5 13a11.64 11.64.0 01-7 2c9 5 20 0 20-11.5a4.5 4.5.0 00-.08-.83A7.72 7.72.0 0023 3z"/></svg></a><a href=https://github.com/soonraah target=_blank rel="noopener noreferrer me" title=Github><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37.0 00-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44.0 0020 4.77 5.07 5.07.0 0019.91 1S18.73.65 16 2.48a13.38 13.38.0 00-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07.0 005 4.77a5.44 5.44.0 00-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37.0 009 18.13V22"/></svg></a></div></footer></article><article class=post-entry><figure class=entry-cover><img src=https://soonraah.github.io/image/photo/simone-pellegrini-L3QG_OBluT0-unsplash.jpg alt="Back of Hercules in main square in Florence, Italy."></figure><header class=entry-header><h2>Apache Flink の Backpressure の仕組みについて調べた</h2></header><section class=entry-content><p>ストリーム処理のフレームワークが備える backpressure という機能がある。
このポストでは Apache Flink の backpressure について調べたことを記載する。
Backpressure の目的 backpressure はストリーム処理システムにおける負荷管理の仕組みの一つ。
一時的な入力データ量の増大に対応する。
インターネットユーザの行動履歴やセンサーデータなどは常に一定量のデータが流れているわけではなく、単位時間あたりのデータ量は常に変動している。
一時的にスパイクしてデータ量が増大するようなことも起こりうる。
複数の operator からなる dataflow graph により構成されるストリーム処理システムにおいては、処理スピードのボトルネックとなる operator が存在する。
一時的に入力データ量が増えてボトルネックの operator の処理速度を上回ってしまった場合に、データの取りこぼしが発生するのを防ぐのが backpressure の目的となる。
Backpressure の仕組み Buffer-based ここでは以前のブログでも紹介した、ストリーム処理で必要とされる機能について書かれた Fragkoulis et al. 1 を引用して一般論としての backpressure について述べたい。
上流／下流の operator をそれぞれ producer, consumer とする。
producer, consumer (それらの subtask と言ってもいいかも) がそれぞれ異なる物理マシンに deploy されているケースが Figure 12b となる。
各 subtask は input と output の buffer を持っており、
producer は処理結果を output buffer に書き出す TCP 等の物理的な接続でデータを送信 consumer 側の output buffer にデータを格納 consumer がそれを読み込んで処理する というような流れになる。...</p></section><footer class=entry-footer>February 28, 2021&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Flink の Backpressure の仕組みについて調べた" href=https://soonraah.github.io/posts/backpressure-for-flink/></a></article><article class=post-entry><figure class=entry-cover><img src=https://soonraah.github.io/image/photo/claudia-chiavazza-N9vsB6OEeKM-unsplash.jpg alt=Lake></figure><header class=entry-header><h2>データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu</h2></header><section class=entry-content><p>はじめに 前回のポストではデータレイクとはどういうものかというのを調べた。
今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。
以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。
大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05） from NTT DATA Technology & Innovation Delta Lake Apache Hudi Apache Kudu これらはすべて論理的なストレージレイヤーを担う。
こちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。
当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。
Delta Lake https://delta.io/
Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.
Delta Lake
Delta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。...</p></section><footer class=entry-footer>January 26, 2021&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu" href=https://soonraah.github.io/posts/oss-for-data-lake/></a></article><article class=post-entry><figure class=entry-cover><img src=https://soonraah.github.io/image/photo/stephen-walker-mhqoyciC5I0-unsplash.jpg alt=Lake></figure><header class=entry-header><h2>いまさらながらのデータレイク</h2></header><section class=entry-content><p>最近よく聞かれるようになった「データレイク」という概念にあまりついていけていなかったため、いまさらながらざっと調べてみた。
データレイクとは Wikipedia によると最初にこの言葉を使ったのは Pentaho 社の CTO である James Dixon らしい。
その時の彼のブログ (10年前…) を読むと、既にあったデータマートに対して
Only a subset of the attributes are examined, so only pre-determined questions can be answered. The data is aggregated so visibility into the lowest levels is lost
–Pentaho, Hadoop, and Data Lakes - James Dixon’s Blog というような問題意識からデータレイクというコンセプトを提案したようだ。
最近？のデータレイクについてはベンダー等の記事が参考になる。
データレイクとは - AWS データレイクとは？ - talend データレイクとは？データレイクの落とし穴と効果 - Informatica 書籍だと『AWSではじめるデータレイク: クラウドによる統合型データリポジトリ構築入門』がいいだろうか。
データレイクの概要と AWS が考えている構築・運用がざっとわかる。...</p></section><footer class=entry-footer>December 31, 2020&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to いまさらながらのデータレイク" href=https://soonraah.github.io/posts/what-is-a-data-lake/></a></article><article class=post-entry><figure class=entry-cover><img src=https://soonraah.github.io/image/photo/mika-baumeister-Wpnoqo2plFA-unsplash.jpg alt=CSV></figure><header class=entry-header><h2>Apache Flink の DataStream API 利用時の CSV ファイル読み込み</h2></header><section class=entry-content><p>ストリーム処理における CSV ファイルの読み込み Apache Flink は unbounded なストリームデータを処理するためのフレームワークだ。
しかし現実的な application を開発する場合、ストリームデータに加えて static なファイルや DB 等を読み込みたいこともある。
star schema における dimension table 的な情報をストリームに結合したい場合 等が考えられる。
このポストでは Flink で DataStream API ベースでの実装において CSV ファイルを読むことを考える。
Flink は現時点の stable である v1.11 を想定。
CSV ファイルを読む方法 DataStream API ベースの実装で CSV ファイルを読むには StreamExecutionEnvironment のメソッドである readFile() を使う。
overload された同名のメソッドがいくつか存在するが、次の2つの引数が特に重要だろう。
まず1つめは FileInputFormat&lt;OUT> inputFormat であり、こちらは data stream の生成に用いる入力フォーマットを指定する。
おそらく最も一般的なのが TextInputFormat だと思われる。
もちろん単なる text として CSV ファイルを読み込み、後続の処理で各レコードを parse することも可能だが CSV 用の入力フォーマットがいくつか用意されているようだ。
PojoCsvInputFormat RowCsvInputFormat TupleCsvInputFormat なんとなく名前でわかると思うが、それぞれ readFile() の結果として返される DataStreamSource が内包する型が異なる。...</p></section><footer class=entry-footer>December 1, 2020&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Flink の DataStream API 利用時の CSV ファイル読み込み" href=https://soonraah.github.io/posts/read-csv-by-flink-datastream-api/></a></article><article class=post-entry><figure class=entry-cover><img src=https://soonraah.github.io/image/photo/sharon-mccutcheon-8lnbXtxFGZw-unsplash.jpg alt=Profit></figure><header class=entry-header><h2>機械学習の精度と利益と倫理とイシューと</h2></header><section class=entry-content><p>ちょっと昔話 かつて参画したプロジェクトの話。
そのプロジェクトでは他社から受注した受託開発として機械学習系のシステムを開発していた。
当時としては新しいフレームワークを使い、かなり頑張ってなんとか納期内で完成させた。
その中の1つの機能として A/B テストができるようにしていた。
パラメータチューニングによりパフォーマンスを改善することを想定していた。
しかし結局その機能は使われることがなかった。
なぜか。
A/B テストを実施するためのクライアントの追加の予算がつかなかったためである。
受託なのでなおさらなのだが、売上にならなければ工数をかけるこはできない。
工数を使ってパフォーマンス改善することはできなかった。
手はあるのに。
機械学習の精度は必ずしも利益に結びつかない この昔話で何が言いたいかというと、機械学習の精度改善は必ずしも利益に結びつかないということである。
そのことを示しているとても素晴らしい資料がこちら。
機械学習の精度と売上の関係 from Tokoroten Nakayama 前述の昔話の例はこの資料で言うところの③ロジスティック型 (=外注) となる。
いったん売上が立った後、追加予算がつかなかったので精度改善では売上は増えなかったのだ。
倫理感による精度改善 受託開発を主としている組織であれば工数にはシビアなので、売上の立たない工数をかけることはあまりないだろう。
(よっぽどの炎上鎮火とかでなければ)
しかし自社で製品やサービスを作って提供しているような組織の場合、利益にならない精度改善をしているのを時折見かける。
なぜそのようなことが起こるかと言うと多くの場合はデータサイエンティスト／機械学習エンジニアとしての倫理感からなのではないだろうか。
「◯◯予測という機能なのでできるだけ良い予測精度を示すべきだ」
「ユーザには気づかれない部分だが精度が悪いので改善したい」
倫理感や興味が先行してしまっているのだ。
しかしその精度を上げた先に利益があるとは限らない。
機械学習で職を得ている人間は自分の仕事を機械学習の精度を上げるゲームだとみなす傾向があるように思う。
例えばインターネット広告の CTR 予測。
これは予測精度が高いほど利益は改善するし、広告主に価値も提供できる。
精度改善に倫理と利益が伴っている、とても機械学習がハマる例だと思う。
本来はこれらを兼ね備えているのが良い適用先であるはずだ。
イシューは行き渡っているのか 利益に結びつかない、または間接的にしか結びつかないような精度改善をやることが許されるというのは組織に余裕があるということで悪いことではないのかもしれない。
しかし単によいイシューの設定ができてないだけという可能性もある。
自社で製品やサービスを作って提供しているような組織において、単純なロジスティック回帰でコアなところのビジネスを大きく加速させることができた時期を過ぎると機械学習で解くのに適したよい問題を恒常的に見つけ出すのは実は難しいのではないだろうかと最近考えるようになった。
ビジネスの領域拡大よりも既存領域への機械学習の適用の方が速いということは十分ありうる。
もちろんチームの規模にもよる。
機械学習チームの人的リソースの規模に対して機械学習で解くべきよいイシューを見つけ出せているのか、ということだ。
少し前にちょっと話題になったこちらの件もイシューが大事だと言っている。
全ての機械学習の論文は新しいアルゴリズムを提案しているのですか？ - Quora キャリアの行く末 事業会社においてビジネスの領域拡大よりも既存領域への機械学習の適用の方が速く、よいイシューを提供しにくいということがよく起こるのであれば、機械学習チームのリソースは余剰気味になりやすいということになる。
これが続くと今後機械学習しかやらない人材の市場価値は下がっていくのかもしれない。
もしくは自社で製品やサービスを持っている組織ではなく、受託開発やコンサルが主戦場になっていくのかもしれない。
何にせよ特定のプロダクトに commit したいのであれば機械学習エンジニアは機械学習以外のスキルも磨いていく必要があるように思う。
おわりに 見える範囲にいる人が利益にならない精度改善をしているのを横目で見てこのようなことを考えていた。
難しいけどできるだけ金を生んでいきたい。...</p></section><footer class=entry-footer>November 12, 2020&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 機械学習の精度と利益と倫理とイシューと" href=https://soonraah.github.io/posts/ml-accuracy-profit-ethic-issue/></a></article><footer class=page-footer><nav class=pagination><a class=next href=/page/2/>次のページ »</a></nav></footer></main><footer class=footer><span>&copy; 2021 <a href=https://soonraah.github.io>Froglog</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top" accesskey=g><button class=top-link id=top-link type=button><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);document.querySelector(`[id='${id}']`).scrollIntoView({behavior:"smooth"});});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>