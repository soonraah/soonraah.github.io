<!doctype html><html lang=ja dir=auto><head><meta name=generator content="Hugo 0.147.3"><script async src="https://www.googletagmanager.com/gtag/js?id=G-NSEGH2YT17"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NSEGH2YT17")</script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Froglog</title>
<meta name=description content="blog"><meta name=author content="soonraah"><link rel=canonical href=https://soonraah.github.io/><meta name=google-site-verification content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css integrity="sha256-IhHKMWS+eDACT2qtKzouUghDpk+PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as=style><link rel=icon href=https://soonraah.github.io/favicon2.ico><link rel=icon type=image/png sizes=16x16 href=https://soonraah.github.io/image/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://soonraah.github.io/image/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://soonraah.github.io/static/image/favicon/apple-touch-icon.png><link rel=mask-icon href=https://soonraah.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://soonraah.github.io/index.xml><link rel=alternate type=application/json href=https://soonraah.github.io/index.json><link rel=alternate hreflang=ja href=https://soonraah.github.io/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:url" content="https://soonraah.github.io/"><meta property="og:site_name" content="Froglog"><meta property="og:title" content="Froglog"><meta property="og:description" content="blog"><meta property="og:locale" content="ja"><meta property="og:type" content="website"><meta property="og:image" content="https://soonraah.github.io/image/brand/soonraah_full.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://soonraah.github.io/image/brand/soonraah_full.png"><meta name=twitter:title content="Froglog"><meta name=twitter:description content="blog"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Froglog","url":"https://soonraah.github.io/","description":"blog","logo":"https://soonraah.github.io/favicon2.ico","sameAs":["https://twitter.com/soonraah","https://github.com/soonraah"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://soonraah.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://soonraah.github.io/image/brand/favicon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://soonraah.github.io/about/ title=About><span>About</span></a></li><li><a href=https://soonraah.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://soonraah.github.io/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://soonraah.github.io/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://soonraah.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/danting-zhu-kWsT6p_S3cY-unsplash.jpg alt=iceberg></figure><header class=entry-header><h2 class=entry-hint-parent>Apache Iceberg の table を near real time で更新する</h2></header><div class=entry-content><p>Apache Iceberg の table を near real time に、つまり高頻度で更新するということをやってみた。
Apache Iceberg とは Apache Iceberg (以下 Iceberg) は分散ファイルシステムやクラウドストレージ上の table format であり、Apache Hudi や Delta Lake と並んで data lake や lakehouse architecture で用いられる。
特徴的なのは table とデータ実体 (Parquet, Avro など) の間に metadata file, manifest list, manifest file の抽象的なレイヤーがあり、ファイル単位で table の状態を track できること。
これにより強い isolation level、パフォーマンス、schema evolution など様々な機能・性能を実現できるようになっている。
Apache Iceberg Iceberg Table Spec
詳しくは公式ドキュメントを参照のこと。
最近では SmartNews 社が Iceberg で data lake を構築したことを記事にしていた。
Flink-based Iceberg Real-Time Data Lake in SmartNews (Part I) | by SmartNews | SmartNews, Inc | Apr, 2023 | Medium ベンダー提供の DWH 中心ではなく Lakehouse Architecture を目指すのであれば最有力の table format の1つだと言えそう。
...</p></div><footer class=entry-footer><span title='2023-05-11 01:30:00 +0900 JST'>5月 11, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Iceberg の table を near real time で更新する" href=https://soonraah.github.io/posts/update-iceberg-table-in-near-real-time/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/sebastian-herrmann-NbtIDoFKGO8-unsplash.jpg alt=contract></figure><header class=entry-header><h2 class=entry-hint-parent>Data Contract について調べた</h2></header><div class=entry-content><p>データエンジニアリングの領域で少し前から目にするようになった “data contract” という言葉。
なんとなく今の業務で困っている課題の解決になりそうな気がしつつもよくわかっていなかったので調べてみた。
data contract について語られているいくつかのブログ記事などを参考にしている。
Data Contract とは データの schema というのはナマモノで、いろいろな理由で変更されることがある。
schema を変更する場合、その schema のデータ (table や log) が所属する単一のビジネス機能や application のドメインで行われることになる。
そのドメインの閉じた世界で考える分にはこれで問題ないのだが、DWH や data lake など組織レベルのデータ基盤でデータを流通していた場合はその先のことも考えないといけなくなる。
このようにチームを超える影響というのは、ビジネス機能に責任を持っているチームからは見えにくくなっていることが多い。
上流の application 側で schema を変更したら下流のデータ基盤の ETL 処理がぶっ壊れてしまった、というのはデータ基盤運用あるあるではないだろうか。
というところを解決して平和に過ごせるようにすることが data contract の主なモチベーションだと思われる。
“contract” は日本語で言うところの「契約」。
組織におけるデータ流通において、データの送り手である producer 側と受け手である consumer 側との間で合意した契約を遵守することにより、前述のような問題を避けることができるというのが data contract である。
組織内のデータの見通しがよくなったり、パイプラインを宣言的に開発することができるようになるというメリットもある。
エンジニアにとっては Datafold のブログ記事の例を読むとイメージしやすいかもしれない。
To provide another analogy, data contracts are what API is for the web services. Say we want to get data from Twitter. One way is to scrape it by downloading and parsing the HTML of Twitter’s webpage. This may work, but our scraper will likely break occasionally, if Twitter, for instance, changes a name of a CSS class or HTML structure. There is no contract between Twitter’s web page and our scraper. However, if we access the same data via Twitter’s API, we know exactly the structure of the response we’re going to get. An API has required inputs, predictable outputs, error codes, SLAs (service level agreements – e.g. uptime), and terms of use, and other important properties. Importantly, API is also versioned which helps ensure that changes to the API won’t break end user’s applications, and to take advantage of those changes users would graciously migrate to the new version.
...</p></div><footer class=entry-footer><span title='2023-04-08 17:00:00 +0900 JST'>4月 8, 2023</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Data Contract について調べた" href=https://soonraah.github.io/posts/looked-into-data-contracts/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/matteo-vistocco-JISJeV-pXaQ-unsplash.jpg alt=gap></figure><header class=entry-header><h2 class=entry-hint-parent>Glue Schema Registry の導入を断念した話</h2></header><div class=entry-content><p>業務で AWS Glue Schema Registry を使おうとしたけど、やっぱりやめたというお話。
Glue Schema Registry What’s Schema Registry? AWS Glue Schema Registry は2020年に発表された AWS の機能だ。
Control the evolution of data streams using the AWS Glue Schema Registry 一方、私が最初に schema registry 的なものを見たのは Confluent の例。
Schema Registry の概要 - Confluent AWS の Glue Schema Registry はこれより後のリリースであり、同等のものの AWS マネージド版といったところだろうか。
schema registry で何ができるかは Confluent のリンク先の図がとてもわかりやすいので参考にしていただきたい。
Glue Schema Registry もだいたい同じで、ストリーム処理のための機能である。
Glue Schema Registry で解決したい課題とその機能 データ基盤上のストリーム処理における schema 管理はバッチ処理のそれとは異なる難しさがある。
これは schema evolution と呼ばれる問題で以前のポストでも述べている。
バッチ処理おじさんがストリーム処理のシステムを開発するにあたって調べたこと 難しい点として以下のようなことが挙げられる。
...</p></div><footer class=entry-footer><span title='2022-12-13 00:30:00 +0900 JST'>12月 13, 2022</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Glue Schema Registry の導入を断念した話" href=https://soonraah.github.io/posts/give-up-on-schema-registry/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://source.unsplash.com/MylhxBVekRA/1000x1000 alt="Orange trees by a frozen lake"></figure><header class=entry-header><h2 class=entry-hint-parent>「データレイク」と「データレイク層」</h2></header><div class=entry-content><p>「データレイク」という言葉は使う人によって異なった意味があるように感じており、気になっていた。
このポストではアーキテクチャ目線でのデータレイクと内容物目線でのデータレイクの違いについて書いてみる。
便宜上前者を「データレイク」、後者を「データレイク層」と呼ぶことにする。
アーキテクチャ目線の「データレイク」 「データレイク」については以前こちらのポストで書いたのでここでは詳しく触れない。
詳細はリンク先を見ていただきたい。
ここでキーとなるのが、
加工前データや非構造化データを含むあらゆるデータを保存 一元的なデータ管理 という部分だ。
あらゆるデータを一元的に管理するという思想であり、これができるアーキテクチャがデータレイクということだ。
例えば AWS や Azure のドキュメントを見るとデータレイクの中が zone に分けられており、生データを保持する raw zone や加工されたデータを置いておく curated zone などがある。
(zone の命名にもいくつかの流派があるようだ…)
Reference architecture - Data Analytics Lens Data lake zones and containers - Cloud Adoption Framework | Microsoft Docs 次の Robinhood 社の例でもデータレイク中に生データとその派生データが存在している。
Fresher Data Lake on AWS S3 | by Balaji Varadarajan | Robinhood 内容物目線の「データレイク層」 一方でデータレイクには生データのみを置くべき、という考えもある。
本書におけるデータレイク（DataLake）層とは、元のデータをコピーして、1つのシステムに集約したものを指します。 データソース（＝水源）から流れてきたデータを蓄える場所なのでレイク（湖）と呼びます。
ECサイトの注文履歴データを、分析用DBにコピーしている場合、それがデータレイクと言えます。データレイクのデータは、データソースと一対一の関係にあります。何も加工していない、ただのコピーだからです。
何も加工していない、ただのコピーであることが重要です。仮にデータの中身に誤りがあったとしても、修正や加工をせず、そのまま集約しましょう。
– ゆずたそ,渡部 徹太郎,伊藤 徹郎. 実践的データ基盤への処方箋〜 ビジネス価値創出のためのデータ・システム・ヒトのノウハウ (Japanese Edition) (pp.57-58). Kindle 版.
...</p></div><footer class=entry-footer><span title='2022-06-21 08:00:00 +0900 JST'>6月 21, 2022</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 「データレイク」と「データレイク層」" href=https://soonraah.github.io/posts/data-lake-and-data-lake-layer/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/xavier-von-erlach-AU2goNvfyWU-unsplash.jpg alt="Maturing cheese at the Alpage des Lachiores, Val d'Hérens."></figure><header class=entry-header><h2 class=entry-hint-parent>成熟フェーズの事業におけるデータサイエンティスト</h2></header><div class=entry-content><p>ポエムです。
事業フェーズごとのデータサイエンティストの役割 まずはこちらの発表。
事業立ち上げにデータサイエンティストは必要なのか？ | CA BASE NEXT とても納得できる内容だった。
一部抜き出して要約すると
事業の立ち上げフェーズ データがまだなかったり、整備されていない状態 データサイエンスによる改善がしにくい 事業のグロースフェーズ 大規模なデータが使える状態 データサイエンスによる改善がやりやすい とのこと。異論はない。
では事業が立ち上がり、グロースが落ち着いたその後の成熟フェーズではどうなのだろうかという話。
成熟フェーズにおける改善の難しさ 端的に言うと成熟フェーズでは ML によるさらなる改善は困難になってくると思う。
ここで言う成熟フェーズにおいてはプロダクトの進化とともに機械学習もそれなりに適用されてきたものとする。
成熟フェーズということで既存の ML モデル、特にビジネスインパクトが大きい箇所はこれまでいろいろな改善が重ねられてきている。
そのモデルの精度をさらに上げるとなると、より高度なアルゴリズム、より複雑なデータ等を扱う必要がある。
しかし技術的によっぽど大きなブレークスルーがない限りは精度の改善幅はグロースフェーズよりもかなり小さいものとなるだろう。
精度が上がれば上がるほど、次の1%を上げるためのコストは大きくなっていく。
改善が進むほどに次の改善業務は困難になっていく。
(蛇足だがある程度大きな組織でなければ高度で state-of-the-art な ML アルゴリズムは運用しない方がいいと考えている)
では既存ではない新しい適用箇所に ML を使えばいいのではとなるかもしれない。
しかしやはりそれも難しい。
ビジネスインパクトが大きく、かつわかりやすい適用箇所にはおそらくすでに ML が適用されているからだ。
その状態から更によい適用箇所を見つけるには深いドメイン知識が必要になったりする。
という感じでいわゆるキラキラした「ML でビジネスをドライブ！」みたいなことは成熟フェーズでは難しいことが多いのではないか。
しかしデータサイエンティストにやることがないわけではない。
成熟フェーズで何ができるか ぱっと思いつくのは次のような仕事。
データドリブンな施策の立案・評価 これは事業フェーズ問わずあるべき ドメイン知識が必要 ML エンジニアリング パイプラインの改善や属人性をなくすお仕事 ML モデルの受動的なメンテナンス 精度が変化したときの調査 内部的・外部的要因によるデータの変化への対応 やっぱり ML モデルの精度改善 成熟フェーズということでビジネスもスケールしていれば 0.1% の精度改善でも売上的なインパクトは大きいかもしれない いわゆる狭義のデータサイエンスではなく、ドメイン知識であったりアナリストやエンジニア的な視点が絡んだ仕事が増えてくる。
よくある「ML だけじゃなく◯◯もできると強いよね」みたいな話になってしまった。
おわりに …という話が少し前に Twitter で知人との話題に上がった。
若者が歴史的にいろんな人が改善に取り組んできた ML モデルの改善にアサインされている、というのが近いところで観測されたのでたいへんそうだなあと思いつつこの件を思い出したので書いてみた。
...</p></div><footer class=entry-footer><span title='2021-07-12 22:00:00 +0900 JST'>7月 12, 2021</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 成熟フェーズの事業におけるデータサイエンティスト" href=https://soonraah.github.io/posts/ds-in-maturation-phase/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/simone-pellegrini-L3QG_OBluT0-unsplash.jpg alt="Back of Hercules in main square in Florence, Italy."></figure><header class=entry-header><h2 class=entry-hint-parent>Apache Flink の Backpressure の仕組みについて調べた</h2></header><div class=entry-content><p>ストリーム処理のフレームワークが備える backpressure という機能がある。
このポストでは Apache Flink の backpressure について調べたことを記載する。
Backpressure の目的 backpressure はストリーム処理システムにおける負荷管理の仕組みの一つ。
一時的な入力データ量の増大に対応する。
インターネットユーザの行動履歴やセンサーデータなどは常に一定量のデータが流れているわけではなく、単位時間あたりのデータ量は常に変動している。
一時的にスパイクしてデータ量が増大するようなことも起こりうる。
複数の operator からなる dataflow graph により構成されるストリーム処理システムにおいては、処理スピードのボトルネックとなる operator が存在する。
一時的に入力データ量が増えてボトルネックの operator の処理速度を上回ってしまった場合に、データの取りこぼしが発生するのを防ぐのが backpressure の目的となる。
Backpressure の仕組み Buffer-based ここでは以前のブログでも紹介した、ストリーム処理で必要とされる機能について書かれた Fragkoulis et al. 1 を引用して一般論としての backpressure について述べたい。
上流／下流の operator をそれぞれ producer, consumer とする。
producer, consumer (それらの subtask と言ってもいいかも) がそれぞれ異なる物理マシンに deploy されているケースが Figure 12b となる。
各 subtask は input と output の buffer を持っており、
producer は処理結果を output buffer に書き出す TCP 等の物理的な接続でデータを送信 consumer 側の output buffer にデータを格納 consumer がそれを読み込んで処理する というような流れになる。
buffer はマシンごとの buffer pool で管理されており、input/output で buffer が必要となった場合はこの buffer pool に buffer が要求される。
...</p></div><footer class=entry-footer><span title='2021-02-28 21:00:00 +0900 JST'>2月 28, 2021</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Flink の Backpressure の仕組みについて調べた" href=https://soonraah.github.io/posts/backpressure-for-flink/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/claudia-chiavazza-N9vsB6OEeKM-unsplash.jpg alt=Lake></figure><header class=entry-header><h2 class=entry-hint-parent>データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu</h2></header><div class=entry-content><p>はじめに 前回のポストではデータレイクとはどういうものかというのを調べた。
今回はデータレイクの文脈でどのような OSS が注目されているのかを見ていきたい。
以下は NTT データさんによる講演資料であり、その中で「近年登場してきた、リアルタイム分析に利用可能なOSSストレージレイヤソフト」というのが3つ挙げられている。
大規模データ活用向けストレージレイヤソフトのこれまでとこれから（NTTデータ テクノロジーカンファレンス 2019 講演資料、2019/09/05） from NTT DATA Technology & Innovation Delta Lake Apache Hudi Apache Kudu これらはすべて論理的なストレージレイヤーを担う。
こちらの講演資料に付け足すようなこともないかもしれないが、このポストではデータレイクという文脈から自分で調べて理解した内容をまとめるということを目的にする。
当然 Hadoop, Hive, Spark 等もデータレイクの文脈において超重要だが、「データレイク」という言葉がよく聞かれるようになる前から普及していたのでこのポストでは触れないことにする。
Delta Lake https://delta.io/
Delta Lake is an open-source storage layer that brings ACID transactions to Apache Spark™ and big data workloads.
Delta Lake
Delta Lake は Apache Spark の読み書きに ACID な transaction を提供するストレージレイヤーの OSS である。
Databricks が作り、2019年4月に v0.1.0 がリリースされたのが最初だ。
使い方はめちゃ簡単で、dependency を設定した上で Spark で
...</p></div><footer class=entry-footer><span title='2021-01-26 08:00:00 +0900 JST'>1月 26, 2021</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to データレイク関連の OSS - Delta Lake, Apache Hudi, Apache Kudu" href=https://soonraah.github.io/posts/oss-for-data-lake/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/stephen-walker-mhqoyciC5I0-unsplash.jpg alt=Lake></figure><header class=entry-header><h2 class=entry-hint-parent>いまさらながらのデータレイク</h2></header><div class=entry-content><p>最近よく聞かれるようになった「データレイク」という概念にあまりついていけていなかったため、いまさらながらざっと調べてみた。
データレイクとは Wikipedia によると最初にこの言葉を使ったのは Pentaho 社の CTO である James Dixon らしい。
その時の彼のブログ (10年前…) を読むと、既にあったデータマートに対して
Only a subset of the attributes are examined, so only pre-determined questions can be answered. The data is aggregated so visibility into the lowest levels is lost
–Pentaho, Hadoop, and Data Lakes - James Dixon’s Blog というような問題意識からデータレイクというコンセプトを提案したようだ。
最近？のデータレイクについてはベンダー等の記事が参考になる。
データレイクとは - AWS データレイクとは？ - talend データレイクとは？データレイクの落とし穴と効果 - Informatica 書籍だと『AWSではじめるデータレイク: クラウドによる統合型データリポジトリ構築入門』がいいだろうか。
データレイクの概要と AWS が考えている構築・運用がざっとわかる。
Amazon で検索した限りだと現時点でタイトルに「データレイク」を含む和書はこれのみだった。
...</p></div><footer class=entry-footer><span title='2020-12-31 20:00:00 +0900 JST'>12月 31, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to いまさらながらのデータレイク" href=https://soonraah.github.io/posts/what-is-a-data-lake/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/mika-baumeister-Wpnoqo2plFA-unsplash.jpg alt=CSV></figure><header class=entry-header><h2 class=entry-hint-parent>Apache Flink の DataStream API 利用時の CSV ファイル読み込み</h2></header><div class=entry-content><p>ストリーム処理における CSV ファイルの読み込み Apache Flink は unbounded なストリームデータを処理するためのフレームワークだ。
しかし現実的な application を開発する場合、ストリームデータに加えて static なファイルや DB 等を読み込みたいこともある。
star schema における dimension table 的な情報をストリームに結合したい場合 等が考えられる。
このポストでは Flink で DataStream API ベースでの実装において CSV ファイルを読むことを考える。
Flink は現時点の stable である v1.11 を想定。
CSV ファイルを読む方法 DataStream API ベースの実装で CSV ファイルを読むには StreamExecutionEnvironment のメソッドである readFile() を使う。
overload された同名のメソッドがいくつか存在するが、次の2つの引数が特に重要だろう。
まず1つめは FileInputFormat&lt;OUT> inputFormat であり、こちらは data stream の生成に用いる入力フォーマットを指定する。
おそらく最も一般的なのが TextInputFormat だと思われる。
もちろん単なる text として CSV ファイルを読み込み、後続の処理で各レコードを parse することも可能だが CSV 用の入力フォーマットがいくつか用意されているようだ。
PojoCsvInputFormat RowCsvInputFormat TupleCsvInputFormat なんとなく名前でわかると思うが、それぞれ readFile() の結果として返される DataStreamSource が内包する型が異なる。
これについては後述の実験にて確認する。
...</p></div><footer class=entry-footer><span title='2020-12-01 00:30:00 +0900 JST'>12月 1, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to Apache Flink の DataStream API 利用時の CSV ファイル読み込み" href=https://soonraah.github.io/posts/read-csv-by-flink-datastream-api/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://soonraah.github.io/image/photo/sharon-mccutcheon-8lnbXtxFGZw-unsplash.jpg alt=Profit></figure><header class=entry-header><h2 class=entry-hint-parent>機械学習の精度と利益と倫理とイシューと</h2></header><div class=entry-content><p>ちょっと昔話 かつて参画したプロジェクトの話。
そのプロジェクトでは他社から受注した受託開発として機械学習系のシステムを開発していた。
当時としては新しいフレームワークを使い、かなり頑張ってなんとか納期内で完成させた。
その中の1つの機能として A/B テストができるようにしていた。
パラメータチューニングによりパフォーマンスを改善することを想定していた。
しかし結局その機能は使われることがなかった。
なぜか。
A/B テストを実施するためのクライアントの追加の予算がつかなかったためである。
受託なのでなおさらなのだが、売上にならなければ工数をかけるこはできない。
工数を使ってパフォーマンス改善することはできなかった。
手はあるのに。
機械学習の精度は必ずしも利益に結びつかない この昔話で何が言いたいかというと、機械学習の精度改善は必ずしも利益に結びつかないということである。
そのことを示しているとても素晴らしい資料がこちら。
機械学習の精度と売上の関係 from Tokoroten Nakayama 前述の昔話の例はこの資料で言うところの③ロジスティック型 (=外注) となる。
いったん売上が立った後、追加予算がつかなかったので精度改善では売上は増えなかったのだ。
倫理感による精度改善 受託開発を主としている組織であれば工数にはシビアなので、売上の立たない工数をかけることはあまりないだろう。
(よっぽどの炎上鎮火とかでなければ)
しかし自社で製品やサービスを作って提供しているような組織の場合、利益にならない精度改善をしているのを時折見かける。
なぜそのようなことが起こるかと言うと多くの場合はデータサイエンティスト／機械学習エンジニアとしての倫理感からなのではないだろうか。
「◯◯予測という機能なのでできるだけ良い予測精度を示すべきだ」
「ユーザには気づかれない部分だが精度が悪いので改善したい」
倫理感や興味が先行してしまっているのだ。
しかしその精度を上げた先に利益があるとは限らない。
機械学習で職を得ている人間は自分の仕事を機械学習の精度を上げるゲームだとみなす傾向があるように思う。
例えばインターネット広告の CTR 予測。
これは予測精度が高いほど利益は改善するし、広告主に価値も提供できる。
精度改善に倫理と利益が伴っている、とても機械学習がハマる例だと思う。
本来はこれらを兼ね備えているのが良い適用先であるはずだ。
イシューは行き渡っているのか 利益に結びつかない、または間接的にしか結びつかないような精度改善をやることが許されるというのは組織に余裕があるということで悪いことではないのかもしれない。
しかし単によいイシューの設定ができてないだけという可能性もある。
自社で製品やサービスを作って提供しているような組織において、単純なロジスティック回帰でコアなところのビジネスを大きく加速させることができた時期を過ぎると機械学習で解くのに適したよい問題を恒常的に見つけ出すのは実は難しいのではないだろうかと最近考えるようになった。
ビジネスの領域拡大よりも既存領域への機械学習の適用の方が速いということは十分ありうる。
もちろんチームの規模にもよる。
機械学習チームの人的リソースの規模に対して機械学習で解くべきよいイシューを見つけ出せているのか、ということだ。
少し前にちょっと話題になったこちらの件もイシューが大事だと言っている。
全ての機械学習の論文は新しいアルゴリズムを提案しているのですか？ - Quora キャリアの行く末 事業会社においてビジネスの領域拡大よりも既存領域への機械学習の適用の方が速く、よいイシューを提供しにくいということがよく起こるのであれば、機械学習チームのリソースは余剰気味になりやすいということになる。
これが続くと今後機械学習しかやらない人材の市場価値は下がっていくのかもしれない。
もしくは自社で製品やサービスを持っている組織ではなく、受託開発やコンサルが主戦場になっていくのかもしれない。
何にせよ特定のプロダクトに commit したいのであれば機械学習エンジニアは機械学習以外のスキルも磨いていく必要があるように思う。
おわりに 見える範囲にいる人が利益にならない精度改善をしているのを横目で見てこのようなことを考えていた。
難しいけどできるだけ金を生んでいきたい。</p></div><footer class=entry-footer><span title='2020-11-12 09:30:00 +0900 JST'>11月 12, 2020</span>&nbsp;·&nbsp;soonraah</footer><a class=entry-link aria-label="post link to 機械学習の精度と利益と倫理とイシューと" href=https://soonraah.github.io/posts/ml-accuracy-profit-ethic-issue/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://soonraah.github.io/page/2/>«&nbsp;前へ&nbsp;
</a><a class=next href=https://soonraah.github.io/page/4/>次へ&nbsp;&nbsp;»</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://soonraah.github.io/>Froglog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>